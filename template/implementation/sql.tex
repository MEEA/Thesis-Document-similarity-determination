\section{SQL Support Implementation}
\label{sec:implementationsql}

The implementation of the different components described in the \ac{SQL} architecture approaches in Chapter \ref{chap:design} are explained in this section. We describe the implementation of the three main components which provide support for MySQL incoming requests, and a multi-database protocol for outgoing requests. \ac{NMF} routing in ServiceMix-mt is supported by the \ac{NMR} and a set of endpoints which are deployed on the ServiceMix-camel, and ServiceMix-camel-mt. 


%explain that this is an extension of the myosotic tungsten connector. That is a proxy to provide a direct access to backend mysql databases, which is enhaced with ip filtering
%explain that we need to integrate it with the esb, so we have to extend it, recompile it, and build it as an osgi bundle
%start explaining the osgi bundle properties, and the osgi bundle activator
%explain how it consumes the services from external bundles. We can put here an example of consuming the cashing service of the jbi registry which is in the activator, and the normalized message router api which is in the xbean file.

%server configuration file
%%%% Server Thread
%this is a server thread which listens on port 3311, and with a pool of threads which are managed by the java.util.concurrent.ExecutorService. The max number of concurrent users can be set in the config file. Per defect is 100 of simultaneous connections and with a wait termination time of 10 seconds. Each thread will wait 10 seconds to terminate in case that the system wants to be shut down

%%%% Connection handler, which is an interface which allows the support of more than one protocol in the same package, but the ports must be different. We highly recommend to build different protocol support as separate osgi bundles, instead of everything in the same osgi bundle
%%%% Mysql connection and protocol handler
% difference between the two of the handlers
% Server has three main states: waiting, sentservergreeting, and command processing
% here we can put a graph like the one of the mysql protocol to explain the data flow.
% we centrate the business logic of the bundle in the process query function. Explain the flow of the process query: classificate query, extract table information, request for meta-data for the database and the table, get the metadata, cache the metadata, build the structures of both queries and meta-data for the queries, retrieve the response, get the data and metadata, and cache it if it is allowed, and send it to the user in tcp stream. if a query is of type create, it includes in the service registry the information related to the table which was created
% mention multiqueries
% mention when we cache the information

%%%% MySQL utils package
% contains the main functionalities to read the tcp stream and it describes the mysql package according to the mysql specification. read byte, read long, read string, write byte, write long, write stream. It provides also the conversion of the base 64 to byte and byte to base 64. explain why we do this. we must sent the queries in string stile so that they can be modified by the transformer. this is transparent to the user.
% Mysql constants are stored in a different file. The protocol constants of the mysql communication protocol.

%%%% JBI package
% put a list of the properties and their types
% explain the main functionality of this package -> provide integration of the mysql protocol with the jbi environment (NMR)
% explain the need to implement our own result set and result set meta data. Because the information is received from the camel jdbc as a arraylist<hashmap<string,object>>. 
% message exchange handler is in charge of controling everything, and at the same time functions as the statement of the sql.
% NMarshalers, marshaling and demarshaling of the requests. Marshaling from string, and property vectors to nmr, and marshaling the result into the result set, result set meta data, and statement
% nmconstants contain the variables which are used in the NMF

%%%% Registry
% the access credentials for the postgresql service registry are here also, and the fixed server responses to the "server config queries"
% connection with the jbi registry cache, and connection with the service registry
% cashing functionalities, the logic of the cashing in the system
% creation of the cashing keys to be able to store both tenant authentication, tenant properties, and tenant queries. we can make here a listing with the keys
\subsection{CDASMix MySQL Proxy}
The CDASMix MySQL Proxy provides support for MySQL connections. It implements the functionalities of a MySQL proxy and the needed routing operations and transformation to  integrate it in ServiceMix-mt. As discussed in Chapter \ref{chap:relatedworks}, the original MySQL proxy is implemented in the C programming language. Therefore, we cannot integrate it with ServiceMix-mt, as this runs on a Java platform. The Myosotis Tungsten Connector is part of a data replication engine developed by Continuent, Inc \cite{tungstenwiki}. One of the components which build the application is a MySQL proxy written in the Java programming language. This component suites the proxying requirements in this diploma thesis, and it runs on the Java platform. However, it is not \ac{OSGi} compliant, it is not integrated with the \ac{JBI} environment, and the backend databases' meta-data must be explicitly defined in its configuration file. Furthermore, it provides a direct connection from the component to the database. We utilize it as a base for implementing the CDASMix MySQL Proxy, and aggregate the required functionalities of this diploma thesis. We present the class diagram of the component in Section \ref{appendix:cdasmixmysqlproxy}, but omit the attributes and operations listings due to the high amount of operations, and attributes we manage in the component.

ServiceMix-mt is built as an \ac{OSGi} container with \ac{JBI} integration functionalities. Furthermore, ServiceMix 4.x and later version consider the \ac{JBI} framework deprecated in their systems. Therefore, we build the CDASMix MySQL Proxy component as an \ac{OSGi} bundle. During the bundle activation process, the \ac{OSGi} container creates one instance of the class which implements the \term{BundleActivator} interface, and executes its operations. The class \term{OSGIHandler} of the MySQL Proxy \ac{OSGi} bundle implements those operations, and allows us to instantiate the classes which are used in the component, its properties, and the references to third party \ac{OSGi} bundles. Furthermore, it loads the server properties file from the bundle package. The instantiation of Java classes packed in third party bundles can be done by looking up the associated bundle service in the \ac{OSGi} registry. The lookup can be done either by accessing with Java code the \term{BundleContext} operations (see Listing \ref{lst:bundleactivator}), or using Spring functionalities. Spring enables the properties setting and the external bundle reference in \ac{XML} format (see Listing \ref{lst:bundleactivator}), in the \term{beans.xml} file. We utilize this feature to reference to the following \ac{OSGi} bundles: the \ac{NMR} \ac{API} shipped with ServiceMix, and the \ac{JBI} ServiceMix Registry developed by Uralov \cite{Uralov2012}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\lstinputlisting[float=htb,label={lst:bundleactivator},caption={[Reference to External OSGi Bundle Services]Reference to external OSGi bundle JBI Service Registry Cache and \ac{NMR} \ac{API} services utilizing Java libraries and Spring XML beans.},style=ebnf]{./gfx/bundleactivation.txt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The \term{mysqlproxy.server} package contains the main classes of this component. The \term{Configuration} class loads the configuration file, reads it, and sets the properties of the server which accepts the incoming MySQL requests. The \term{ServerThread} starts the server and listens in the port defined in the server configuration file. This class interacts with the Java library \term{java.util.concurrent.ExecutorService}, in order to provide a pool of threads for processing the incoming requests. The maximum number of concurrent connections the server can accept is defined in the configuration file, and its default value is 100. Due to possible delays in the backend Cloud data stores, the threads termination time can be set in the configuration file, and its default value is 10 seconds. When restarting the \ac{OSGi} bundle, or shutting down ServiceMix-mt, the component shut down process is delayed due to the termination of the threads. 

For each connection accepted in the server thread, an instance of a protocol handler is created. We highly recommend to utilize the MySQL client native driver MySQL Connector/J \term{mysql-connector-java-5.1.22-bin.jar}, as we follow the MySQL protocol it implements in this component. The \term{ConnectionHandler} is implemented as a Java interface, in order to allow future extensibility for different database server protocols. In this diploma thesis we provide support for the MySQL communication protocol. However, we do not recommend to implement a multiple protocol support in the component. The server thread listens to one specific port, and this fact may lead with conflicts between the protocols or the classes which implement the protocol support. Furthermore, a change or upgrade of a specific protocol would involve the redeployment of the component, and a service outage of all the protocols supported. The system resources consumption, e.g. Java heap memory or CPU, is limited for each bundle in the \ac{OSGi} container, and may lead to scalability problems with the maximum number of concurrent threads in the pool. We recommend to implement the different database server communication protocols in independent \ac{OSGi} components, but profiting from the resources sharing support for common resources, e.g. cache, in the \ac{OSGi} container. Each \term{ConnectionHandler} instance creates a \term{ProtocolHandler}. The \term{ProtocolHandler} class groups the support for the MySQL communication protocol phases: connection, authentication, command, and termination (see Section \ref{sec:fundamentalssql}). 

The internal server states are defined as waiting, sent server greeting, and command processing. During the waiting phase, the server waits for the client's MySQL packet to arrive. In the send server greeting phase, the MySQL server greeting is sent to the client, and the server waits for the authentication challenge response. When the authentication is successful, the server is in the command phase. The command phase groups the interpretation of the request, verification of the tenant and user information, message transfer to the \term{CDASMixjdbc} component, and the transmission of the MySQL response via the \ac{TCP} socket created by the client.

The logic of the query processing is located in the method \term{processQuery}. This method receives the \ac{SQL} query contained in the MySQL packet, and processes it. The processing of the query is divided into the following activities: classification, meta-data retrieval, meta-data construction, and response transfer. The classification of queries is fundamental in a system which provides cashing functionalities. We differentiate the received queries as server configuration queries, data retrieval queries, and database modification queries. In the first group we classify the queries which are related to the specific server configuration that a MySQL client requires. This queries must be directly executed in the backend \ac{SQL} Cloud data store. Therefore, they are forwarded directly to the \term{CDASMixjdbc} component. The data retrieval queries involve those that read the data stored in a database. The response to this queries is cached in order to read them directly from the cashing component in a close future. The database modification queries perform modification on the backend Cloud data stores, such as table creation, row update, or row insertion. These cannot be cached, but the entries in the cache which contain data related to the modified tables are invalidated. The meta-data of the user's request is retrieved from the \term{mysqlproxy.registry} package, which includes information about the target database, access credentials, etc. Multi-querying processing is supported in the prototype, allowing users to include in one execution statement more than one query. For each of the queries a set of meta-data for the request is created, as one query may contain different meta data from another one (e.g. tables which are located in different backend Cloud data stores). 

The operations on the MySQL packages are included in the \term{commons.mysql} package. This contains the \term{MySQLPacket} class, which provides a set of I/O operations for reading and writing on \ac{TCP} streams, and specifically adapted to the MySQL packet format, e.g. read byte, read integer, read long, read string, write byte, write string, write long, etc. The \term{MySQLPacket} class provides a Java based representation of the MySQL packet. The processing of binary content in the \ac{SQL} queries requires a special transformation in the scope of the system. For integration purposes with querying transformation component, we must send the query as a string which can be parsed prior to the transformation. Therefore, we encode the binary data contained in the MySQL request into base64, and inject it in the string representation of the query. Binary data in a received MySQL request is identified by the prefix \term{binary}. In the backend Cloud data store the binary data is stored in base64 format, but this transformation must be transparent to the user. Hence, the class provides decoding support when the component receives from the backend data store a previously stored base64 format, and sends it to the client as binary data. The \term{MySQLConstants} class included in this packet contains the protocol constants. 

The integration with the \ac{JBI} framework of ServiceMix-mt is provided by the \term{mysql.jbi} package, where marshaling and demarshaling of the requests and responses to and from the \ac{NMF} occurs. The detailed content of the marshalled incoming requests and responses is described in Appendix \ref{appendix:nmfcontent}. As the MySQL requests and responses differ, in Chapter \ref{chap:design} we design two different contents. The data retrieval operation responses to the MySQL client must be sent as \term{java.sql.ResultSet} objects, which are contained in the \term{java.sql.Statement}. This fact forces us to implement such objects, and its methods, as the response from the \term{CDASMixjdbc} component stores the retrieved data in a \term{java.util.ArrayList}. The demarshaler in this package creates the \term{java.sql.ResultSet} and the \term{java.sql.Statement}, and populates it with the retrieved data in the \term{java.util.ArrayList}. Furthermore, the marshaler creates the \term{java.sql.ResultSetMetadata} with the meta-data retrieved from the backend database server. The meta-data contained in this object does not refer to connection or tenant-aware meta-data, but the meta-data of the table, rows, and columns of the backend database where the query is executed. The \term{NMConstants} class contains the standardized naming we define of the properties and attachments in the \ac{NMF}. The \term{MessageExchangeHandler} class implements the operations which directly invoke the routing operations in the \ac{NMR} \ac{API}. The target \ac{JBI} endpoint \ac{URI} is dynamically created from the tenant and user \ac{UUID} retrieved from the cache, or the service registry, and inserted in the \term{MessageExchange} target endpoint URI. After the creation of the \term{MessageExchange}, the synchronous \term{sendsync} operation of the \ac{NMR} \ac{API} is invoked, the message is routed, and the thread waits until the reception of the message from the \ac{JBI} endpoint.

As described before, the CDASMix MySQL proxy component interacts with two main components to retrieve tenant's information: Registry Cache, and the Service Registry. The former is provided by the \ac{OSGi} bundle \term{jbi.servicemix.registry}, while the latter is connected through a set of methods provided in the \term{mysqlproxy.registry} package in the CDASMix MySQL proxy component. The cashing interface provided by the \term{jbi.servicemix.registry} implement the put and get operations, where the cashing key, and the data to store are provided. The \term{mysqlproxy.registry} accesses the cache through this interface, but dynamically creates the cashing key for the object it stores, following the format described in Listing \ref{lst:cachekey}. Three different types of information identified by a unique tag are stored in the cache: tenant authentication, tenant backend data source properties, and query results. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\lstinputlisting[float=htb,label={lst:cachekey},caption={[Dynamic Creation of Cache Keys]Dynamic creation of cache keys to store the different types of data and meta-data.},style=ebnf]{./gfx/cachekeys.txt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

When the information is not located in the cache, the service registry is queried, and its result cashed. The CDASMix MySQL proxy establishes a database connection with the PostgreSQL database server where the service registry is hosted when the component is deployed. A dedicated connection for this component reduces the latency of creating a database connection per received MySQL request. 


%%%% provides the integratio with the jbi environment
% equal to the jdbccdasmix proxy, this registers the jbi endpoint prefix
% we extend the clases which are involved in the deployment of the service units: camel spring deployer, and the endpoint uri, which are the camelprovider endpoint and the camelconsumer endpoint. 
% in this component, as in the servicemix-camel, we use the jbi option check serialization = nocheck. This checks if the object can be serializable. But all the objects we use in the properties implement the serializable interface, so thre is no need of checking this. 
\subsection{Multi-tenant ServiceMix Camel Service Engine}

The ServiceMix-camel-mt \ac{JBI} \ac{SE} provides integration support between the Camel router, and the \ac{JBI} environment. This \ac{SE} includes in its package the \term{camel-core} libraries, in order to interact with the camel endpoints which are by default included in it, e.g. camel-email, camel-jms, camel-http, camel-ftp, etc. Muhler extends in his work this \ac{SE} in order to include multi-tenancy awareness \cite{Muhler2012}. In this subsection we describe the modifications he makes, and the extensions we develop to make it compatible with the requirements of our system. 

The Camel router provides support for describing its routes in two styles: \ac{POJO}, and Spring. The former allow programmers to describe the camel routes in a Java class which extends camel's \term{RouteBuilder} class, while the latter allows the route description in \ac{XML} format. Files which describe the routes are packed in \ac{SU}s, and these in a \ac{SA}. The \term{CamelSpringDeployer} class in ServiceMix-camel-mt implement the necessary methods for extracting the routes for deployment. Muhler extends this class in \term{CamelSpringDeployerMT}, and includes tenant-aware operations for injecting tenant-aware information in the service and endpoint \ac{URI}s. However, the tenant-aware information is not enough in our system, due to requirements specified in Chapter \ref{chap:spec}. Therefore, we extend his work by adding the tenant's user information in the multi-tenant information injected in the \ac{URI}s.

A Camel \ac{JBI} endpoint is identified by the prefix \term{jbi:}, and the endpoints are classified into two types: consumer, and provider. Consumer endpoints receive message exchanges from endpoints exposed in the \ac{NMR}, while providers forward the message exchanges to \ac{JBI} endpoints exposed in the \ac{NMR}, or to external services. The \term{CamelConsumerEndpoint} and \term{CamelProviderEndpoint} classes include the endpoint configuration, and the necessary methods for creating and accepting message exchanges. Hence, we modified them and included multi-tenancy awareness operations which listen to and send messages to multi-tenant aware \ac{JBI} endpoints. 

In the design approach two for \ac{SQL} support described in Chapter \ref{chap:design} we define two Camel \ac{JBI} endpoints for routing requests to the \term{CDASMixjdbc} component: the tentants' \ac{JBI} endpoints, and the \term{JBIToCamelJdbc} endpoint. The former is deployed on ServiceMix-camel-mt, and the latter on ServiceMix-camel. Both routes definitions are packed and deployed in different \ac{SU}s, and \ac{SA}s, due to their deployment on different components. In the \ac{URI} endpoint definition we set the Camel \ac{JBI} option \term{check serialization= nocheck}, which deactivates the serialization checking of objects contained in the property section of the \ac{NMF}. The objects the system sends in the \ac{NMF} properties section implement the interface serializable. Therefore, there is no need of overloading the system with checking operations. The \term{JBIToCamelJdbc} endpoint forwards the messages exchanges to the \term{CDASMixjdbc} camel component (see Listing \ref{lst:jdbcuri}).

%%%%bundle activator
%adds the prefix of the component to the camel context registry
%%%% jdbccdasmix
%component class, endpoint class, short explain
%producer class, contains the logic of retrieving the message, analyzing the data and the meta-data, looking for the data source, if it does not exist, create one. then it conencts to the database and send the properties which were received in the proxy. this is done in a loop for all the queries selected, which must be equal to the number of properties in the vector properties. we send one set of properties per query. remind here that we can get data from different backend data sources, and a multiquerying accepts data from different backend databases. categorizes the queries into two groups, data retrieval and data modification. retrieval always returns a result set with the data in it, but the modification does not get a result set with the data, but it can optionally retrieve the generated keys from the statement. we always retrieve them and send them back to the mysql proxy. if the tenant wanted this, ok, if not, then the mysql proxy does not send this back.
%%%%datasources
%explain which ones we already implement, and that the data source is an interface in order to make it extensible in the future
%explain the jndi, that we use it as a datasource cache/registry
%%%%util
%the constants of the nm headers
%data sources, which are not database sources, but data handlers in order to be able to send the attachment in the message which is provided by camel. this provides the operations of the javax.activation.DataSource, and provide the binary stream of the objects
\subsection{Camel CDASMix JDBC Component}

The Camel CDASMix JDBC component provides support for creating and exchanging requests with external database systems via \ac{JDBC}. We implement the communication support for the following three database systems: MySQL, PostgreSQL, and Oracle. The connections to the databases are established by utilizing its client native drivers via \ac{JDBC}: \term{mysql-connector-java-5.1.22}, \term{postgresql-9.1-901.jdbc3}, and \term{ojdbc14-10.2.0}. These are included in the \ac{OSGi} bundle of the \term{CDASMixjdbc} component, and \term{DataSource} objects are created for establishing the connection with the backend database systems. The \term{CdasmixDataSource} interface is implemented by the three protocol specific datasources: \term{CdasmixMySQLDS}, \term{CdasmixPostgresDS}, and \term{CdasmixOracleDS} (see Figure \ref{fig:cdasmixjdbcclassdiagram}). Therefore, the database specific \term{DataSource} creation is handled in the \term{DataSourceHandler} class, which evaluates the target datasource driver property contained in the \ac{NMF}. This class interacts with the \ac{JNDI} registry of the system for registering, and retrieving the \term{DataSource} instances.

\lstinputlisting[label={lst:jdbcuri},caption={[Route definition for JDBCCDASMix Camel Component]Route definition for JBIToCamelJdbc \ac{JBI} endpoint to JDBCCDASMix Camel Component.},style=xml]{./gfx/jdbccdasmixuri.xml}

This component is developed as a custom camel component, and in the Camel registry its endpoints are identified by the prefix \term{cdasmixjdbc} (see Listing \ref{lst:jdbcuri}). The \ac{OSGi} container allows the redeployment of the component without the need of redeploying the external components which use its libraries. During the activation process of this \ac{OSGi} bundle, an instance of the component is created and registered in the Camel registry. Camel endpoints containing in its \ac{URI} the \term{jdbccdasmix} component create an instance of the \term{JdbcCdasmixComponent} class. The original Camel-jdbc component requires the user to specify the data source name in the endpoint \ac{URI}, and its properties in the bean configuration. However, we do not require the explicit description of the data source in the \ac{URI}, as the component retrieves it from the \ac{NMF}, and creates it dynamically. The \term{JdbcCdasmixEndpoint} class creates an instance of the producer endpoint, the \term{JdbcCdasmixProducer}. The \term{JdbcCdasmixProducer} includes the main logic of the component. When a \ac{NMF} is received in the \term{jdbccdasmix} endpoint, its properties are extracted and analyzed, the connection to the backend database is established, the message is demarshaled, the request on the database system is performed, the response from the database system is marshaled into the \ac{NMF}, and forwarded back to the endpoint which created the exchange. The response's meta-data is stored in the properties section of the \ac{NMF}, while the data is stored in the attachment section of the \ac{NMF}. The storage of attachments in the \ac{NMF} through the Camel \ac{API} requires the storage of the data in a class which implement the \term{javax.activation.DataSource} class. Threfore, we implement two different classes which implement it, and store different data: the data retrieved from the backend database system (when success), or the error messages (when an error occurs). Operations on different backend database systems in one message exchange are considered atomic. If one backend database system answers with an error, the message exchange status is set to error, and forwarded to the endpoint which created the message exchange. 

The support of \ac{JDBC} in a custom component and a unique endpoint \ac{URI} prefix allows the developers to use the existing Camel-jdbc component for their non multi-tenant aware connections. 


%\begin{figure}[htb]
%	\centering
%		\includegraphics[width=.95\textwidth, trim=0.0cm 0.0cm 0.0cm 0.0cm, clip]{./gfx/systemimplementation.pdf}
%	\caption[Implemented and Configured \ac{BC} for integration with Taxi Scenario v2.0]{Implemented and Configured \ac{BC} for integration with Taxi Scenario v2.0 \cite{4CaaSt}, \cite{Muhler2012}.}
%	\label{fig:systemintegrationimpl}
%\end{figure}

 
