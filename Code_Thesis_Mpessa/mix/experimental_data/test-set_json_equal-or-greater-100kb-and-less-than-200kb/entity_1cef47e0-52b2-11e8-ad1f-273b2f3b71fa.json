{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=15532",
  "eid" : "1cef47e0-52b2-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778557790,
  "textBody" : "In mathematics, an integral assigns numbers to functions in a way that can describe displacement, area, volume, and other concepts that arise by combining infinitesimal data. Integration is one of the two main operations of calculus, with its inverse, differentiation, being the other. Given a function  of a real variable  and an interval  of the real line, the definite integral\n\n\\int_a^b \\! f(x)\\,dx\n\nis defined informally as the signed area of the region in the -plane that is bounded by the graph of , the -axis and the vertical lines  and . The area above the -axis adds to the total and that below the -axis subtracts from the total.\n\nRoughly speaking, the operation of integration is the reverse of differentiation. For this reason, the term integral may also refer to the related notion of the antiderivative, a function  whose derivative is the given function . In this case, it is called an indefinite integral and is written:\nF(x) = \\int f(x)\\,dx.\n\nThe integrals discussed in this article are those termed definite integrals. It is the fundamental theorem of calculus that connects differentiation with the definite integral: if  is a continuous real-valued function defined on a closed interval , then, once an antiderivative  of  is known, the definite integral of  over that interval is given by\n\n\\int_a^b f(x) dx \\left[ F(x) \\right]_{a}^{b} \n F(b) - F(a) \\, .\n\nThe principles of integration were formulated independently by Isaac Newton and Gottfried Leibniz in the late 17th century, who thought of the integral as an infinite sum of rectangles of infinitesimal width. Bernhard Riemann gave a rigorous mathematical definition of integrals. It is based on a limiting procedure that approximates the area of a curvilinear region by breaking the region into thin vertical slabs. Beginning in the nineteenth century, more sophisticated notions of integrals began to appear, where the type of the function as well as the domain over which the integration is performed has been generalised. A line integral is defined for functions of two or three variables, and the interval of integration  is replaced by a certain curve connecting two points on the plane or in the space. In a surface integral, the curve is replaced by a piece of a surface in the three-dimensional space.\n\nHistory\n\nPre-calculus integration\n\nThe first documented systematic technique capable of determining integrals is the method of exhaustion of the ancient Greek astronomer Eudoxus (ca. 370 BC), which sought to find areas and volumes by breaking them up into an infinite number of divisions for which the area or volume was known. This method was further developed and employed by Archimedes in the 3rd century BC and used to calculate areas for parabolas and an approximation to the area of a circle.\n\nA similar method was independently developed in China around the 3rd century AD by Liu Hui, who used it to find the area of the circle. This method was later used in the 5th century by Chinese father-and-son mathematicians Zu Chongzhi and Zu Geng to find the volume of a sphere (; ).\n\nThe next significant advances in integral calculus did not begin to appear until the 17th century. At this time, the work of Cavalieri with his method of Indivisibles, and work by Fermat, began to lay the foundations of modern calculus, with Cavalieri computing the integrals of  up to degree  in Cavalieri's quadrature formula. Further steps were made in the early 17th century by Barrow and Torricelli, who provided the first hints of a connection between integration and differentiation. Barrow provided the first proof of the fundamental theorem of calculus. Wallis generalized Cavalieri's method, computing integrals of  to a general power, including negative powers and fractional powers.\n\nNewton and Leibniz\n\nThe major advance in integration came in the 17th century with the independent discovery of the fundamental theorem of calculus by Newton and Leibniz. The theorem demonstrates a connection between integration and differentiation. This connection, combined with the comparative ease of differentiation, can be exploited to calculate integrals. In particular, the fundamental theorem of calculus allows one to solve a much broader class of problems. Equal in importance is the comprehensive mathematical framework that both Newton and Leibniz developed. Given the name infinitesimal calculus, it allowed for precise analysis of functions within continuous domains. This framework eventually became modern calculus, whose notation for integrals is drawn directly from the work of Leibniz.\n\nFormalization\n\nWhile Newton and Leibniz provided a systematic approach to integration, their work lacked a degree of rigour. Bishop Berkeley memorably attacked the vanishing increments used by Newton, calling them \"ghosts of departed quantities\". Calculus acquired a firmer footing with the development of limits. Integration was first rigorously formalized, using limits, by Riemann. Although all bounded piecewise continuous functions are Riemann-integrable on a bounded interval, subsequently more general functions were considered—particularly in the context of Fourier analysis—to which Riemann's definition does not apply, and Lebesgue formulated a different definition of integral, founded in measure theory (a subfield of real analysis). Other definitions of integral, extending Riemann's and Lebesgue's approaches, were proposed. These approaches based on the real number system are the ones most common today, but alternative approaches exist, such as a definition of integral as the standard part of an infinite Riemann sum, based on the hyperreal number system.\n\nHistorical notation\n\nIsaac Newton used a small vertical bar above a variable to indicate integration, or placed the variable inside a box. The vertical bar was easily confused with  or , which are used to indicate differentiation, and the box notation was difficult for printers to reproduce, so these notations were not widely adopted.\n\nThe modern notation for the indefinite integral was introduced by Gottfried Leibniz in 1675 (; ). He adapted the integral symbol, ∫, from the letter ſ (long s), standing for summa (written as ſumma; Latin for \"sum\" or \"total\"). The modern notation for the definite integral, with limits above and below the integral sign, was first used by Joseph Fourier in Mémoires of the French Academy around 1819–20, reprinted in his book of 1822 (; ).\n\nApplications\n\nIntegrals are used extensively in many areas of mathematics as well as in many other areas that rely on mathematics.\n\nFor example, in probability theory, integrals are used to determine the probability of some random variable falling within a certain range. Moreover, the integral under an entire probability density function must equal 1, which provides a test of whether a function with no negative values could be a density function or not.\n\nIntegrals can be used for computing the area of a two-dimensional region that has a curved boundary, as well as computing the volume of a three-dimensional object that has a curved boundary.\n\nIntegrals are also used in physics, in areas like kinematics to find quantities like displacement, time, and velocity. For example, in rectilinear motion, the displacement of an object over the time interval [a,b] is given by: \n\nx(b)-x(a) = \\int_a^b v(t) \\,dt,\n\nwhere v(t) is the velocity expressed as a function of time. The work done by a force F(x) (given as a function of position) from an initial position A to a final position B is:\n\nW_{A\\rightarrow B} = \\int_A^B F(x)\\,dx.\n\nTerminology and notation\n\nStandard\n\nThe integral with respect to  of a real-valued function  of a real variable  on the interval  is written as\n\n\\displaystyle \\int_a^b f(x)\\,dx.\n\nThe integral sign  represents integration. The symbol , called the differential of the variable , indicates that the variable of integration is . The function  to be integrated is called the integrand. The symbol  is separated from the integrand by a space (as shown). If a function has an integral, it is said to be integrable. The points  and  are called the limits of the integral. An integral where the limits are specified is called a definite integral. The integral is said to be over the interval .\n\nIf the integral goes from a finite value a to the upper limit infinity, the integral expresses the limit of the integral from a to a value b as b goes to infinity. If the value of the integral gets closer and closer to a finite value, the integral is said to converge to that value. If not, the integral is said to diverge.\n\nWhen the limits are omitted, as in\n\\int f(x) \\,dx,\nthe integral is called an indefinite integral, which represents a class of functions (the antiderivative) whose derivative is the integrand. The fundamental theorem of calculus relates the evaluation of definite integrals to indefinite integrals. Occasionally, limits of integration are omitted for definite integrals when the same limits occur repeatedly in a particular context. Usually, the author will make this convention clear at the beginning of the relevant text.\n\nThere are several extensions of the notation for integrals to encompass integration on unbounded domains and/or in multiple dimensions (see later sections of this article).\n\nMeaning of the symbol dx \n\nHistorically, the symbol dx was taken to represent an infinitesimally \"small piece\" of the independent variable x to be multiplied by the integrand and summed up in an infinite sense. While this notion is still heuristically useful, later mathematicians have deemed infinitesimal quantities to be untenable from the standpoint of the real number system.In the 20th century, nonstandard analysis was developed as a new approach to calculus that incorporates a rigorous concept of infinitesimals by using an expanded number system called the hyperreal numbers. Though placed on a sound axiomatic footing and of interest in its own right as a new area of investigation, nonstandard analysis remains somewhat controversial from a pedagogical standpoint, with proponents pointing out the intuitive nature of infinitesimals for beginning students of calculus and opponents criticizing the logical complexity of the system as a whole. In introductory calculus, the expression dx is therefore not assigned an independent meaning; instead, it is viewed as part of the symbol for integration and serves as its delimiter on the right side of the expression being integrated. \n\nIn more sophisticated contexts, dx can have its own significance, the meaning of which depending on the particular area of mathematics being discussed. When used in one of these ways, the original Leibnitz notation is co-opted to apply to a generalization of the original definition of the integral. Some common interpretations of dx include: an integrator function in Riemann-Stieltjes integration (indicated by dα(x) in general), a measure in Lebesgue theory (indicated by dμ in general), or a differential form in exterior calculus (indicated by dx^{i_1}\\wedge\\cdots\\wedge dx^{i_k} in general). In the last case, even the letter d has an independent meaning — as the exterior derivative operator on differential forms.\n\nConversely, in advanced settings, it is not uncommon to leave out dx when only the simple Riemann integral is being used, or the exact type of integral is immaterial. For instance, one might write \\int_a^b (c_1f+c_2g) \n c_1\\int_a^b f + c_2\\int_a^b g  to express the linearity of the integral, a property shared by the Riemann integral and all generalizations thereof.\n\nVariants\n\nIn modern Arabic mathematical notation, a reflected integral symbol  is used instead of the symbol , since the Arabic script and mathematical expressions go right to left.. Some authors, particularly of European origin, use an upright \"d\" to indicate the variable of integration (i.e.,  instead of ), since properly speaking, \"d\" is not a variable. Also, the symbol  is not always placed after , as for instance in\n\\int\\limits_0^1 \\frac{3\\ dx}{x^2+1}\\quad or \\quad\\int_{0}^{1} dx \\int_{0}^{1} dy\\ e^{-(x^2+y^2)} .\nIn the first expression, the differential is treated as an infinitesimal \"multiplicative\" factor, formally following a \"commutative property\" when \"multiplied\" by the expression 3/(x2+1). In the second expression, showing the differentials first highlights and clarifies the variables that are being integrated with respect to, a practice particularly popular with physicists.\n\nInterpretations of the integral\n\nIntegrals appear in many practical situations. If a swimming pool is rectangular with a flat bottom, then from its length, width, and depth we can easily determine the volume of water it can contain (to fill it), the area of its surface (to cover it), and the length of its edge (to rope it). But if it is oval with a rounded bottom, all of these quantities call for integrals. Practical approximations may suffice for such trivial examples, but precision engineering (of any discipline) requires exact and rigorous values for these elements.\n\nTo start off, consider the curve  between  and  with  (see figure). We ask:\nWhat is the area under the function , in the interval from 0 to 1?\nand call this (yet unknown) area the (definite) integral of . The notation for this integral will be\n\\int_0^1 \\sqrt{x}\\ dx.\n\nAs a first approximation, look at the unit square given by the sides  to  and  and . Its area is exactly 1. Actually, the true value of the integral must be somewhat less than 1. Decreasing the width of the approximation rectangles and increasing the number of rectangles gives a better result; so cross the interval in five steps, using the approximation points 0, 1/5, 2/5, and so on to 1. Fit a box for each step using the right end height of each curve piece, thus , , and so on to . Summing the areas of these rectangles, we get a better approximation for the sought integral, namely\n\\textstyle \\sqrt{\\frac{1}{5}}\\left(\\frac{1}{5}-0\\right)+\\sqrt{\\frac{2}{5}}\\left(\\frac{2}{5}-\\frac{1}{5}\\right)+\\cdots+\\sqrt{\\frac{5}{5}}\\left(\\frac{5}{5}-\\frac{4}{5}\\right)\\approx 0.7497.\n\nWe are taking a sum of finitely many function values of , multiplied with the differences of two subsequent approximation points. We can easily see that the approximation is still too large. Using more steps produces a closer approximation, but will always be too high and will never be exact. Alternatively, replacing these subintervals by ones with the left end height of each piece, we will get an approximation that is too low: for example, with twelve such subintervals we will get an approximate value for the area of 0.6203. \n\nThe key idea is the transition from adding finitely many differences of approximation points multiplied by their respective function values to using infinitely many fine, or infinitesimal steps. When this transition is completed in the above example, it turns out that the area under the curve within the stated bounds is 2/3.\n\nThe notation\n\\int f(x)\\ dx\nconceives the integral as a weighted sum, denoted by the elongated , of function values, , multiplied by infinitesimal step widths, the so-called differentials, denoted by .\n\nHistorically, after the failure of early efforts to rigorously interpret infinitesimals, Riemann formally defined integrals as a limit of weighted sums, so that the  suggested the limit of a difference (namely, the interval width). Shortcomings of Riemann's dependence on intervals and continuity motivated newer definitions, especially the Lebesgue integral, which is founded on an ability to extend the idea of \"measure\" in much more flexible ways. Thus the notation\n\\int_A f(x)\\ d\\mu\nrefers to a weighted sum in which the function values are partitioned, with  measuring the weight to be assigned to each value. Here  denotes the region of integration.\n\nFormal definitions\n\nThere are many ways of formally defining an integral, not all of which are equivalent. The differences exist mostly to deal with differing special cases which may not be integrable under other definitions, but also occasionally for pedagogical reasons. The most commonly used definitions of integral are Riemann integrals and Lebesgue integrals.\n\nRiemann integral\n\nThe Riemann integral is defined in terms of Riemann sums of functions with respect to tagged partitions of an interval. Let  be a closed interval of the real line; then a tagged partition of  is a finite sequence\n\n a x_0 \\le t_1 \\le x_1 \\le t_2 \\le x_2 \\le \\cdots \\le x_{n-1} \\le t_n \\le x_n \n b . \\,\\!\n\nThis partitions the interval  into  sub-intervals  indexed by , each of which is \"tagged\" with a distinguished point . A Riemann sum of a function  with respect to such a tagged partition is defined as\n\\sum_{i=1}^{n} f(t_i) \\Delta_i ; \nthus each term of the sum is the area of a rectangle with height equal to the function value at the distinguished point of the given sub-interval, and width the same as the sub-interval width. Let  be the width of sub-interval ; then the mesh of such a tagged partition is the width of the largest sub-interval formed by the partition, . The Riemann integral of a function  over the interval  is equal to  if:\nFor all  there exists  such that, for any tagged partition  with mesh less than , we have\n:\\left| S - \\sum_{i=1}^{n} f(t_i)\\Delta_i \\right| \nWhen the chosen tags give the maximum (respectively, minimum) value of each interval, the Riemann sum becomes an upper (respectively, lower) Darboux sum, suggesting the close connection between the Riemann integral and the Darboux integral.\n\nLebesgue integral\n\nIt is often of interest, both in theory and applications, to be able to pass to the limit under the integral. For instance, a sequence of functions can frequently be constructed that approximate, in a suitable sense, the solution to a problem. Then the integral of the solution function should be the limit of the integrals of the approximations. However, many functions that can be obtained as limits are not Riemann-integrable, and so such limit theorems do not hold with the Riemann integral. Therefore, it is of great importance to have a definition of the integral that allows a wider class of functions to be integrated .\n\nSuch an integral is the Lebesgue integral, that exploits the following fact to enlarge the class of integrable functions: if the values of a function are rearranged over the domain, the integral of a function should remain the same. Thus Henri Lebesgue introduced the integral bearing his name, explaining this integral thus in a letter to Paul Montel:\n\nAs  puts it, \"To compute the Riemann integral of , one partitions the domain  into subintervals\", while in the Lebesgue integral, \"one is in effect partitioning the range of \". The definition of the Lebesgue integral thus begins with a measure, μ. In the simplest case, the Lebesgue measure  of an interval  is its width, , so that the Lebesgue integral agrees with the (proper) Riemann integral when both exist. In more complicated cases, the sets being measured can be highly fragmented, with no continuity and no resemblance to intervals.\n\nUsing the \"partitioning the range of \" philosophy, the integral of a non-negative function  should be the sum over  of the areas between a thin horizontal strip between  and . This area is just . Let }. The Lebesgue integral of  is then defined by \n\\int f = \\int_0^\\infty f^*(t)\\,dt\nwhere the integral on the right is an ordinary improper Riemann integral ( is a strictly decreasing positive function, and therefore has a well-defined improper Riemann integral). For a suitable class of functions (the measurable functions) this defines the Lebesgue integral.\n\nA general measurable function  is Lebesgue-integrable if the sum of the absolute values of the areas of the regions between the graph of  and the -axis is finite:\n\\int_E |f|\\,d\\mu \nIn that case, the integral is, as in the Riemannian case, the difference between the area above the -axis and the area below the -axis:\n\\int_E f \\,d\\mu = \\int_E f^+ \\,d\\mu - \\int_E f^- \\,d\\mu\nwhere\n\\begin{alignat}{3}\n & f^+(x) &&{}{} \\max \\{f(x),0\\} &&{}\n{} \\begin{cases}\n               f(x), & \\text{if } f(x) > 0, \\\\\n               0, & \\text{otherwise,}\n             \\end{cases}\\\\\n & f^-(x) &&{}{} \\max \\{-f(x),0\\} &&{}\n{} \\begin{cases}\n               -f(x), & \\text{if } f(x) \n\nOther integrals\n\nAlthough the Riemann and Lebesgue integrals are the most widely used definitions of the integral, a number of others exist, including:\n* The Darboux integral, which is constructed using Darboux sums and is equivalent to a Riemann integral, meaning that a function is Darboux-integrable if and only if it is Riemann-integrable. Darboux integrals have the advantage of being simpler to define than Riemann integrals.\n* The Riemann–Stieltjes integral, an extension of the Riemann integral.\n* The Lebesgue–Stieltjes integral, further developed by Johann Radon, which generalizes the Riemann–Stieltjes and Lebesgue integrals.\n* The Daniell integral, which subsumes the Lebesgue integral and Lebesgue–Stieltjes integral without the dependence on measures.\n* The Haar integral, used for integration on locally compact topological groups, introduced by Alfréd Haar in 1933.\n* The Henstock–Kurzweil integral, variously defined by Arnaud Denjoy, Oskar Perron, and (most elegantly, as the gauge integral) Jaroslav Kurzweil, and developed by Ralph Henstock.\n* The Itô integral and Stratonovich integral, which define integration with respect to semimartingales such as Brownian motion.\n\n* The Young integral, which is a kind of Riemann–Stieltjes integral with respect to certain functions of unbounded variation.\n* The rough path integral, which is defined for functions equipped with some additional \"rough path\" structure and generalizes stochastic integration against both semimartingales and processes such as the fractional Brownian motion.\n\nProperties\n\nLinearity\n\nThe collection of Riemann-integrable functions on a closed interval  forms a vector space under the operations of pointwise addition and multiplication by a scalar, and the operation of integration\n f \\mapsto \\int_a^b f(x) \\; dx\n\nis a linear functional on this vector space. Thus, firstly, the collection of integrable functions is closed under taking linear combinations; and, secondly, the integral of a linear combination is the linear combination of the integrals,\n\n \\int_a^b (\\alpha f + \\beta g)(x) \\, dx = \\alpha \\int_a^b f(x) \\,dx + \\beta \\int_a^b g(x) \\, dx. \\,\n\nSimilarly, the set of real-valued Lebesgue-integrable functions on a given measure space  with measure  is closed under taking linear combinations and hence form a vector space, and the Lebesgue integral\n\n f\\mapsto \\int_E f \\, d\\mu \n\nis a linear functional on this vector space, so that\n\n \\int_E (\\alpha f + \\beta g) \\, d\\mu = \\alpha \\int_E f \\, d\\mu + \\beta \\int_E g \\, d\\mu. \n\nMore generally, consider the vector space of all measurable functions on a measure space , taking values in a locally compact complete topological vector space  over a locally compact topological field . Then one may define an abstract integration map assigning to each function  an element of  or the symbol ,\n f\\mapsto\\int_E f \\,d\\mu, \\,\nthat is compatible with linear combinations. In this situation, the linearity holds for the subspace of functions whose integral is an element of  (i.e. \"finite\"). The most important special cases arise when  is , , or a finite extension of the field  of p-adic numbers, and  is a finite-dimensional vector space over , and when  and  is a complex Hilbert space.\n\nLinearity, together with some natural continuity properties and normalisation for a certain class of \"simple\" functions, may be used to give an alternative definition of the integral. This is the approach of Daniell for the case of real-valued functions on a set , generalized by Nicolas Bourbaki to functions with values in a locally compact topological vector space. See  for an axiomatic characterisation of the integral.\n\nInequalities\n\nA number of general inequalities hold for Riemann-integrable functions defined on a closed and bounded interval  and can be generalized to other notions of integral (Lebesgue and Daniell).\n\n* Upper and lower bounds. An integrable function  on , is necessarily bounded on that interval. Thus there are real numbers  and  so that  for all  in . Since the lower and upper sums of  over  are therefore bounded by, respectively,  and , it follows that\n:  m(b - a) \\leq \\int_a^b f(x) \\, dx \\leq M(b - a). \n\n* Inequalities between functions. If  for each  in  then each of the upper and lower sums of  is bounded above by the upper and lower sums, respectively, of . Thus\n:  \\int_a^b f(x) \\, dx \\leq \\int_a^b g(x) \\, dx. \nThis is a generalization of the above inequalities, as  is the integral of the constant function with value  over .\nIn addition, if the inequality between functions is strict, then the inequality between integrals is also strict. That is, if  for each  in , then\n:  \\int_a^b f(x) \\, dx \n\n* Subintervals. If  is a subinterval of  and  is non-negative for all , then\n:  \\int_c^d f(x) \\, dx \\leq \\int_a^b f(x) \\, dx. \n\n* Products and absolute values of functions. If  and  are two functions, then we may consider their pointwise products and powers, and absolute values:\n: \n (fg)(x)f(x) g(x), \\; f^2 (x) \n (f(x))^2, \\; |f| (x) = |f(x)|.\\,\nIf  is Riemann-integrable on  then the same is true for , and\n: \\left| \\int_a^b f(x) \\, dx \\right| \\leq \\int_a^b | f(x) | \\, dx. \nMoreover, if  and  are both Riemann-integrable then  is also Riemann-integrable, and\n: \\left( \\int_a^b (fg)(x) \\, dx \\right)^2 \\leq \\left( \\int_a^b f(x)^2 \\, dx \\right) \\left( \\int_a^b g(x)^2 \\, dx \\right). \nThis inequality, known as the Cauchy–Schwarz inequality, plays a prominent role in Hilbert space theory, where the left hand side is interpreted as the inner product of two square-integrable functions  and  on the interval .\n\n* Hölder's inequality. Suppose that  and  are two real numbers,  with , and   and  are two Riemann-integrable functions. Then the functions   and  are also integrable and the following Hölder's inequality holds:\n:\\left|\\int f(x)g(x)\\,dx\\right| \\leq\n\\left(\\int \\left|f(x)\\right|^p\\,dx \\right)^{1/p} \\left(\\int\\left|g(x)\\right|^q\\,dx\\right)^{1/q}.\nFor   \n 2, Hölder's inequality becomes the Cauchy–Schwarz inequality.\n\n* Minkowski inequality. Suppose that  is a real number and  and  are Riemann-integrable functions. Then  and  are also Riemann-integrable and the following Minkowski inequality holds:\n:\\left(\\int \\left|f(x)+g(x)\\right|^p\\,dx \\right)^{1/p} \\leq\n\\left(\\int \\left|f(x)\\right|^p\\,dx \\right)^{1/p} +\n\\left(\\int \\left|g(x)\\right|^p\\,dx \\right)^{1/p}.\nAn analogue of this inequality for Lebesgue integral is used in construction of Lp spaces.\n\nConventions\n\nIn this section,  is a real-valued Riemann-integrable function. The integral\n \\int_a^b f(x) \\, dx \nover an interval  is defined if . This means that the upper and lower sums of the function  are evaluated on a partition  whose values  are increasing. Geometrically, this signifies that integration takes place \"left to right\", evaluating  within intervals  where an interval with a higher index lies to the right of one with a lower index. The values  and , the end-points of the interval, are called the limits of integration of . Integrals can also be defined if :\n\n* Reversing limits of integration. If  then define\n: \\int_a^b f(x) \\, dx = - \\int_b^a f(x) \\, dx. \nThis, with , implies:\n* Integrals over intervals of length zero. If  is a real number then\n: \\int_a^a f(x) \\, dx = 0. \n\nThe first convention is necessary in consideration of taking integrals over subintervals of ; the second says that an integral taken over a degenerate interval, or a point, should be zero. One reason for the first convention is that the integrability of  on an interval  implies that  is integrable on any subinterval , but in particular integrals have the property that:\n\n* Additivity of integration on intervals. If  is any element of , then\n:  \\int_a^b f(x) \\, dx = \\int_a^c f(x) \\, dx + \\int_c^b f(x) \\, dx.\nWith the first convention, the resulting relation\n\\begin{align}\n \\int_a^c f(x) \\, dx &{}= \\int_a^b f(x) \\, dx - \\int_c^b f(x) \\, dx \\\\\n &{} = \\int_a^b f(x) \\, dx + \\int_b^c f(x) \\, dx\n\\end{align}\nis then well-defined for any cyclic permutation of , , and .\n\nFundamental theorem of calculus\n\nThe fundamental theorem of calculus is the statement that differentiation and integration are inverse operations: if a continuous function is first integrated and then differentiated, the original function is retrieved. An important consequence, sometimes called the second fundamental theorem of calculus, allows one to compute integrals by using an antiderivative of the function to be integrated.\n\nStatements of theorems\n\nFundamental theorem of calculus\n\nLet  be a continuous real-valued function defined on a closed interval . Let  be the function defined, for all  in , by\nF(x) = \\int_a^x f(t)\\, dt.\nThen,  is continuous on , differentiable on the open interval , and\n\nF'(x) = f(x)\n\nfor all  in .\n\nSecond fundamental theorem of calculus\n\nLet  be a real-valued function defined on a closed interval [] that admits an antiderivative  on . That is,  and  are functions such that for all  in ,\n\nf(x) = F'(x).\n\nIf  is integrable on  then\n\n\\int_a^b f(x)\\,dx = F(b) - F(a).\n\nCalculating integrals\n\nThe second fundamental theorem allows many integrals to be calculated explicitly. For example, to calculate the integral\n\\int_0^1x^{1/2}\\,dx,\nof the square root function  between 0 and 1, it is sufficient to find an antiderivative, that is, a function  whose derivative equals  :\nF'(x)=f(x).\nOne such function is . Then the value of the integral in question is\n\\int_0^1x^{1/2}\\,dx F(1) - F(0) \n \\frac{2}{3} (1)^{3/2} - \\frac{2}{3} (0)^{3/2}=\\frac{2}{3}.\n\nThis is a case of a general rule, that for , with , the related function, the so-called antiderivative is  Tables of this and similar antiderivatives can be used to calculate integrals explicitly, in much the same way that tables of derivatives can be used.\n\nExtensions\n\nImproper integrals\n\nA \"proper\" Riemann integral assumes the integrand is defined and finite on a closed and bounded interval, bracketed by the limits of integration. An improper integral occurs when one or more of these conditions is not satisfied. In some cases such integrals may be defined by considering the limit of a sequence of proper Riemann integrals on progressively larger intervals.\n\nIf the interval is unbounded, for instance at its upper end, then the improper integral is the limit as that endpoint goes to infinity.\n\\int_{a}^{\\infty} f(x)\\,dx = \\lim_{b \\to \\infty} \\int_{a}^{b} f(x)\\,dx\nIf the integrand is only defined or finite on a half-open interval, for instance , then again a limit may provide a finite result.\n\\int_{a}^{b} f(x)\\,dx = \\lim_{\\epsilon \\to 0} \\int_{a+\\epsilon}^{b} f(x)\\,dx\n\nThat is, the improper integral is the limit of proper integrals as one endpoint of the interval of integration approaches either a specified real number, or , or . In more complicated cases, limits are required at both endpoints, or at interior points.\n\nMultiple integration\n\nJust as the definite integral of a positive function of one variable represents the area of the region between the graph of the function and the x-axis, the double integral of a positive function of two variables represents the volume of the region between the surface defined by the function and the plane that contains its domain. For example, a function in two dimensions depends on two real variables, x and y, and the integral of a function f over the rectangle R given as the Cartesian product of two intervals R=[a,b]\\times [c,d] can be written\n\n\\int_R f(x,y)\\,dA\n\nwhere the differential  indicates that integration is taken with respect to area. This double integral can be defined using Riemann sums, and represents the (signed) volume under the graph of  over the domain R. Under suitable conditions (e.g., if f is continuous), then Fubini's theorem guarantees that this integral can be expressed as an equivalent iterated integral\n\n\\int_a^b\\left[\\int_c^d f(x,y)\\,dy\\right]\\,dx.\n\nThis reduces the problem of computing a double integral to computing one-dimensional integrals. Because of this, another notation for the integral over R uses a double integral sign:\n\\iint_R f(x,y) dA.\n\nIntegration over more general domains is possible. The integral of a function f, with respect to volume, over a subset D of  ℝn is denoted by notation such as\n\n\\int_D f(\\mathbf x)d^n\\mathbf x,\\quad \\int_D f\\,dV\n\nor similar. See volume integral.\n\nLine integrals\n\nThe concept of an integral can be extended to more general domains of integration, such as curved lines and surfaces. Such integrals are known as line integrals and surface integrals respectively. These have important applications in physics, as when dealing with vector fields.\n\nA line integral (sometimes called a path integral) is an integral where the function to be integrated is evaluated along a curve. Various different line integrals are in use. In the case of a closed curve it is also called a contour integral.\n\nThe function to be integrated may be a scalar field or a vector field. The value of the line integral is the sum of values of the field at all points on the curve, weighted by some scalar function on the curve (commonly arc length or, for a vector field, the scalar product of the vector field with a differential vector in the curve). This weighting distinguishes the line integral from simpler integrals defined on intervals. Many simple formulas in physics have natural continuous analogs in terms of line integrals; for example, the fact that work is equal to force, , multiplied by displacement, , may be expressed (in terms of vector quantities) as:\nW=\\mathbf F\\cdot\\mathbf s.\nFor an object moving along a path  in a vector field  such as an electric field or gravitational field, the total work done by the field on the object is obtained by summing up the differential work done in moving from  to . This gives the line integral\nW=\\int_C \\mathbf F\\cdot d\\mathbf s.\n\nSurface integrals\n\nA surface integral is a definite integral taken over a surface (which may be a curved set in space); it can be thought of as the double integral analog of the line integral. The function to be integrated may be a scalar field or a vector field. The value of the surface integral is the sum of the field at all points on the surface. This can be achieved by splitting the surface into surface elements, which provide the partitioning for Riemann sums.\n\nFor an example of applications of surface integrals, consider a vector field  on a surface ; that is, for each point  in ,  is a vector. Imagine that we have a fluid flowing through , such that  determines the velocity of the fluid at . The flux is defined as the quantity of fluid flowing through  in unit amount of time. To find the flux, we need to take the dot product of  with the unit surface normal to  at each point, which will give us a scalar field, which we integrate over the surface:\n\\int_S {\\mathbf v}\\cdot \\,d{\\mathbf {S}}.\nThe fluid flux in this example may be from a physical fluid such as water or air, or from electrical or magnetic flux. Thus surface integrals have applications in physics, particularly with the classical theory of electromagnetism.\n\nContour integrals\n\nIn complex analysis, the integrand is a complex-valued function of a complex variable  instead of a real function of a real variable . When a complex function is integrated along a curve \\gamma in the complex plane, the integral is denoted as follows\n\n\\int_{\\gamma} f(z)\\,dz.\n\nThis is known as a contour integral.\n\nIntegrals of differential forms\n\nA differential form is a mathematical concept in the fields of multivariable calculus, differential topology, and tensors. Differential forms are organized by degree. For example, a one-form is a weighted sum of the differentials of the coordinates, such as:\nE(x,y,z)\\,dx + F(x,y,z)\\,dy + G(x,y,z)\\, dz\nwhere E, F, G are functions in three dimensions. A differential one-form can be integrated over an oriented path, and the resulting integral is just another way of writing a line integral. Here the basic differentials dx, dy, dz measure infinitesimal oriented lengths parallel to the three coordinate axes.\n\nA differential two-form is a sum of the form\nG(x,y,z)dx\\wedge dy + E(x,y,z)dy\\wedge dz + F(x,y,z)dz\\wedge dx.\nHere the basic two-forms dx\\wedge dy, dz\\wedge dx, dy\\wedge dz measure oriented areas parallel to the coordinate two-planes. The symbol \\wedge denotes the wedge product, which is similar to the cross product in the sense that the wedge product of two forms representing oriented lengths represents an oriented area. A two-form can be integrated over an oriented surface, and the resulting integral is equivalent to the surface integral giving the flux of E\\mathbf i+F\\mathbf j+G\\mathbf k.\n\nUnlike the cross product, and the three-dimensional vector calculus, the wedge product and the calculus of differential forms makes sense in arbitrary dimension and on more general manifolds (curves, surfaces, and their higher-dimensional analogs). The exterior derivative plays the role of the gradient and curl of vector calculus, and Stokes' theorem simultaneously generalizes the three theorems of vector calculus: the divergence theorem, Green's theorem, and the Kelvin-Stokes theorem.\n\nSummations\n\nThe discrete equivalent of integration is summation. Summations and integrals can be put on the same foundations using the theory of Lebesgue integrals or time scale calculus.\n\nComputation\n\nAnalytical\n\nThe most basic technique for computing definite integrals of one real variable is based on the fundamental theorem of calculus. Let  be the function of  to be integrated over a given interval . Then, find an antiderivative of ; that is, a function  such that  on the interval. Provided the integrand and integral have no singularities on the path of integration, by the fundamental theorem of calculus,\n\n\\int_a^b f(x)\\,dx=F(b)-F(a).\n\nThe integral is not actually the antiderivative, but the fundamental theorem provides a way to use antiderivatives to evaluate definite integrals.\n\nThe most difficult step is usually to find the antiderivative of . It is rarely possible to glance at a function and write down its antiderivative. More often, it is necessary to use one of the many techniques that have been developed to evaluate integrals. Most of these techniques rewrite one integral as a different one which is hopefully more tractable. Techniques include:\n* Integration by substitution\n* Integration by parts\n* Inverse function integration\n* Changing the order of integration\n* Integration by trigonometric substitution\n* Tangent half-angle substitution\n* Integration by partial fractions\n* Integration by reduction formulae\n* Integration using parametric derivatives\n* Integration using Euler's formula\n* Euler substitution\n* Differentiation under the integral sign\n* Contour integration\nAlternative methods exist to compute more complex integrals. Many nonelementary integrals can be expanded in a Taylor series and integrated term by term. Occasionally, the resulting infinite series can be summed analytically. The method of convolution using Meijer G-functions can also be used, assuming that the integrand can be written as a product of Meijer G-functions. There are also many less common ways of calculating definite integrals; for instance, Parseval's identity can be used to transform an integral over a rectangular region into an infinite sum. Occasionally, an integral can be evaluated by a trick; for an example of this, see Gaussian integral.\n\nComputations of volumes of solids of revolution can usually be done with disk integration or shell integration.\n\nSpecific results which have been worked out by various techniques are collected in the list of integrals.\n\nSymbolic\n\nMany problems in mathematics, physics, and engineering involve integration where an explicit formula for the integral is desired. Extensive tables of integrals have been compiled and published over the years for this purpose. With the spread of computers, many professionals, educators, and students have turned to computer algebra systems that are specifically designed to perform difficult or tedious tasks, including integration. Symbolic integration has been one of the motivations for the development of the first such systems, like Macsyma.\n\nA major mathematical difficulty in symbolic integration is that in many cases, a closed formula for the antiderivative of a rather simple-looking function does not exist. For instance, it is known that the antiderivatives of the functions  and  cannot be expressed in the closed form involving only rational and exponential functions, logarithm, trigonometric functions and inverse trigonometric functions, and the operations of multiplication and composition; in other words, none of the three given functions is integrable in elementary functions, which are the functions which may be built from  rational functions, roots of a polynomial, logarithm, and exponential functions. The Risch algorithm provides a general criterion to determine whether the antiderivative of an elementary function is elementary, and, if it is, to compute it. Unfortunately, it turns out that functions with closed expressions of antiderivatives are the exception rather than the rule. Consequently, computerized algebra systems have no hope of being able to find an antiderivative for a randomly constructed elementary function. On the positive side, if the 'building blocks' for antiderivatives are fixed in advance, it may be still be possible to decide whether the antiderivative of a given function can be expressed using these blocks and operations of multiplication and composition, and to find the symbolic answer whenever it exists. The Risch algorithm, implemented in Mathematica and other computer algebra systems, does just that for functions and antiderivatives built from  rational functions, radicals, logarithm, and exponential functions.\n\nSome special integrands occur often enough to warrant special study. In particular, it may be useful to have, in the set of antiderivatives, the special functions (like the Legendre functions, the hypergeometric function, the gamma function, the incomplete gamma function and so on — see Symbolic integration for more details). Extending the Risch's algorithm to include such functions is possible but challenging and has been an active research subject.\n\nMore recently a new approach has emerged, using D-finite functions, which are the solutions of linear differential equations with polynomial coefficients. Most of the elementary and special functions are D-finite, and the integral of a D-finite function is also a D-finite function. This provides an algorithm to express the antiderivative of a D-finite function as the solution of a differential equation.\n\nThis theory also allows one to compute the definite integral of a D-function as the sum of a series given by the first coefficients, and provides an algorithm to compute any coefficient.[http://algo.inria.fr/chyzak/mgfun.html Frédéric Chyzak's Mgfun Project: Introduction to the Package Mgfun and Related Packages]\n\nNumerical\n\nSome integrals found in real applications can be computed by closed-form antiderivatives. Others are not so accommodating. Some antiderivatives do not have closed forms, some closed forms require special functions that themselves are a challenge to compute, and others are so complex that finding the exact answer is too slow. This motivates the study and application of numerical approximations of integrals. This subject, called numerical integration or numerical quadrature, arose early in the study of integration for the purpose of making hand calculations. The development of general-purpose computers made numerical integration more practical and drove a desire for improvements. The goals of numerical integration are accuracy, reliability, efficiency, and generality, and sophisticated modern methods can vastly outperform a naive method by all four measures (; ; ).\n\nConsider, for example, the integral\n \\int_{-2}^{2} \\tfrac{1}{5} \\left( \\tfrac{1}{100}(322 + 3 x (98 + x (37 + x))) - 24 \\frac{x}{1+x^2} \\right) dx \nwhich has the exact answer . (In ordinary practice, the answer is not known in advance, so an important task — not explored here — is to decide when an approximation is good enough.) A “calculus book” approach divides the integration range into, say, 16 equal pieces, and computes function values.\n\nUsing the left end of each piece, the rectangle method sums 16 function values and multiplies by the step width, , here 0.25, to get an approximate value of 3.94325 for the integral. The accuracy is not impressive, but calculus formally uses pieces of infinitesimal width, so initially this may seem little cause for concern. Indeed, repeatedly doubling the number of steps eventually produces an approximation of 3.76001. However, 218 pieces are required, a great computational expense for such little accuracy; and a reach for greater accuracy can force steps so small that arithmetic precision becomes an obstacle.\n\nA better approach replaces the rectangles used in a Riemann sum with trapezoids. The trapezoid rule is almost as easy to calculate; it sums all 17 function values, but weights the first and last by one half, and again multiplies by the step width. This immediately improves the approximation to 3.76925, which is noticeably more accurate. Furthermore, only 210 pieces are needed to achieve 3.76000, substantially less computation than the rectangle method for comparable accuracy. The idea behind the trapezoid rule, that more accurate approximations to the function yield better approximations to the integral, can be carried further. Simpson's rule approximates the integrand by a piecewise quadratic function. Riemann sums, the trapezoid rule, and Simpson's rule are examples of a family of quadrature rules called Newton–Cotes formulas. The degree  Newton–Cotes quadrature rule approximates the polynomial on each subinterval by a degree  polynomial. This polynomial is chosen to interpolate the values of the function on the interval. Higher degree Newton-Cotes approximations can be more accurate, but they require more function evaluations (already Simpson's rule requires twice the function evaluations of the trapezoid rule), and they can suffer from numerical inaccuracy due to Runge's phenomenon. One solution to this problem is Clenshaw–Curtis quadrature, in which the integrand is approximated by expanding it in terms of Chebyshev polynomials. This produces an approximation whose values never deviate far from those of the original function.\n\nRomberg's method builds on the trapezoid method to great effect. First, the step lengths are halved incrementally, giving trapezoid approximations denoted by , and so on, where  is half of . For each new step size, only half the new function values need to be computed; the others carry over from the previous size (as shown in the table above). But the really powerful idea is to interpolate a polynomial through the approximations, and extrapolate to . With this method a numerically exact answer here requires only four pieces (five function values). The Lagrange polynomial interpolating  {(4.00,6.128), (2.00,4.352), (1.00,3.908)} is 3.76 + 0.148, producing the extrapolated value 3.76 at .\n\nGaussian quadrature often requires noticeably less work for superior accuracy. In this example, it can compute the function values at just two  positions, , then double each value and sum to get the numerically exact answer. The explanation for this dramatic success lies in the choice of points. Unlike Newton–Cotes rules, which interpolate the integrand at evenly spaced points, Gaussian quadrature evaluates the function at the roots of a set of orthogonal polynomials. An -point Gaussian method is exact for polynomials of degree up to . The function in this example is a degree 3 polynomial, plus a term that cancels because the chosen endpoints are symmetric around zero. (Cancellation also benefits the Romberg method.)\n\nIn practice, each method must use extra evaluations to ensure an error bound on an unknown function; this tends to offset some of the advantage of the pure Gaussian method, and motivates the popular Gauss–Kronrod quadrature formulae. More broadly, adaptive quadrature partitions a range into pieces based on function properties, so that data points are concentrated where they are needed most.\n\nThe computation of higher-dimensional integrals (for example, volume calculations) makes important use of such alternatives as Monte Carlo integration.\n\nA calculus text is no substitute for numerical analysis, but the reverse is also true. Even the best adaptive numerical code sometimes requires a user to help with the more demanding integrals. For example, improper integrals may require a change of variable or methods that can avoid infinite function values, and known properties like symmetry and periodicity may provide critical leverage. For example, the integral \\int_0^1 x^{-1/2} e^{-x}\\,dx is difficult to evaluate numerically because it is infinite at . However, the substitution  transforms the integral into 2\\int_0^1 e^{-u^2}\\,du, which has no singularities at all.\n\nMechanical\n\nThe area of an arbitrary two-dimensional shape can be determined using a measuring instrument called planimeter. The volume of irregular objects can be measured with precision by the fluid displaced as the object is submerged.\n\nGeometrical\n\nArea can sometimes be found via geometrical compass-and-straightedge constructions of an equivalent square.",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Integral" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=15532" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "In mathematics, an integral assigns numbers to functions in a way that can describe displacement, area, volume, and other concepts that arise by combining infinitesimal data. Integration is one of the two main operations of calculus, with its inverse, differentiation, being the other. Given a function  of a real variable  and an interval  of the real line, the definite integral\n\n\\int_a^b \\! f(x)\\,dx\n\nis defined informally as the signed area of the region in the -plane that is bounded by the graph of , the -axis and the vertical lines  and . The area above the -axis adds to the total and that below the -axis subtracts from the total.\n\nRoughly speaking, the operation of integration is the reverse of differentiation. For this reason, the term integral may also refer to the related notion of the antiderivative, a function  whose derivative is the given function . In this case, it is called an indefinite integral and is written:\nF(x) = \\int f(x)\\,dx.\n\nThe integrals discussed in this article are those termed definite integrals. It is the fundamental theorem of calculus that connects differentiation with the definite integral: if  is a continuous real-valued function defined on a closed interval , then, once an antiderivative  of  is known, the definite integral of  over that interval is given by\n\n\\int_a^b f(x) dx \\left[ F(x) \\right]_{a}^{b} \n F(b) - F(a) \\, .\n\nThe principles of integration were formulated independently by Isaac Newton and Gottfried Leibniz in the late 17th century, who thought of the integral as an infinite sum of rectangles of infinitesimal width. Bernhard Riemann gave a rigorous mathematical definition of integrals. It is based on a limiting procedure that approximates the area of a curvilinear region by breaking the region into thin vertical slabs. Beginning in the nineteenth century, more sophisticated notions of integrals began to appear, where the type of the function as well as the domain over which the integration is performed has been generalised. A line integral is defined for functions of two or three variables, and the interval of integration  is replaced by a certain curve connecting two points on the plane or in the space. In a surface integral, the curve is replaced by a piece of a surface in the three-dimensional space.\n\nHistory\n\nPre-calculus integration\n\nThe first documented systematic technique capable of determining integrals is the method of exhaustion of the ancient Greek astronomer Eudoxus (ca. 370 BC), which sought to find areas and volumes by breaking them up into an infinite number of divisions for which the area or volume was known. This method was further developed and employed by Archimedes in the 3rd century BC and used to calculate areas for parabolas and an approximation to the area of a circle.\n\nA similar method was independently developed in China around the 3rd century AD by Liu Hui, who used it to find the area of the circle. This method was later used in the 5th century by Chinese father-and-son mathematicians Zu Chongzhi and Zu Geng to find the volume of a sphere (; ).\n\nThe next significant advances in integral calculus did not begin to appear until the 17th century. At this time, the work of Cavalieri with his method of Indivisibles, and work by Fermat, began to lay the foundations of modern calculus, with Cavalieri computing the integrals of  up to degree  in Cavalieri's quadrature formula. Further steps were made in the early 17th century by Barrow and Torricelli, who provided the first hints of a connection between integration and differentiation. Barrow provided the first proof of the fundamental theorem of calculus. Wallis generalized Cavalieri's method, computing integrals of  to a general power, including negative powers and fractional powers.\n\nNewton and Leibniz\n\nThe major advance in integration came in the 17th century with the independent discovery of the fundamental theorem of calculus by Newton and Leibniz. The theorem demonstrates a connection between integration and differentiation. This connection, combined with the comparative ease of differentiation, can be exploited to calculate integrals. In particular, the fundamental theorem of calculus allows one to solve a much broader class of problems. Equal in importance is the comprehensive mathematical framework that both Newton and Leibniz developed. Given the name infinitesimal calculus, it allowed for precise analysis of functions within continuous domains. This framework eventually became modern calculus, whose notation for integrals is drawn directly from the work of Leibniz.\n\nFormalization\n\nWhile Newton and Leibniz provided a systematic approach to integration, their work lacked a degree of rigour. Bishop Berkeley memorably attacked the vanishing increments used by Newton, calling them \"ghosts of departed quantities\". Calculus acquired a firmer footing with the development of limits. Integration was first rigorously formalized, using limits, by Riemann. Although all bounded piecewise continuous functions are Riemann-integrable on a bounded interval, subsequently more general functions were considered—particularly in the context of Fourier analysis—to which Riemann's definition does not apply, and Lebesgue formulated a different definition of integral, founded in measure theory (a subfield of real analysis). Other definitions of integral, extending Riemann's and Lebesgue's approaches, were proposed. These approaches based on the real number system are the ones most common today, but alternative approaches exist, such as a definition of integral as the standard part of an infinite Riemann sum, based on the hyperreal number system.\n\nHistorical notation\n\nIsaac Newton used a small vertical bar above a variable to indicate integration, or placed the variable inside a box. The vertical bar was easily confused with  or , which are used to indicate differentiation, and the box notation was difficult for printers to reproduce, so these notations were not widely adopted.\n\nThe modern notation for the indefinite integral was introduced by Gottfried Leibniz in 1675 (; ). He adapted the integral symbol, ∫, from the letter ſ (long s), standing for summa (written as ſumma; Latin for \"sum\" or \"total\"). The modern notation for the definite integral, with limits above and below the integral sign, was first used by Joseph Fourier in Mémoires of the French Academy around 1819–20, reprinted in his book of 1822 (; ).\n\nApplications\n\nIntegrals are used extensively in many areas of mathematics as well as in many other areas that rely on mathematics.\n\nFor example, in probability theory, integrals are used to determine the probability of some random variable falling within a certain range. Moreover, the integral under an entire probability density function must equal 1, which provides a test of whether a function with no negative values could be a density function or not.\n\nIntegrals can be used for computing the area of a two-dimensional region that has a curved boundary, as well as computing the volume of a three-dimensional object that has a curved boundary.\n\nIntegrals are also used in physics, in areas like kinematics to find quantities like displacement, time, and velocity. For example, in rectilinear motion, the displacement of an object over the time interval [a,b] is given by: \n\nx(b)-x(a) = \\int_a^b v(t) \\,dt,\n\nwhere v(t) is the velocity expressed as a function of time. The work done by a force F(x) (given as a function of position) from an initial position A to a final position B is:\n\nW_{A\\rightarrow B} = \\int_A^B F(x)\\,dx.\n\nTerminology and notation\n\nStandard\n\nThe integral with respect to  of a real-valued function  of a real variable  on the interval  is written as\n\n\\displaystyle \\int_a^b f(x)\\,dx.\n\nThe integral sign  represents integration. The symbol , called the differential of the variable , indicates that the variable of integration is . The function  to be integrated is called the integrand. The symbol  is separated from the integrand by a space (as shown). If a function has an integral, it is said to be integrable. The points  and  are called the limits of the integral. An integral where the limits are specified is called a definite integral. The integral is said to be over the interval .\n\nIf the integral goes from a finite value a to the upper limit infinity, the integral expresses the limit of the integral from a to a value b as b goes to infinity. If the value of the integral gets closer and closer to a finite value, the integral is said to converge to that value. If not, the integral is said to diverge.\n\nWhen the limits are omitted, as in\n\\int f(x) \\,dx,\nthe integral is called an indefinite integral, which represents a class of functions (the antiderivative) whose derivative is the integrand. The fundamental theorem of calculus relates the evaluation of definite integrals to indefinite integrals. Occasionally, limits of integration are omitted for definite integrals when the same limits occur repeatedly in a particular context. Usually, the author will make this convention clear at the beginning of the relevant text.\n\nThere are several extensions of the notation for integrals to encompass integration on unbounded domains and/or in multiple dimensions (see later sections of this article).\n\nMeaning of the symbol dx \n\nHistorically, the symbol dx was taken to represent an infinitesimally \"small piece\" of the independent variable x to be multiplied by the integrand and summed up in an infinite sense. While this notion is still heuristically useful, later mathematicians have deemed infinitesimal quantities to be untenable from the standpoint of the real number system.In the 20th century, nonstandard analysis was developed as a new approach to calculus that incorporates a rigorous concept of infinitesimals by using an expanded number system called the hyperreal numbers. Though placed on a sound axiomatic footing and of interest in its own right as a new area of investigation, nonstandard analysis remains somewhat controversial from a pedagogical standpoint, with proponents pointing out the intuitive nature of infinitesimals for beginning students of calculus and opponents criticizing the logical complexity of the system as a whole. In introductory calculus, the expression dx is therefore not assigned an independent meaning; instead, it is viewed as part of the symbol for integration and serves as its delimiter on the right side of the expression being integrated. \n\nIn more sophisticated contexts, dx can have its own significance, the meaning of which depending on the particular area of mathematics being discussed. When used in one of these ways, the original Leibnitz notation is co-opted to apply to a generalization of the original definition of the integral. Some common interpretations of dx include: an integrator function in Riemann-Stieltjes integration (indicated by dα(x) in general), a measure in Lebesgue theory (indicated by dμ in general), or a differential form in exterior calculus (indicated by dx^{i_1}\\wedge\\cdots\\wedge dx^{i_k} in general). In the last case, even the letter d has an independent meaning — as the exterior derivative operator on differential forms.\n\nConversely, in advanced settings, it is not uncommon to leave out dx when only the simple Riemann integral is being used, or the exact type of integral is immaterial. For instance, one might write \\int_a^b (c_1f+c_2g) \n c_1\\int_a^b f + c_2\\int_a^b g  to express the linearity of the integral, a property shared by the Riemann integral and all generalizations thereof.\n\nVariants\n\nIn modern Arabic mathematical notation, a reflected integral symbol  is used instead of the symbol , since the Arabic script and mathematical expressions go right to left.. Some authors, particularly of European origin, use an upright \"d\" to indicate the variable of integration (i.e.,  instead of ), since properly speaking, \"d\" is not a variable. Also, the symbol  is not always placed after , as for instance in\n\\int\\limits_0^1 \\frac{3\\ dx}{x^2+1}\\quad or \\quad\\int_{0}^{1} dx \\int_{0}^{1} dy\\ e^{-(x^2+y^2)} .\nIn the first expression, the differential is treated as an infinitesimal \"multiplicative\" factor, formally following a \"commutative property\" when \"multiplied\" by the expression 3/(x2+1). In the second expression, showing the differentials first highlights and clarifies the variables that are being integrated with respect to, a practice particularly popular with physicists.\n\nInterpretations of the integral\n\nIntegrals appear in many practical situations. If a swimming pool is rectangular with a flat bottom, then from its length, width, and depth we can easily determine the volume of water it can contain (to fill it), the area of its surface (to cover it), and the length of its edge (to rope it). But if it is oval with a rounded bottom, all of these quantities call for integrals. Practical approximations may suffice for such trivial examples, but precision engineering (of any discipline) requires exact and rigorous values for these elements.\n\nTo start off, consider the curve  between  and  with  (see figure). We ask:\nWhat is the area under the function , in the interval from 0 to 1?\nand call this (yet unknown) area the (definite) integral of . The notation for this integral will be\n\\int_0^1 \\sqrt{x}\\ dx.\n\nAs a first approximation, look at the unit square given by the sides  to  and  and . Its area is exactly 1. Actually, the true value of the integral must be somewhat less than 1. Decreasing the width of the approximation rectangles and increasing the number of rectangles gives a better result; so cross the interval in five steps, using the approximation points 0, 1/5, 2/5, and so on to 1. Fit a box for each step using the right end height of each curve piece, thus , , and so on to . Summing the areas of these rectangles, we get a better approximation for the sought integral, namely\n\\textstyle \\sqrt{\\frac{1}{5}}\\left(\\frac{1}{5}-0\\right)+\\sqrt{\\frac{2}{5}}\\left(\\frac{2}{5}-\\frac{1}{5}\\right)+\\cdots+\\sqrt{\\frac{5}{5}}\\left(\\frac{5}{5}-\\frac{4}{5}\\right)\\approx 0.7497.\n\nWe are taking a sum of finitely many function values of , multiplied with the differences of two subsequent approximation points. We can easily see that the approximation is still too large. Using more steps produces a closer approximation, but will always be too high and will never be exact. Alternatively, replacing these subintervals by ones with the left end height of each piece, we will get an approximation that is too low: for example, with twelve such subintervals we will get an approximate value for the area of 0.6203. \n\nThe key idea is the transition from adding finitely many differences of approximation points multiplied by their respective function values to using infinitely many fine, or infinitesimal steps. When this transition is completed in the above example, it turns out that the area under the curve within the stated bounds is 2/3.\n\nThe notation\n\\int f(x)\\ dx\nconceives the integral as a weighted sum, denoted by the elongated , of function values, , multiplied by infinitesimal step widths, the so-called differentials, denoted by .\n\nHistorically, after the failure of early efforts to rigorously interpret infinitesimals, Riemann formally defined integrals as a limit of weighted sums, so that the  suggested the limit of a difference (namely, the interval width). Shortcomings of Riemann's dependence on intervals and continuity motivated newer definitions, especially the Lebesgue integral, which is founded on an ability to extend the idea of \"measure\" in much more flexible ways. Thus the notation\n\\int_A f(x)\\ d\\mu\nrefers to a weighted sum in which the function values are partitioned, with  measuring the weight to be assigned to each value. Here  denotes the region of integration.\n\nFormal definitions\n\nThere are many ways of formally defining an integral, not all of which are equivalent. The differences exist mostly to deal with differing special cases which may not be integrable under other definitions, but also occasionally for pedagogical reasons. The most commonly used definitions of integral are Riemann integrals and Lebesgue integrals.\n\nRiemann integral\n\nThe Riemann integral is defined in terms of Riemann sums of functions with respect to tagged partitions of an interval. Let  be a closed interval of the real line; then a tagged partition of  is a finite sequence\n\n a x_0 \\le t_1 \\le x_1 \\le t_2 \\le x_2 \\le \\cdots \\le x_{n-1} \\le t_n \\le x_n \n b . \\,\\!\n\nThis partitions the interval  into  sub-intervals  indexed by , each of which is \"tagged\" with a distinguished point . A Riemann sum of a function  with respect to such a tagged partition is defined as\n\\sum_{i=1}^{n} f(t_i) \\Delta_i ; \nthus each term of the sum is the area of a rectangle with height equal to the function value at the distinguished point of the given sub-interval, and width the same as the sub-interval width. Let  be the width of sub-interval ; then the mesh of such a tagged partition is the width of the largest sub-interval formed by the partition, . The Riemann integral of a function  over the interval  is equal to  if:\nFor all  there exists  such that, for any tagged partition  with mesh less than , we have\n:\\left| S - \\sum_{i=1}^{n} f(t_i)\\Delta_i \\right| \nWhen the chosen tags give the maximum (respectively, minimum) value of each interval, the Riemann sum becomes an upper (respectively, lower) Darboux sum, suggesting the close connection between the Riemann integral and the Darboux integral.\n\nLebesgue integral\n\nIt is often of interest, both in theory and applications, to be able to pass to the limit under the integral. For instance, a sequence of functions can frequently be constructed that approximate, in a suitable sense, the solution to a problem. Then the integral of the solution function should be the limit of the integrals of the approximations. However, many functions that can be obtained as limits are not Riemann-integrable, and so such limit theorems do not hold with the Riemann integral. Therefore, it is of great importance to have a definition of the integral that allows a wider class of functions to be integrated .\n\nSuch an integral is the Lebesgue integral, that exploits the following fact to enlarge the class of integrable functions: if the values of a function are rearranged over the domain, the integral of a function should remain the same. Thus Henri Lebesgue introduced the integral bearing his name, explaining this integral thus in a letter to Paul Montel:\n\nAs  puts it, \"To compute the Riemann integral of , one partitions the domain  into subintervals\", while in the Lebesgue integral, \"one is in effect partitioning the range of \". The definition of the Lebesgue integral thus begins with a measure, μ. In the simplest case, the Lebesgue measure  of an interval  is its width, , so that the Lebesgue integral agrees with the (proper) Riemann integral when both exist. In more complicated cases, the sets being measured can be highly fragmented, with no continuity and no resemblance to intervals.\n\nUsing the \"partitioning the range of \" philosophy, the integral of a non-negative function  should be the sum over  of the areas between a thin horizontal strip between  and . This area is just . Let }. The Lebesgue integral of  is then defined by \n\\int f = \\int_0^\\infty f^*(t)\\,dt\nwhere the integral on the right is an ordinary improper Riemann integral ( is a strictly decreasing positive function, and therefore has a well-defined improper Riemann integral). For a suitable class of functions (the measurable functions) this defines the Lebesgue integral.\n\nA general measurable function  is Lebesgue-integrable if the sum of the absolute values of the areas of the regions between the graph of  and the -axis is finite:\n\\int_E |f|\\,d\\mu \nIn that case, the integral is, as in the Riemannian case, the difference between the area above the -axis and the area below the -axis:\n\\int_E f \\,d\\mu = \\int_E f^+ \\,d\\mu - \\int_E f^- \\,d\\mu\nwhere\n\\begin{alignat}{3}\n & f^+(x) &&{}{} \\max \\{f(x),0\\} &&{}\n{} \\begin{cases}\n               f(x), & \\text{if } f(x) > 0, \\\\\n               0, & \\text{otherwise,}\n             \\end{cases}\\\\\n & f^-(x) &&{}{} \\max \\{-f(x),0\\} &&{}\n{} \\begin{cases}\n               -f(x), & \\text{if } f(x) \n\nOther integrals\n\nAlthough the Riemann and Lebesgue integrals are the most widely used definitions of the integral, a number of others exist, including:\n* The Darboux integral, which is constructed using Darboux sums and is equivalent to a Riemann integral, meaning that a function is Darboux-integrable if and only if it is Riemann-integrable. Darboux integrals have the advantage of being simpler to define than Riemann integrals.\n* The Riemann–Stieltjes integral, an extension of the Riemann integral.\n* The Lebesgue–Stieltjes integral, further developed by Johann Radon, which generalizes the Riemann–Stieltjes and Lebesgue integrals.\n* The Daniell integral, which subsumes the Lebesgue integral and Lebesgue–Stieltjes integral without the dependence on measures.\n* The Haar integral, used for integration on locally compact topological groups, introduced by Alfréd Haar in 1933.\n* The Henstock–Kurzweil integral, variously defined by Arnaud Denjoy, Oskar Perron, and (most elegantly, as the gauge integral) Jaroslav Kurzweil, and developed by Ralph Henstock.\n* The Itô integral and Stratonovich integral, which define integration with respect to semimartingales such as Brownian motion.\n\n* The Young integral, which is a kind of Riemann–Stieltjes integral with respect to certain functions of unbounded variation.\n* The rough path integral, which is defined for functions equipped with some additional \"rough path\" structure and generalizes stochastic integration against both semimartingales and processes such as the fractional Brownian motion.\n\nProperties\n\nLinearity\n\nThe collection of Riemann-integrable functions on a closed interval  forms a vector space under the operations of pointwise addition and multiplication by a scalar, and the operation of integration\n f \\mapsto \\int_a^b f(x) \\; dx\n\nis a linear functional on this vector space. Thus, firstly, the collection of integrable functions is closed under taking linear combinations; and, secondly, the integral of a linear combination is the linear combination of the integrals,\n\n \\int_a^b (\\alpha f + \\beta g)(x) \\, dx = \\alpha \\int_a^b f(x) \\,dx + \\beta \\int_a^b g(x) \\, dx. \\,\n\nSimilarly, the set of real-valued Lebesgue-integrable functions on a given measure space  with measure  is closed under taking linear combinations and hence form a vector space, and the Lebesgue integral\n\n f\\mapsto \\int_E f \\, d\\mu \n\nis a linear functional on this vector space, so that\n\n \\int_E (\\alpha f + \\beta g) \\, d\\mu = \\alpha \\int_E f \\, d\\mu + \\beta \\int_E g \\, d\\mu. \n\nMore generally, consider the vector space of all measurable functions on a measure space , taking values in a locally compact complete topological vector space  over a locally compact topological field . Then one may define an abstract integration map assigning to each function  an element of  or the symbol ,\n f\\mapsto\\int_E f \\,d\\mu, \\,\nthat is compatible with linear combinations. In this situation, the linearity holds for the subspace of functions whose integral is an element of  (i.e. \"finite\"). The most important special cases arise when  is , , or a finite extension of the field  of p-adic numbers, and  is a finite-dimensional vector space over , and when  and  is a complex Hilbert space.\n\nLinearity, together with some natural continuity properties and normalisation for a certain class of \"simple\" functions, may be used to give an alternative definition of the integral. This is the approach of Daniell for the case of real-valued functions on a set , generalized by Nicolas Bourbaki to functions with values in a locally compact topological vector space. See  for an axiomatic characterisation of the integral.\n\nInequalities\n\nA number of general inequalities hold for Riemann-integrable functions defined on a closed and bounded interval  and can be generalized to other notions of integral (Lebesgue and Daniell).\n\n* Upper and lower bounds. An integrable function  on , is necessarily bounded on that interval. Thus there are real numbers  and  so that  for all  in . Since the lower and upper sums of  over  are therefore bounded by, respectively,  and , it follows that\n:  m(b - a) \\leq \\int_a^b f(x) \\, dx \\leq M(b - a). \n\n* Inequalities between functions. If  for each  in  then each of the upper and lower sums of  is bounded above by the upper and lower sums, respectively, of . Thus\n:  \\int_a^b f(x) \\, dx \\leq \\int_a^b g(x) \\, dx. \nThis is a generalization of the above inequalities, as  is the integral of the constant function with value  over .\nIn addition, if the inequality between functions is strict, then the inequality between integrals is also strict. That is, if  for each  in , then\n:  \\int_a^b f(x) \\, dx \n\n* Subintervals. If  is a subinterval of  and  is non-negative for all , then\n:  \\int_c^d f(x) \\, dx \\leq \\int_a^b f(x) \\, dx. \n\n* Products and absolute values of functions. If  and  are two functions, then we may consider their pointwise products and powers, and absolute values:\n: \n (fg)(x)f(x) g(x), \\; f^2 (x) \n (f(x))^2, \\; |f| (x) = |f(x)|.\\,\nIf  is Riemann-integrable on  then the same is true for , and\n: \\left| \\int_a^b f(x) \\, dx \\right| \\leq \\int_a^b | f(x) | \\, dx. \nMoreover, if  and  are both Riemann-integrable then  is also Riemann-integrable, and\n: \\left( \\int_a^b (fg)(x) \\, dx \\right)^2 \\leq \\left( \\int_a^b f(x)^2 \\, dx \\right) \\left( \\int_a^b g(x)^2 \\, dx \\right). \nThis inequality, known as the Cauchy–Schwarz inequality, plays a prominent role in Hilbert space theory, where the left hand side is interpreted as the inner product of two square-integrable functions  and  on the interval .\n\n* Hölder's inequality. Suppose that  and  are two real numbers,  with , and   and  are two Riemann-integrable functions. Then the functions   and  are also integrable and the following Hölder's inequality holds:\n:\\left|\\int f(x)g(x)\\,dx\\right| \\leq\n\\left(\\int \\left|f(x)\\right|^p\\,dx \\right)^{1/p} \\left(\\int\\left|g(x)\\right|^q\\,dx\\right)^{1/q}.\nFor   \n 2, Hölder's inequality becomes the Cauchy–Schwarz inequality.\n\n* Minkowski inequality. Suppose that  is a real number and  and  are Riemann-integrable functions. Then  and  are also Riemann-integrable and the following Minkowski inequality holds:\n:\\left(\\int \\left|f(x)+g(x)\\right|^p\\,dx \\right)^{1/p} \\leq\n\\left(\\int \\left|f(x)\\right|^p\\,dx \\right)^{1/p} +\n\\left(\\int \\left|g(x)\\right|^p\\,dx \\right)^{1/p}.\nAn analogue of this inequality for Lebesgue integral is used in construction of Lp spaces.\n\nConventions\n\nIn this section,  is a real-valued Riemann-integrable function. The integral\n \\int_a^b f(x) \\, dx \nover an interval  is defined if . This means that the upper and lower sums of the function  are evaluated on a partition  whose values  are increasing. Geometrically, this signifies that integration takes place \"left to right\", evaluating  within intervals  where an interval with a higher index lies to the right of one with a lower index. The values  and , the end-points of the interval, are called the limits of integration of . Integrals can also be defined if :\n\n* Reversing limits of integration. If  then define\n: \\int_a^b f(x) \\, dx = - \\int_b^a f(x) \\, dx. \nThis, with , implies:\n* Integrals over intervals of length zero. If  is a real number then\n: \\int_a^a f(x) \\, dx = 0. \n\nThe first convention is necessary in consideration of taking integrals over subintervals of ; the second says that an integral taken over a degenerate interval, or a point, should be zero. One reason for the first convention is that the integrability of  on an interval  implies that  is integrable on any subinterval , but in particular integrals have the property that:\n\n* Additivity of integration on intervals. If  is any element of , then\n:  \\int_a^b f(x) \\, dx = \\int_a^c f(x) \\, dx + \\int_c^b f(x) \\, dx.\nWith the first convention, the resulting relation\n\\begin{align}\n \\int_a^c f(x) \\, dx &{}= \\int_a^b f(x) \\, dx - \\int_c^b f(x) \\, dx \\\\\n &{} = \\int_a^b f(x) \\, dx + \\int_b^c f(x) \\, dx\n\\end{align}\nis then well-defined for any cyclic permutation of , , and .\n\nFundamental theorem of calculus\n\nThe fundamental theorem of calculus is the statement that differentiation and integration are inverse operations: if a continuous function is first integrated and then differentiated, the original function is retrieved. An important consequence, sometimes called the second fundamental theorem of calculus, allows one to compute integrals by using an antiderivative of the function to be integrated.\n\nStatements of theorems\n\nFundamental theorem of calculus\n\nLet  be a continuous real-valued function defined on a closed interval . Let  be the function defined, for all  in , by\nF(x) = \\int_a^x f(t)\\, dt.\nThen,  is continuous on , differentiable on the open interval , and\n\nF'(x) = f(x)\n\nfor all  in .\n\nSecond fundamental theorem of calculus\n\nLet  be a real-valued function defined on a closed interval [] that admits an antiderivative  on . That is,  and  are functions such that for all  in ,\n\nf(x) = F'(x).\n\nIf  is integrable on  then\n\n\\int_a^b f(x)\\,dx = F(b) - F(a).\n\nCalculating integrals\n\nThe second fundamental theorem allows many integrals to be calculated explicitly. For example, to calculate the integral\n\\int_0^1x^{1/2}\\,dx,\nof the square root function  between 0 and 1, it is sufficient to find an antiderivative, that is, a function  whose derivative equals  :\nF'(x)=f(x).\nOne such function is . Then the value of the integral in question is\n\\int_0^1x^{1/2}\\,dx F(1) - F(0) \n \\frac{2}{3} (1)^{3/2} - \\frac{2}{3} (0)^{3/2}=\\frac{2}{3}.\n\nThis is a case of a general rule, that for , with , the related function, the so-called antiderivative is  Tables of this and similar antiderivatives can be used to calculate integrals explicitly, in much the same way that tables of derivatives can be used.\n\nExtensions\n\nImproper integrals\n\nA \"proper\" Riemann integral assumes the integrand is defined and finite on a closed and bounded interval, bracketed by the limits of integration. An improper integral occurs when one or more of these conditions is not satisfied. In some cases such integrals may be defined by considering the limit of a sequence of proper Riemann integrals on progressively larger intervals.\n\nIf the interval is unbounded, for instance at its upper end, then the improper integral is the limit as that endpoint goes to infinity.\n\\int_{a}^{\\infty} f(x)\\,dx = \\lim_{b \\to \\infty} \\int_{a}^{b} f(x)\\,dx\nIf the integrand is only defined or finite on a half-open interval, for instance , then again a limit may provide a finite result.\n\\int_{a}^{b} f(x)\\,dx = \\lim_{\\epsilon \\to 0} \\int_{a+\\epsilon}^{b} f(x)\\,dx\n\nThat is, the improper integral is the limit of proper integrals as one endpoint of the interval of integration approaches either a specified real number, or , or . In more complicated cases, limits are required at both endpoints, or at interior points.\n\nMultiple integration\n\nJust as the definite integral of a positive function of one variable represents the area of the region between the graph of the function and the x-axis, the double integral of a positive function of two variables represents the volume of the region between the surface defined by the function and the plane that contains its domain. For example, a function in two dimensions depends on two real variables, x and y, and the integral of a function f over the rectangle R given as the Cartesian product of two intervals R=[a,b]\\times [c,d] can be written\n\n\\int_R f(x,y)\\,dA\n\nwhere the differential  indicates that integration is taken with respect to area. This double integral can be defined using Riemann sums, and represents the (signed) volume under the graph of  over the domain R. Under suitable conditions (e.g., if f is continuous), then Fubini's theorem guarantees that this integral can be expressed as an equivalent iterated integral\n\n\\int_a^b\\left[\\int_c^d f(x,y)\\,dy\\right]\\,dx.\n\nThis reduces the problem of computing a double integral to computing one-dimensional integrals. Because of this, another notation for the integral over R uses a double integral sign:\n\\iint_R f(x,y) dA.\n\nIntegration over more general domains is possible. The integral of a function f, with respect to volume, over a subset D of  ℝn is denoted by notation such as\n\n\\int_D f(\\mathbf x)d^n\\mathbf x,\\quad \\int_D f\\,dV\n\nor similar. See volume integral.\n\nLine integrals\n\nThe concept of an integral can be extended to more general domains of integration, such as curved lines and surfaces. Such integrals are known as line integrals and surface integrals respectively. These have important applications in physics, as when dealing with vector fields.\n\nA line integral (sometimes called a path integral) is an integral where the function to be integrated is evaluated along a curve. Various different line integrals are in use. In the case of a closed curve it is also called a contour integral.\n\nThe function to be integrated may be a scalar field or a vector field. The value of the line integral is the sum of values of the field at all points on the curve, weighted by some scalar function on the curve (commonly arc length or, for a vector field, the scalar product of the vector field with a differential vector in the curve). This weighting distinguishes the line integral from simpler integrals defined on intervals. Many simple formulas in physics have natural continuous analogs in terms of line integrals; for example, the fact that work is equal to force, , multiplied by displacement, , may be expressed (in terms of vector quantities) as:\nW=\\mathbf F\\cdot\\mathbf s.\nFor an object moving along a path  in a vector field  such as an electric field or gravitational field, the total work done by the field on the object is obtained by summing up the differential work done in moving from  to . This gives the line integral\nW=\\int_C \\mathbf F\\cdot d\\mathbf s.\n\nSurface integrals\n\nA surface integral is a definite integral taken over a surface (which may be a curved set in space); it can be thought of as the double integral analog of the line integral. The function to be integrated may be a scalar field or a vector field. The value of the surface integral is the sum of the field at all points on the surface. This can be achieved by splitting the surface into surface elements, which provide the partitioning for Riemann sums.\n\nFor an example of applications of surface integrals, consider a vector field  on a surface ; that is, for each point  in ,  is a vector. Imagine that we have a fluid flowing through , such that  determines the velocity of the fluid at . The flux is defined as the quantity of fluid flowing through  in unit amount of time. To find the flux, we need to take the dot product of  with the unit surface normal to  at each point, which will give us a scalar field, which we integrate over the surface:\n\\int_S {\\mathbf v}\\cdot \\,d{\\mathbf {S}}.\nThe fluid flux in this example may be from a physical fluid such as water or air, or from electrical or magnetic flux. Thus surface integrals have applications in physics, particularly with the classical theory of electromagnetism.\n\nContour integrals\n\nIn complex analysis, the integrand is a complex-valued function of a complex variable  instead of a real function of a real variable . When a complex function is integrated along a curve \\gamma in the complex plane, the integral is denoted as follows\n\n\\int_{\\gamma} f(z)\\,dz.\n\nThis is known as a contour integral.\n\nIntegrals of differential forms\n\nA differential form is a mathematical concept in the fields of multivariable calculus, differential topology, and tensors. Differential forms are organized by degree. For example, a one-form is a weighted sum of the differentials of the coordinates, such as:\nE(x,y,z)\\,dx + F(x,y,z)\\,dy + G(x,y,z)\\, dz\nwhere E, F, G are functions in three dimensions. A differential one-form can be integrated over an oriented path, and the resulting integral is just another way of writing a line integral. Here the basic differentials dx, dy, dz measure infinitesimal oriented lengths parallel to the three coordinate axes.\n\nA differential two-form is a sum of the form\nG(x,y,z)dx\\wedge dy + E(x,y,z)dy\\wedge dz + F(x,y,z)dz\\wedge dx.\nHere the basic two-forms dx\\wedge dy, dz\\wedge dx, dy\\wedge dz measure oriented areas parallel to the coordinate two-planes. The symbol \\wedge denotes the wedge product, which is similar to the cross product in the sense that the wedge product of two forms representing oriented lengths represents an oriented area. A two-form can be integrated over an oriented surface, and the resulting integral is equivalent to the surface integral giving the flux of E\\mathbf i+F\\mathbf j+G\\mathbf k.\n\nUnlike the cross product, and the three-dimensional vector calculus, the wedge product and the calculus of differential forms makes sense in arbitrary dimension and on more general manifolds (curves, surfaces, and their higher-dimensional analogs). The exterior derivative plays the role of the gradient and curl of vector calculus, and Stokes' theorem simultaneously generalizes the three theorems of vector calculus: the divergence theorem, Green's theorem, and the Kelvin-Stokes theorem.\n\nSummations\n\nThe discrete equivalent of integration is summation. Summations and integrals can be put on the same foundations using the theory of Lebesgue integrals or time scale calculus.\n\nComputation\n\nAnalytical\n\nThe most basic technique for computing definite integrals of one real variable is based on the fundamental theorem of calculus. Let  be the function of  to be integrated over a given interval . Then, find an antiderivative of ; that is, a function  such that  on the interval. Provided the integrand and integral have no singularities on the path of integration, by the fundamental theorem of calculus,\n\n\\int_a^b f(x)\\,dx=F(b)-F(a).\n\nThe integral is not actually the antiderivative, but the fundamental theorem provides a way to use antiderivatives to evaluate definite integrals.\n\nThe most difficult step is usually to find the antiderivative of . It is rarely possible to glance at a function and write down its antiderivative. More often, it is necessary to use one of the many techniques that have been developed to evaluate integrals. Most of these techniques rewrite one integral as a different one which is hopefully more tractable. Techniques include:\n* Integration by substitution\n* Integration by parts\n* Inverse function integration\n* Changing the order of integration\n* Integration by trigonometric substitution\n* Tangent half-angle substitution\n* Integration by partial fractions\n* Integration by reduction formulae\n* Integration using parametric derivatives\n* Integration using Euler's formula\n* Euler substitution\n* Differentiation under the integral sign\n* Contour integration\nAlternative methods exist to compute more complex integrals. Many nonelementary integrals can be expanded in a Taylor series and integrated term by term. Occasionally, the resulting infinite series can be summed analytically. The method of convolution using Meijer G-functions can also be used, assuming that the integrand can be written as a product of Meijer G-functions. There are also many less common ways of calculating definite integrals; for instance, Parseval's identity can be used to transform an integral over a rectangular region into an infinite sum. Occasionally, an integral can be evaluated by a trick; for an example of this, see Gaussian integral.\n\nComputations of volumes of solids of revolution can usually be done with disk integration or shell integration.\n\nSpecific results which have been worked out by various techniques are collected in the list of integrals.\n\nSymbolic\n\nMany problems in mathematics, physics, and engineering involve integration where an explicit formula for the integral is desired. Extensive tables of integrals have been compiled and published over the years for this purpose. With the spread of computers, many professionals, educators, and students have turned to computer algebra systems that are specifically designed to perform difficult or tedious tasks, including integration. Symbolic integration has been one of the motivations for the development of the first such systems, like Macsyma.\n\nA major mathematical difficulty in symbolic integration is that in many cases, a closed formula for the antiderivative of a rather simple-looking function does not exist. For instance, it is known that the antiderivatives of the functions  and  cannot be expressed in the closed form involving only rational and exponential functions, logarithm, trigonometric functions and inverse trigonometric functions, and the operations of multiplication and composition; in other words, none of the three given functions is integrable in elementary functions, which are the functions which may be built from  rational functions, roots of a polynomial, logarithm, and exponential functions. The Risch algorithm provides a general criterion to determine whether the antiderivative of an elementary function is elementary, and, if it is, to compute it. Unfortunately, it turns out that functions with closed expressions of antiderivatives are the exception rather than the rule. Consequently, computerized algebra systems have no hope of being able to find an antiderivative for a randomly constructed elementary function. On the positive side, if the 'building blocks' for antiderivatives are fixed in advance, it may be still be possible to decide whether the antiderivative of a given function can be expressed using these blocks and operations of multiplication and composition, and to find the symbolic answer whenever it exists. The Risch algorithm, implemented in Mathematica and other computer algebra systems, does just that for functions and antiderivatives built from  rational functions, radicals, logarithm, and exponential functions.\n\nSome special integrands occur often enough to warrant special study. In particular, it may be useful to have, in the set of antiderivatives, the special functions (like the Legendre functions, the hypergeometric function, the gamma function, the incomplete gamma function and so on — see Symbolic integration for more details). Extending the Risch's algorithm to include such functions is possible but challenging and has been an active research subject.\n\nMore recently a new approach has emerged, using D-finite functions, which are the solutions of linear differential equations with polynomial coefficients. Most of the elementary and special functions are D-finite, and the integral of a D-finite function is also a D-finite function. This provides an algorithm to express the antiderivative of a D-finite function as the solution of a differential equation.\n\nThis theory also allows one to compute the definite integral of a D-function as the sum of a series given by the first coefficients, and provides an algorithm to compute any coefficient.[http://algo.inria.fr/chyzak/mgfun.html Frédéric Chyzak's Mgfun Project: Introduction to the Package Mgfun and Related Packages]\n\nNumerical\n\nSome integrals found in real applications can be computed by closed-form antiderivatives. Others are not so accommodating. Some antiderivatives do not have closed forms, some closed forms require special functions that themselves are a challenge to compute, and others are so complex that finding the exact answer is too slow. This motivates the study and application of numerical approximations of integrals. This subject, called numerical integration or numerical quadrature, arose early in the study of integration for the purpose of making hand calculations. The development of general-purpose computers made numerical integration more practical and drove a desire for improvements. The goals of numerical integration are accuracy, reliability, efficiency, and generality, and sophisticated modern methods can vastly outperform a naive method by all four measures (; ; ).\n\nConsider, for example, the integral\n \\int_{-2}^{2} \\tfrac{1}{5} \\left( \\tfrac{1}{100}(322 + 3 x (98 + x (37 + x))) - 24 \\frac{x}{1+x^2} \\right) dx \nwhich has the exact answer . (In ordinary practice, the answer is not known in advance, so an important task — not explored here — is to decide when an approximation is good enough.) A “calculus book” approach divides the integration range into, say, 16 equal pieces, and computes function values.\n\nUsing the left end of each piece, the rectangle method sums 16 function values and multiplies by the step width, , here 0.25, to get an approximate value of 3.94325 for the integral. The accuracy is not impressive, but calculus formally uses pieces of infinitesimal width, so initially this may seem little cause for concern. Indeed, repeatedly doubling the number of steps eventually produces an approximation of 3.76001. However, 218 pieces are required, a great computational expense for such little accuracy; and a reach for greater accuracy can force steps so small that arithmetic precision becomes an obstacle.\n\nA better approach replaces the rectangles used in a Riemann sum with trapezoids. The trapezoid rule is almost as easy to calculate; it sums all 17 function values, but weights the first and last by one half, and again multiplies by the step width. This immediately improves the approximation to 3.76925, which is noticeably more accurate. Furthermore, only 210 pieces are needed to achieve 3.76000, substantially less computation than the rectangle method for comparable accuracy. The idea behind the trapezoid rule, that more accurate approximations to the function yield better approximations to the integral, can be carried further. Simpson's rule approximates the integrand by a piecewise quadratic function. Riemann sums, the trapezoid rule, and Simpson's rule are examples of a family of quadrature rules called Newton–Cotes formulas. The degree  Newton–Cotes quadrature rule approximates the polynomial on each subinterval by a degree  polynomial. This polynomial is chosen to interpolate the values of the function on the interval. Higher degree Newton-Cotes approximations can be more accurate, but they require more function evaluations (already Simpson's rule requires twice the function evaluations of the trapezoid rule), and they can suffer from numerical inaccuracy due to Runge's phenomenon. One solution to this problem is Clenshaw–Curtis quadrature, in which the integrand is approximated by expanding it in terms of Chebyshev polynomials. This produces an approximation whose values never deviate far from those of the original function.\n\nRomberg's method builds on the trapezoid method to great effect. First, the step lengths are halved incrementally, giving trapezoid approximations denoted by , and so on, where  is half of . For each new step size, only half the new function values need to be computed; the others carry over from the previous size (as shown in the table above). But the really powerful idea is to interpolate a polynomial through the approximations, and extrapolate to . With this method a numerically exact answer here requires only four pieces (five function values). The Lagrange polynomial interpolating  {(4.00,6.128), (2.00,4.352), (1.00,3.908)} is 3.76 + 0.148, producing the extrapolated value 3.76 at .\n\nGaussian quadrature often requires noticeably less work for superior accuracy. In this example, it can compute the function values at just two  positions, , then double each value and sum to get the numerically exact answer. The explanation for this dramatic success lies in the choice of points. Unlike Newton–Cotes rules, which interpolate the integrand at evenly spaced points, Gaussian quadrature evaluates the function at the roots of a set of orthogonal polynomials. An -point Gaussian method is exact for polynomials of degree up to . The function in this example is a degree 3 polynomial, plus a term that cancels because the chosen endpoints are symmetric around zero. (Cancellation also benefits the Romberg method.)\n\nIn practice, each method must use extra evaluations to ensure an error bound on an unknown function; this tends to offset some of the advantage of the pure Gaussian method, and motivates the popular Gauss–Kronrod quadrature formulae. More broadly, adaptive quadrature partitions a range into pieces based on function properties, so that data points are concentrated where they are needed most.\n\nThe computation of higher-dimensional integrals (for example, volume calculations) makes important use of such alternatives as Monte Carlo integration.\n\nA calculus text is no substitute for numerical analysis, but the reverse is also true. Even the best adaptive numerical code sometimes requires a user to help with the more demanding integrals. For example, improper integrals may require a change of variable or methods that can avoid infinite function values, and known properties like symmetry and periodicity may provide critical leverage. For example, the integral \\int_0^1 x^{-1/2} e^{-x}\\,dx is difficult to evaluate numerically because it is infinite at . However, the substitution  transforms the integral into 2\\int_0^1 e^{-u^2}\\,du, which has no singularities at all.\n\nMechanical\n\nThe area of an arbitrary two-dimensional shape can be determined using a measuring instrument called planimeter. The volume of irregular objects can be measured with precision by the fluid displaced as the object is submerged.\n\nGeometrical\n\nArea can sometimes be found via geometrical compass-and-straightedge constructions of an equivalent square. Integral. http://en.wikipedia.org/?curid=15532."
  }
}
