{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=9637",
  "eid" : "f0bd31a0-52b1-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778483642,
  "textBody" : "In mathematics, the Euler–Maclaurin formula provides a powerful connection between integrals (see calculus) and sums.  It can be used to approximate integrals by finite sums, or conversely to evaluate finite sums and infinite series using integrals and the machinery of calculus. For example, many asymptotic expansions are derived from the formula, and Faulhaber's formula for the sum of powers is an immediate consequence.\n\nThe formula was discovered independently by Leonhard Euler and Colin Maclaurin around 1735 (and later generalized as Darboux's formula).  Euler needed it to compute slowly converging infinite series while Maclaurin used it to calculate integrals.\n\nThe formula\n\nIf m and n are natural numbers and f(x) is a complex or real valued continuous function for real numbers x in the interval [m,n], then the integral\n\nI = \\int_m^n f(x)\\,dx\n\ncan be approximated by the sum (or vice versa)\n\nS = f(m + 1) + \\cdots + f(n - 1) + f(n)\n\n(see rectangle method). The Euler–Maclaurin formula provides expressions for the difference between the sum and the integral in terms of the higher derivatives f^{(k)}(x) evaluated at the end points of the interval, that is to say when xm and x\nn.\n\nExplicitly, for p a positive integer and a function f(x) that is p times continuously differentiable in the interval [m, n], we have\n\n S - I \\sum_{k\n1}^p {\\frac{B_k}{k!} (f^{(k - 1)}(n) - f^{(k - 1)}(m))} + R_p\n\nwhere B_k is the kth Bernoulli number (with B_1=1/2) and R_p is an error term which is normally small for suitable values of p and depends on n, m, p, and f.\n\nThe formula is often written with the subscript taking only even values, since the odd Bernoulli numbers are zero except for B_1, in which case we have\n\n\\sum_{im}^n f(i) \n\n    \\int^n_m f(x)\\,dx + \\frac{f(n) + f(m)}{2} +\n    \\sum_{k=1}^{\\lfloor p/2\\rfloor} \\frac{B_{2k}}{(2k)!} (f^{(2k - 1)}(n) - f^{(2k - 1)}(m)) + R_p\n\nor alternatively\n\n\\sum_{im+1}^n f(i) \n\n    \\int^n_m f(x)\\,dx + \\frac{f(n) - f(m)}{2} +\n    \\sum_{k=1}^{\\lfloor p/2\\rfloor} \\frac{B_{2k}}{(2k)!} (f^{(2k - 1)}(n) - f^{(2k - 1)}(m)) + R_p.\n\nThe first few Bernoulli numbers of even index are:\nB_{2}{\\frac {1}{6}},\\quad B_{4}\n-{\\frac {1}{30}},\\quad B_{6}{\\frac {1}{42}},\\quad B_{8}\n-{\\frac {1}{30}}.\nWe may write the Euler-Maclaurin formula then as\n\n\\sum _{im}^n f(i)-\\int _m^n f(x)~{\\rm d}x\n\\frac {f(m)+f(n)}2+\\frac 16\\frac {f'(n)-f'(m)}{2!}-\\frac 1{30}\\frac {f(n)-f(m)}{4!}+\\cdots +B_{2k}\\frac {f^{(2k-1)}(n)-f^{(2k-1)}(m)}{(2k)!}+R_{2k}.\n\nThe Bernoulli polynomials and periodic function\n\nThe formula is derived below using repeated integration by parts applied to successive intervals [r, r+1] for integers rm, m+1, \\cdots, n-1.  The derivation uses the periodic Bernoulli functions, P_k(x), which are defined in terms of the Bernoulli polynomials B_k(x) for k\n0,1,2 \\cdots.\n\nThe Bernoulli polynomials may be defined recursively by\n\n\\begin{align}\n  B_0(x) &= 1 \\\\\n  B_k'(x) &kB_{k - 1}(x) \\text{ and } \\int_0^1 B_k(x)\\,dx \n 0\\text{ for }k \\ge 1\n\\end{align}\n\nand the periodic Bernoulli functions are defined as\n\n P_k(x) = B_k \\left(x - \\lfloor x\\rfloor\\right) \n\nwhere \\lfloor x \\rfloor denotes the largest integer that is not greater than x so that x - \\lfloor x \\rfloor always lies in the interval [0,1).\n\nIt can be shown that B_k(1) = B_k(0) for all k \\neq 1 so that except for P_1(x), all the periodic Bernoulli functions are continuous.  The functions P_k(x) are sometimes written as \\tilde{B}_k(x).\n\nThe remainder term\n\nThe remainder term R_p can be written as\n\n R_p = (-1)^{p+1}\\int_m^n f^{(p)}(x) {P_{p}(x) \\over p!}\\,dx. \n\nWhen k>0, it can be shown that\n\n\\left| B_k (x) \\right| \\le \\frac{2 \\cdot k!}{(2\\pi)^k}\\zeta(k)\n\nwhere \\zeta  denotes the Riemann zeta function; one approach to prove this inequality is to obtain the Fourier series for the polynomials B_k(x).   The bound is achieved for even k when x is zero.  The term \\zeta(k) may be omitted for odd k but the proof in this case is more complex (see Lehmer). Using this inequality, the size of the remainder term can be estimated using\n\n\\left|R_p\\right|\\leq\\frac{2 \\zeta (p)}{(2\\pi)^{p}}\\int_m^n\\left|f^{(p)}(x)\\right|\\ \\, dx. \n\nApplicable formula\n\nWe can use the formula as a means of approximating a finite integral, with the following simple formula:\n\n\\begin{align}\nI & = \\int_{x_0}^{x_N} f(x)\\,\\mathrm{d}x \\\\[6pt]\n& = h\\left(\\frac{f_{0}}{2} + f_1 +f_2+\\cdots+f_{N-1} + \\frac{f_{N}}{2} \\right) + \\frac{h^2}{12}[f'_0 - f'_N] - \\frac{h^4}{720}[f_0 - f_N]+ \\cdots,\n\\end{align}\n\nwhere N is the number of points in the interval of integration from  x_0  to  x_N  and h is the distance between points so that  h=(x_N - x_0)/N.  Note the series above is usually not convergent;  indeed, often the terms will increase rapidly after a number of iterations.  Thus, attention generally needs to be paid to the remainder term.\n \nThis may be viewed as an extension of the trapezoid rule by the inclusion of correction terms.\n\nApplications\n\nThe Basel problem\n\nThe Basel problem asks to determine the sum\n\n 1 + \\frac14 + \\frac19 + \\frac1{16} + \\frac1{25} + \\cdots \\sum_{n\n1}^\\infty \\frac{1}{n^2}. \n\nEuler computed this sum to 20 decimal places with only a few terms of the Euler–Maclaurin formula in 1735. This probably convinced him that the sum equals \\pi^2/6, which he proved in the same year.Pengelley, David J. [http://www.math.nmsu.edu/~davidp/euler2k2.pdf \"Dances between continuous and discrete: Euler's summation formula\"], in: Robert Bradley and Ed Sandifer (Eds), Proceedings, Euler 2K+2 Conference (Rumford, Maine, 2002), Euler Society, 2003. Parseval's identity for the Fourier series of f(x)=x gives the same result.\n\nSums involving a polynomial\n\nIf f is a polynomial and p is big enough, then the remainder term vanishes.  For instance, if f(x)x^3, we can choose p\n2 to obtain after simplification\n\n\\sum_{i0}^n i^3 \n \\left(\\frac{n(n + 1)}{2}\\right)^2\n\n(see Faulhaber's formula).\n\nNumerical integration\n\nThe Euler–Maclaurin formula is also used for detailed error analysis in numerical quadrature. It explains the superior performance of the trapezoidal rule on smooth periodic functions and is used in certain extrapolation methods. Clenshaw–Curtis quadrature is essentially a change of variables to cast an arbitrary integral in terms of integrals of periodic functions where the Euler–Maclaurin approach is very accurate (in that particular case the Euler–Maclaurin formula takes the form of a discrete cosine transform). This technique is known as a periodizing transformation.\n\nAsymptotic expansion of sums\n\nIn the context of computing asymptotic expansions of sums and series, usually the most useful form of the Euler–Maclaurin formula is\n\n\\sum_{na}^b f(n) \\sim \\int_a^b f(x)\\,dx + \\frac{f(b) + f(a)}{2} + \\sum_{k\n1}^\\infty \\,\\frac{B_{2k}}{(2k)!} (f^{(2k - 1)}(b) - f^{(2k - 1)}(a))\n\nwhere a and b are integers., 23.1.30 Often the expansion remains valid even after taking the limits a\\rightarrow-\\infty or b\\rightarrow +\\infty or both.  In many cases the integral on the right-hand side can be evaluated in closed form in terms of elementary functions even though the sum on the left-hand side cannot. Then all the terms in the asymptotic series can be expressed in terms of elementary functions.  For example,\n\n\\sum_{k0}^\\infty \\frac{1}{(z + k)^2} \\sim \\underbrace{\\int_0^\\infty\\frac{1}{(z + k)^2}\\,dk}_{\n 1/z} + \\frac{1}{2z^2} + \\sum_{t = 1}^\\infty \\frac{B_{2t}}{z^{2t + 1}}.\n\nHere the left-hand side is equal to \\psi^{(1)}(z), namely the first-order polygamma function defined through \\psi^{(1)}(z) = D^2( \\log \\Gamma(z) );  the gamma function \\Gamma(z)  is equal to (z-1)!  if z  is a positive integer. This results in an asymptotic expansion for \\psi^{(1)}(z).   That expansion, in turn, serves as the starting point for one of the derivations of precise error estimates for Stirling's approximation of the factorial function.\n\nExamples\n\nIf  is an integer greater than 1 we have:\n\\sum_{k1}^n \\frac{1}{k^s} \\approx \\frac 1{s-1}+\\frac 12-\\frac 1{(s-1)n^{s-1}}+\\frac 1{2n^s}+\\sum_{i\n1}\\frac{B_{2i}}{(2i)!}\\left[\\frac{(s+2i-2)!}{(s-1)!}-\\frac{(s+2i-2)!}{(s-1)!n^{s+2i-1}}\\right]\n\nCollecting the constants into a value of the Riemann zeta function, we can write an asymptotic expansion:\n\\sum_{k1}^n \\frac{1}{k^s} \\sim\\zeta(s)-\\frac 1{(s-1)n^{s-1}}+\\frac 1{2n^s}-\\sum_{i\n1}\\frac{B_{2i}}{(2i)!}\\frac{(s+2i-2)!}{(s-1)!n^{s+2i-1}}\n\nFor  equal to 2 this simplifies to\n\\sum_{k1}^n \\frac{1}{k^2} \\sim\\zeta(2)-\\frac 1n+\\frac 1{2n^2}-\\sum_{i\n1}\\frac{B_{2i}}{n^{2i+1}}\nor\n\\sum_{k=1}^n \\frac{1}{k^2} \\sim \\frac{\\pi^2}{6} -\\frac{1}{n} +\\frac{1}{2n^2} -\\frac{1}{6n^3}+\\frac{1}{30n^5}-\\frac{1}{42n^7}. \n\nWe can also derive (from Equation 1 below) the perhaps not-so-useful formula:\n \\sum_{k1}^n \\frac{1}{k^s} \n \\frac{1}{n^{s-1}} + s \\int_1^n \\frac{\\lfloor x\\rfloor}{x^{s+1}} dx \\qquad \\text{with }\\quad s \\in \\R \\setminus \\{1\\}\n\nWhen  is 1, we get the following for the so-called harmonic numbers:\n\\begin{align}\n\\sum_{k1}^n \\frac{1}{k} &\n \\log n + \\frac{1}{2} + \\frac{1}{2n} - \\int_1^n \\frac{x-\\lfloor x\\rfloor -1/2}{x^{2}} dx\\\\\n&\\approx \\log n + \\gamma +\\frac{1}{2n} -\\frac{1}{12n^2} + \\frac{1}{120n^4} - \\frac{1}{252n^6}\n\\end{align}\n\nwhere \\gamma \\approx 0.5772156649015328606065 is the Euler constant,\n\nProofs \n\nDerivation by mathematical induction \n\nWe follow the argument given in Apostol.\n\nThe Bernoulli polynomials  and the periodic Bernoulli functions  for  were introduced above.\n\nThe first several Bernoulli polynomials are\n\n\\begin{align}\n  B_1(x) &= x - \\frac{1}{2} \\\\\n  B_2(x) &= x^2 - x + \\frac{1}{6} \\\\\n  B_3(x) &= x^3 - \\frac{3}{2}x^2 + \\frac{1}{2}x \\\\\n  B_4(x) &= x^4 - 2x^3 + x^2 - \\frac{1}{30} \\\\\n         & \\,\\,\\,\\vdots\n\\end{align}\n\nThe values  are the Bernoulli numbers.  Notice that for  we have\n\nB_n(0) B_n(1) \n B_n\\quad(n\\text{th Bernoulli number})\n\nFor ,\n\n B_1(0) -B_1(1) \n B_1\n\nThe functions  agree with the Bernoulli polynomials on the interval   and are periodic with period 1.  Furthermore, except when , they are also continuous. Thus,\n\n P_n(0) P_n(1) \n B_n \\quad (n \\neq 1)\n\nLet  be an integer, and consider the integral\n\n \\int_k^{k + 1} f(x)\\,dx = \\int_k^{k + 1} u\\,dv\n\nwhere\n\n\\begin{align}\n   u &= f(x) \\\\\n  du &= f'(x)\\,dx \\\\\n  dv &P_0(x)\\,dx && \\text{since }P_0(x) \n 1 \\\\\n   v &= P_1(x)\n\\end{align}\n\nIntegrating by parts, we get\n\n\\begin{align}\n \\int_k^{k + 1} f(x)\\,dx &= \\Big[uv\\Big]_k^{k + 1} - \\int_k^{k + 1} v\\,du \\\\[8pt]\n                         &= \\Big[f(x)P_1(x)\\Big]_k^{k + 1} - \\int_k^{k+1} f'(x)P_1(x)\\,dx \\\\[8pt]\n                         &= B_1(1)f(k+1)-B_1(0)f(k) - \\int_k^{k+1} f'(x)P_1(x)\\,dx\n\\end{align}\n\nUsing B_1(0)-1/2, B_1(1)\n1/2, and summing the above from k 0 to k \n n − 1, we get\n\n\\begin{align}\n\\int_0^n f(x)\\, dx &= \\int_0^1 f(x)\\,dx + \\dotsb + \\int_{n-1}^n f(x)\\,dx  \\\\[8pt]\n&= \\frac{f(0)}{2}+ f(1) + \\dotsb + f(n-1) + {f(n) \\over 2} - \\int_0^n f'(x) P_1(x)\\,dx\n\\end{align}\n\nAdding (f(n) − f(0))/2 to both sides and rearranging, we have\n\n \\sum_{k1}^n f(k) \n \\int_0^n f(x)\\,dx + {f(n) - f(0) \\over 2} + \\int_0^n f'(x) P_1(x)\\,dx\\qquad (1)\n\nThe last two terms therefore give the error when the integral is taken to approximate the sum.\n\nNext, consider\n\n \\int_k^{k+1} f'(x)P_1(x)\\,dx = \\int_k^{k + 1} u\\,dv \n\nwhere\n\n\\begin{align}\n   u &= f'(x) \\\\\n  du &= f(x)\\,dx \\\\\n  dv &= P_1(x)\\,dx \\\\\n   v &= \\frac{1}{2}P_2(x)\n\\end{align}\n\nIntegrating by parts again, we get\n\n\\begin{align}\n  \\Big[uv\\Big]_k^{k + 1} - \\int_k^{k + 1} v\\,du &= \\left[ {f'(x)P_2(x) \\over 2} \\right]_k^{k+1} - {1 \\over 2}\\int_k^{k+1} f(x)P_2(x)\\,dx \\\\\n                  &= {B_2 \\over 2}(f'(k + 1) - f'(k)) - {1 \\over 2}\\int_k^{k + 1} f(x)P_2(x)\\,dx\n\\end{align}\n\nThen summing from k 0 to k \n n − 1, and then replacing the last integral in (1) with what we have thus shown to be equal to it, we have\n\n \\sum_{k1}^n f(k) \n \\int_0^n f(x)\\,dx + {f(n) - f(0) \\over 2} + \\frac{B_2}{2}(f'(n) - f'(0)) - {1 \\over 2}\\int_0^n f(x)P_2(x)\\,dx.  \n\nBy now the reader will have guessed that this process can be iterated.  In this way we get a proof of the Euler–Maclaurin summation formula which can be formalized by mathematical induction, in which the induction step relies on integration by parts and on the identities for periodic Bernoulli functions.",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Euler–Maclaurin formula" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=9637" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "In mathematics, the Euler–Maclaurin formula provides a powerful connection between integrals (see calculus) and sums.  It can be used to approximate integrals by finite sums, or conversely to evaluate finite sums and infinite series using integrals and the machinery of calculus. For example, many asymptotic expansions are derived from the formula, and Faulhaber's formula for the sum of powers is an immediate consequence.\n\nThe formula was discovered independently by Leonhard Euler and Colin Maclaurin around 1735 (and later generalized as Darboux's formula).  Euler needed it to compute slowly converging infinite series while Maclaurin used it to calculate integrals.\n\nThe formula\n\nIf m and n are natural numbers and f(x) is a complex or real valued continuous function for real numbers x in the interval [m,n], then the integral\n\nI = \\int_m^n f(x)\\,dx\n\ncan be approximated by the sum (or vice versa)\n\nS = f(m + 1) + \\cdots + f(n - 1) + f(n)\n\n(see rectangle method). The Euler–Maclaurin formula provides expressions for the difference between the sum and the integral in terms of the higher derivatives f^{(k)}(x) evaluated at the end points of the interval, that is to say when xm and x\nn.\n\nExplicitly, for p a positive integer and a function f(x) that is p times continuously differentiable in the interval [m, n], we have\n\n S - I \\sum_{k\n1}^p {\\frac{B_k}{k!} (f^{(k - 1)}(n) - f^{(k - 1)}(m))} + R_p\n\nwhere B_k is the kth Bernoulli number (with B_1=1/2) and R_p is an error term which is normally small for suitable values of p and depends on n, m, p, and f.\n\nThe formula is often written with the subscript taking only even values, since the odd Bernoulli numbers are zero except for B_1, in which case we have\n\n\\sum_{im}^n f(i) \n\n    \\int^n_m f(x)\\,dx + \\frac{f(n) + f(m)}{2} +\n    \\sum_{k=1}^{\\lfloor p/2\\rfloor} \\frac{B_{2k}}{(2k)!} (f^{(2k - 1)}(n) - f^{(2k - 1)}(m)) + R_p\n\nor alternatively\n\n\\sum_{im+1}^n f(i) \n\n    \\int^n_m f(x)\\,dx + \\frac{f(n) - f(m)}{2} +\n    \\sum_{k=1}^{\\lfloor p/2\\rfloor} \\frac{B_{2k}}{(2k)!} (f^{(2k - 1)}(n) - f^{(2k - 1)}(m)) + R_p.\n\nThe first few Bernoulli numbers of even index are:\nB_{2}{\\frac {1}{6}},\\quad B_{4}\n-{\\frac {1}{30}},\\quad B_{6}{\\frac {1}{42}},\\quad B_{8}\n-{\\frac {1}{30}}.\nWe may write the Euler-Maclaurin formula then as\n\n\\sum _{im}^n f(i)-\\int _m^n f(x)~{\\rm d}x\n\\frac {f(m)+f(n)}2+\\frac 16\\frac {f'(n)-f'(m)}{2!}-\\frac 1{30}\\frac {f(n)-f(m)}{4!}+\\cdots +B_{2k}\\frac {f^{(2k-1)}(n)-f^{(2k-1)}(m)}{(2k)!}+R_{2k}.\n\nThe Bernoulli polynomials and periodic function\n\nThe formula is derived below using repeated integration by parts applied to successive intervals [r, r+1] for integers rm, m+1, \\cdots, n-1.  The derivation uses the periodic Bernoulli functions, P_k(x), which are defined in terms of the Bernoulli polynomials B_k(x) for k\n0,1,2 \\cdots.\n\nThe Bernoulli polynomials may be defined recursively by\n\n\\begin{align}\n  B_0(x) &= 1 \\\\\n  B_k'(x) &kB_{k - 1}(x) \\text{ and } \\int_0^1 B_k(x)\\,dx \n 0\\text{ for }k \\ge 1\n\\end{align}\n\nand the periodic Bernoulli functions are defined as\n\n P_k(x) = B_k \\left(x - \\lfloor x\\rfloor\\right) \n\nwhere \\lfloor x \\rfloor denotes the largest integer that is not greater than x so that x - \\lfloor x \\rfloor always lies in the interval [0,1).\n\nIt can be shown that B_k(1) = B_k(0) for all k \\neq 1 so that except for P_1(x), all the periodic Bernoulli functions are continuous.  The functions P_k(x) are sometimes written as \\tilde{B}_k(x).\n\nThe remainder term\n\nThe remainder term R_p can be written as\n\n R_p = (-1)^{p+1}\\int_m^n f^{(p)}(x) {P_{p}(x) \\over p!}\\,dx. \n\nWhen k>0, it can be shown that\n\n\\left| B_k (x) \\right| \\le \\frac{2 \\cdot k!}{(2\\pi)^k}\\zeta(k)\n\nwhere \\zeta  denotes the Riemann zeta function; one approach to prove this inequality is to obtain the Fourier series for the polynomials B_k(x).   The bound is achieved for even k when x is zero.  The term \\zeta(k) may be omitted for odd k but the proof in this case is more complex (see Lehmer). Using this inequality, the size of the remainder term can be estimated using\n\n\\left|R_p\\right|\\leq\\frac{2 \\zeta (p)}{(2\\pi)^{p}}\\int_m^n\\left|f^{(p)}(x)\\right|\\ \\, dx. \n\nApplicable formula\n\nWe can use the formula as a means of approximating a finite integral, with the following simple formula:\n\n\\begin{align}\nI & = \\int_{x_0}^{x_N} f(x)\\,\\mathrm{d}x \\\\[6pt]\n& = h\\left(\\frac{f_{0}}{2} + f_1 +f_2+\\cdots+f_{N-1} + \\frac{f_{N}}{2} \\right) + \\frac{h^2}{12}[f'_0 - f'_N] - \\frac{h^4}{720}[f_0 - f_N]+ \\cdots,\n\\end{align}\n\nwhere N is the number of points in the interval of integration from  x_0  to  x_N  and h is the distance between points so that  h=(x_N - x_0)/N.  Note the series above is usually not convergent;  indeed, often the terms will increase rapidly after a number of iterations.  Thus, attention generally needs to be paid to the remainder term.\n \nThis may be viewed as an extension of the trapezoid rule by the inclusion of correction terms.\n\nApplications\n\nThe Basel problem\n\nThe Basel problem asks to determine the sum\n\n 1 + \\frac14 + \\frac19 + \\frac1{16} + \\frac1{25} + \\cdots \\sum_{n\n1}^\\infty \\frac{1}{n^2}. \n\nEuler computed this sum to 20 decimal places with only a few terms of the Euler–Maclaurin formula in 1735. This probably convinced him that the sum equals \\pi^2/6, which he proved in the same year.Pengelley, David J. [http://www.math.nmsu.edu/~davidp/euler2k2.pdf \"Dances between continuous and discrete: Euler's summation formula\"], in: Robert Bradley and Ed Sandifer (Eds), Proceedings, Euler 2K+2 Conference (Rumford, Maine, 2002), Euler Society, 2003. Parseval's identity for the Fourier series of f(x)=x gives the same result.\n\nSums involving a polynomial\n\nIf f is a polynomial and p is big enough, then the remainder term vanishes.  For instance, if f(x)x^3, we can choose p\n2 to obtain after simplification\n\n\\sum_{i0}^n i^3 \n \\left(\\frac{n(n + 1)}{2}\\right)^2\n\n(see Faulhaber's formula).\n\nNumerical integration\n\nThe Euler–Maclaurin formula is also used for detailed error analysis in numerical quadrature. It explains the superior performance of the trapezoidal rule on smooth periodic functions and is used in certain extrapolation methods. Clenshaw–Curtis quadrature is essentially a change of variables to cast an arbitrary integral in terms of integrals of periodic functions where the Euler–Maclaurin approach is very accurate (in that particular case the Euler–Maclaurin formula takes the form of a discrete cosine transform). This technique is known as a periodizing transformation.\n\nAsymptotic expansion of sums\n\nIn the context of computing asymptotic expansions of sums and series, usually the most useful form of the Euler–Maclaurin formula is\n\n\\sum_{na}^b f(n) \\sim \\int_a^b f(x)\\,dx + \\frac{f(b) + f(a)}{2} + \\sum_{k\n1}^\\infty \\,\\frac{B_{2k}}{(2k)!} (f^{(2k - 1)}(b) - f^{(2k - 1)}(a))\n\nwhere a and b are integers., 23.1.30 Often the expansion remains valid even after taking the limits a\\rightarrow-\\infty or b\\rightarrow +\\infty or both.  In many cases the integral on the right-hand side can be evaluated in closed form in terms of elementary functions even though the sum on the left-hand side cannot. Then all the terms in the asymptotic series can be expressed in terms of elementary functions.  For example,\n\n\\sum_{k0}^\\infty \\frac{1}{(z + k)^2} \\sim \\underbrace{\\int_0^\\infty\\frac{1}{(z + k)^2}\\,dk}_{\n 1/z} + \\frac{1}{2z^2} + \\sum_{t = 1}^\\infty \\frac{B_{2t}}{z^{2t + 1}}.\n\nHere the left-hand side is equal to \\psi^{(1)}(z), namely the first-order polygamma function defined through \\psi^{(1)}(z) = D^2( \\log \\Gamma(z) );  the gamma function \\Gamma(z)  is equal to (z-1)!  if z  is a positive integer. This results in an asymptotic expansion for \\psi^{(1)}(z).   That expansion, in turn, serves as the starting point for one of the derivations of precise error estimates for Stirling's approximation of the factorial function.\n\nExamples\n\nIf  is an integer greater than 1 we have:\n\\sum_{k1}^n \\frac{1}{k^s} \\approx \\frac 1{s-1}+\\frac 12-\\frac 1{(s-1)n^{s-1}}+\\frac 1{2n^s}+\\sum_{i\n1}\\frac{B_{2i}}{(2i)!}\\left[\\frac{(s+2i-2)!}{(s-1)!}-\\frac{(s+2i-2)!}{(s-1)!n^{s+2i-1}}\\right]\n\nCollecting the constants into a value of the Riemann zeta function, we can write an asymptotic expansion:\n\\sum_{k1}^n \\frac{1}{k^s} \\sim\\zeta(s)-\\frac 1{(s-1)n^{s-1}}+\\frac 1{2n^s}-\\sum_{i\n1}\\frac{B_{2i}}{(2i)!}\\frac{(s+2i-2)!}{(s-1)!n^{s+2i-1}}\n\nFor  equal to 2 this simplifies to\n\\sum_{k1}^n \\frac{1}{k^2} \\sim\\zeta(2)-\\frac 1n+\\frac 1{2n^2}-\\sum_{i\n1}\\frac{B_{2i}}{n^{2i+1}}\nor\n\\sum_{k=1}^n \\frac{1}{k^2} \\sim \\frac{\\pi^2}{6} -\\frac{1}{n} +\\frac{1}{2n^2} -\\frac{1}{6n^3}+\\frac{1}{30n^5}-\\frac{1}{42n^7}. \n\nWe can also derive (from Equation 1 below) the perhaps not-so-useful formula:\n \\sum_{k1}^n \\frac{1}{k^s} \n \\frac{1}{n^{s-1}} + s \\int_1^n \\frac{\\lfloor x\\rfloor}{x^{s+1}} dx \\qquad \\text{with }\\quad s \\in \\R \\setminus \\{1\\}\n\nWhen  is 1, we get the following for the so-called harmonic numbers:\n\\begin{align}\n\\sum_{k1}^n \\frac{1}{k} &\n \\log n + \\frac{1}{2} + \\frac{1}{2n} - \\int_1^n \\frac{x-\\lfloor x\\rfloor -1/2}{x^{2}} dx\\\\\n&\\approx \\log n + \\gamma +\\frac{1}{2n} -\\frac{1}{12n^2} + \\frac{1}{120n^4} - \\frac{1}{252n^6}\n\\end{align}\n\nwhere \\gamma \\approx 0.5772156649015328606065 is the Euler constant,\n\nProofs \n\nDerivation by mathematical induction \n\nWe follow the argument given in Apostol.\n\nThe Bernoulli polynomials  and the periodic Bernoulli functions  for  were introduced above.\n\nThe first several Bernoulli polynomials are\n\n\\begin{align}\n  B_1(x) &= x - \\frac{1}{2} \\\\\n  B_2(x) &= x^2 - x + \\frac{1}{6} \\\\\n  B_3(x) &= x^3 - \\frac{3}{2}x^2 + \\frac{1}{2}x \\\\\n  B_4(x) &= x^4 - 2x^3 + x^2 - \\frac{1}{30} \\\\\n         & \\,\\,\\,\\vdots\n\\end{align}\n\nThe values  are the Bernoulli numbers.  Notice that for  we have\n\nB_n(0) B_n(1) \n B_n\\quad(n\\text{th Bernoulli number})\n\nFor ,\n\n B_1(0) -B_1(1) \n B_1\n\nThe functions  agree with the Bernoulli polynomials on the interval   and are periodic with period 1.  Furthermore, except when , they are also continuous. Thus,\n\n P_n(0) P_n(1) \n B_n \\quad (n \\neq 1)\n\nLet  be an integer, and consider the integral\n\n \\int_k^{k + 1} f(x)\\,dx = \\int_k^{k + 1} u\\,dv\n\nwhere\n\n\\begin{align}\n   u &= f(x) \\\\\n  du &= f'(x)\\,dx \\\\\n  dv &P_0(x)\\,dx && \\text{since }P_0(x) \n 1 \\\\\n   v &= P_1(x)\n\\end{align}\n\nIntegrating by parts, we get\n\n\\begin{align}\n \\int_k^{k + 1} f(x)\\,dx &= \\Big[uv\\Big]_k^{k + 1} - \\int_k^{k + 1} v\\,du \\\\[8pt]\n                         &= \\Big[f(x)P_1(x)\\Big]_k^{k + 1} - \\int_k^{k+1} f'(x)P_1(x)\\,dx \\\\[8pt]\n                         &= B_1(1)f(k+1)-B_1(0)f(k) - \\int_k^{k+1} f'(x)P_1(x)\\,dx\n\\end{align}\n\nUsing B_1(0)-1/2, B_1(1)\n1/2, and summing the above from k 0 to k \n n − 1, we get\n\n\\begin{align}\n\\int_0^n f(x)\\, dx &= \\int_0^1 f(x)\\,dx + \\dotsb + \\int_{n-1}^n f(x)\\,dx  \\\\[8pt]\n&= \\frac{f(0)}{2}+ f(1) + \\dotsb + f(n-1) + {f(n) \\over 2} - \\int_0^n f'(x) P_1(x)\\,dx\n\\end{align}\n\nAdding (f(n) − f(0))/2 to both sides and rearranging, we have\n\n \\sum_{k1}^n f(k) \n \\int_0^n f(x)\\,dx + {f(n) - f(0) \\over 2} + \\int_0^n f'(x) P_1(x)\\,dx\\qquad (1)\n\nThe last two terms therefore give the error when the integral is taken to approximate the sum.\n\nNext, consider\n\n \\int_k^{k+1} f'(x)P_1(x)\\,dx = \\int_k^{k + 1} u\\,dv \n\nwhere\n\n\\begin{align}\n   u &= f'(x) \\\\\n  du &= f(x)\\,dx \\\\\n  dv &= P_1(x)\\,dx \\\\\n   v &= \\frac{1}{2}P_2(x)\n\\end{align}\n\nIntegrating by parts again, we get\n\n\\begin{align}\n  \\Big[uv\\Big]_k^{k + 1} - \\int_k^{k + 1} v\\,du &= \\left[ {f'(x)P_2(x) \\over 2} \\right]_k^{k+1} - {1 \\over 2}\\int_k^{k+1} f(x)P_2(x)\\,dx \\\\\n                  &= {B_2 \\over 2}(f'(k + 1) - f'(k)) - {1 \\over 2}\\int_k^{k + 1} f(x)P_2(x)\\,dx\n\\end{align}\n\nThen summing from k 0 to k \n n − 1, and then replacing the last integral in (1) with what we have thus shown to be equal to it, we have\n\n \\sum_{k1}^n f(k) \n \\int_0^n f(x)\\,dx + {f(n) - f(0) \\over 2} + \\frac{B_2}{2}(f'(n) - f'(0)) - {1 \\over 2}\\int_0^n f(x)P_2(x)\\,dx.  \n\nBy now the reader will have guessed that this process can be iterated.  In this way we get a proof of the Euler–Maclaurin summation formula which can be formalized by mathematical induction, in which the induction step relies on integration by parts and on the identities for periodic Bernoulli functions. Euler–Maclaurin formula. http://en.wikipedia.org/?curid=9637."
  }
}
