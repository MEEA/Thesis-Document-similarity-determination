{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=8811",
  "eid" : "ea99d800-52b1-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778473344,
  "textBody" : "In mathematics, the discrete Fourier transform (DFT) converts a finite sequence of equally-spaced samples of a function into a same-length sequence of equally-spaced samples of the discrete-time Fourier transform (DTFT), which is a complex-valued function of frequency. The interval at which the DTFT is sampled is the reciprocal of the duration of the input sequence.  An inverse DFT is a Fourier series, using the DTFT samples as coefficients of complex sinusoids at the corresponding DTFT frequencies.  It has the same sample-values as the original input sequence.  The DFT is therefore said to be a frequency domain representation of the original input sequence.  If the original sequence spans all the non-zero values of a function, its DTFT is continuous (and periodic), and the DFT provides discrete samples of one cycle.  If the original sequence is one cycle of a periodic function, the DFT provides all the non-zero values of one DTFT cycle.\n\nThe DFT is the most important discrete transform, used to perform Fourier analysis in many practical applications.  In digital signal processing, the function is any quantity or signal that varies over time, such as the pressure of a sound wave, a radio signal, or daily temperature readings, sampled over a finite time interval (often defined by a window function). In image processing, the samples can be the values of pixels along a row or column of a raster image. The DFT is also used to efficiently solve partial differential equations, and to perform other operations such as convolutions or multiplying large integers.\n\nSince it deals with a finite amount of data, it can be implemented in computers by numerical algorithms or even dedicated hardware. These implementations usually employ efficient fast Fourier transform (FFT) algorithms;Cooley et al., 1969 so much so that the terms \"FFT\" and \"DFT\" are often used interchangeably.  Prior to its current usage, the \"FFT\" initialism may have also been used for the ambiguous term \"finite Fourier transform\".\n\nDefinition\n\nThe discrete Fourier transform transforms a sequence of N complex numbers    \\left \\{ \\mathbf{ x_n } \\right \\} :x_0, x_1, \\ldots, x_{N-1} into another sequence of complex numbers,  \\left \\{ \\mathbf{X_k} \\right \\} :\n X_0, X_1, \\ldots, X_{N-1}, which is defined by\n\nwhere the last expression follows from the first one by Euler's formula.\n\nThe transform is sometimes denoted by the symbol \\mathcal{F}, as in \\mathbf{X} \\mathcal{F} \\left \\{ \\mathbf{x} \\right \\}  or \\mathcal{F} \\left ( \\mathbf{x} \\right ) or \\mathcal{F} \\mathbf{x}.As a linear transformation on a finite-dimensional vector space, the DFT expression can also be written in terms of a DFT matrix; when scaled appropriately it becomes a unitary matrix and the Xk can thus be viewed as coefficients of x in an orthonormal basis.\n\nMotivation\n\n can also be evaluated outside the domain , and that extended sequence is -periodic. Accordingly, other sequences of  indices are sometimes used,  such as  (if  is even) and  (if  is odd), which amounts to swapping the left and right halves of the result of the transform.\n\n can be interpreted or derived in various ways, for example:\n*It completely describes the discrete-time Fourier transform (DTFT) of an N-periodic sequence, which comprises only discrete frequency components.  (Using the DTFT with periodic data)\n*It can also provide uniformly spaced samples of the continuous DTFT of a finite length sequence.  (Sampling the DTFT)\n*It is the cross correlation of the input sequence, xn, and a complex sinusoid at frequency k/N.  Thus it acts like a matched filter for that frequency.\n*It is the discrete analogy of the formula for the coefficients of a Fourier series:\n\nwhich is also N-periodic.  In the domain  ,  this is the inverse transform of .  In this interpretation, each X_k is a complex number that encodes both amplitude and phase of a complex sinusoidal component  (e^{i 2 \\pi k n / N})  of function x_n.  The sinusoid's frequency is k cycles per N samples.  Its amplitude and phase are:\n\n:|X_k|/N = \\sqrt{\\operatorname{Re}(X_k)^2 + \\operatorname{Im}(X_k)^2}/N\n:\\arg(X_k) \\operatorname{atan2}\\big( \\operatorname{Im}(X_k), \\operatorname{Re}(X_k) \\big)\n-i\\cdot \\operatorname{ln}\\left(\\frac{X_k}\\right),\n\nwhere atan2 is the two-argument form of the arctan function. In polar form X_k |X_k| e^{i \\arg(X_k)} \n |X_k| \\operatorname{cis} \\arg(X_k) where cis is the mnemonic for cos + i sin.\n\nThe normalization factor multiplying the DFT and IDFT (here 1 and 1/N) and the signs of the exponents are merely conventions, and differ in some treatments. The only requirements of these conventions are that the DFT and IDFT have opposite-sign exponents and that the product of their normalization factors be 1/N.  A normalization of \\scriptstyle \\sqrt{1/N} for both the DFT and IDFT, for instance, makes the transforms unitary. A discrete impulse, x_n 1 at n \n 0 and 0 otherwise; might transform to X_k 1 for all k (use normalization factors 1 for DFT and 1/N for IDFT). A DC signal, X_k \n 1 at k 0 and 0 otherwise; might inversely transform to x_n \n 1 for all n (use 1/N for DFT and 1 for IDFT) which is consistent with viewing DC as the mean average of the signal.\n\nExample\n\nLet N=4 and\n\\mathbf{x} =\n\\begin{pmatrix}\nx_0 \\\\\nx_1 \\\\\nx_2 \\\\\nx_3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 \\\\\n2-i \\\\\n-i \\\\\n-1+2i\n\\end{pmatrix}\n. Here we demonstrate how to calculate the DFT of \\mathbf{x} using :\n\nX_0 e^{-i 2 \\pi 0 \\cdot 0 / 4} \\cdot 1 + e^{-i 2 \\pi 0 \\cdot 1 / 4} \\cdot (2-i) + e^{-i 2 \\pi 0 \\cdot 2 / 4} \\cdot (-i) + e^{-i 2 \\pi 0 \\cdot 3 / 4} \\cdot (-1+2i) \n 2\n\nX_1 e^{-i 2 \\pi 1 \\cdot 0 / 4} \\cdot 1 + e^{-i 2 \\pi 1 \\cdot 1 / 4} \\cdot (2-i) + e^{-i 2 \\pi 1 \\cdot 2 / 4} \\cdot (-i) + e^{-i 2 \\pi 1 \\cdot 3 / 4} \\cdot (-1+2i) \n -2-2i\n\nX_2 e^{-i 2 \\pi 2 \\cdot 0 / 4} \\cdot 1 + e^{-i 2 \\pi 2 \\cdot 1 / 4} \\cdot (2-i) + e^{-i 2 \\pi 2 \\cdot 2 / 4} \\cdot (-i) + e^{-i 2 \\pi 2 \\cdot 3 / 4} \\cdot (-1+2i) \n -2i\n\nX_3 e^{-i 2 \\pi 3 \\cdot 0 / 4} \\cdot 1 + e^{-i 2 \\pi 3 \\cdot 1 / 4} \\cdot (2-i) + e^{-i 2 \\pi 3 \\cdot 2 / 4} \\cdot (-i) + e^{-i 2 \\pi 3 \\cdot 3 / 4} \\cdot (-1+2i) \n 4+4i\n\n\\mathbf{X} =\n\\begin{pmatrix}\nX_0 \\\\\nX_1 \\\\\nX_2 \\\\\nX_3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n2 \\\\\n-2-2i \\\\\n-2i \\\\\n4+4i\n\\end{pmatrix}\n\nProperties\n\nCompleteness\n\nThe discrete Fourier transform is an invertible, linear transformation\n\n\\mathcal{F}\\colon\\mathbb{C}^N \\to \\mathbb{C}^N\n\nwith \\mathbb{C} denoting the set of complex numbers. In other words, for any N>0, an N-dimensional complex vector has a DFT and an IDFT which are in turn N-dimensional complex vectors.\n\nThe inverse transform is given by:\n\nx_n \\frac{1}{N} \\sum_{k\n0}^{N-1} X_k\\cdot e^{i 2 \\pi k n / N}\n\nOrthogonality \n\nThe vectors u_k\\left[ e^{ \\frac{2\\pi i}{N} kn} \\;|\\; n\n0,1,\\ldots,N-1 \\right]^T \nform an orthogonal basis over the set of N-dimensional complex vectors:\n\nu^T_k u_{k'}^* \n \\sum_{n\n0}^{N-1} \\left(e^{ \\frac{2\\pi i}{N} kn}\\right) \\left(e^{\\frac{2\\pi i}{N} (-k')n}\\right)\n \\sum_{n\n0}^{N-1} e^{ \\frac{2\\pi i}{N} (k-k') n} \n = N~\\delta_{kk'}\n\nwhere ~\\delta_{kk'} is the Kronecker delta. (In the last step, the summation is trivial if kk', where it is 1+1+⋅⋅⋅\nN, and otherwise is a geometric series that can be explicitly summed to obtain zero.)  This orthogonality condition can be used to derive the formula for the IDFT from the definition of the DFT, and is equivalent to the unitarity property below.\n\nThe Plancherel theorem and Parseval's theorem \n\nIf Xk and Yk are the DFTs of xn and yn respectively then the Parseval's theorem states:\n\n\\sum_{n0}^{N-1} x_n y^*_n \n \\frac{1}{N} \\sum_{k=0}^{N-1} X_k Y^*_k\n\nwhere the star denotes complex conjugation.  Plancherel theorem is a special case of the Parseval's theorem and states:\n\n\\sum_{n0}^{N-1} |x_n|^2 \n \\frac{1}{N} \\sum_{k=0}^{N-1} |X_k|^2.\n\nThese theorems are also equivalent to the unitary condition below.\n\nPeriodicity\n\nThe periodicity can be shown directly from the definition:\n\nX_{k+N} \\ \\stackrel{\\mathrm{def}}{} \\ \\sum_{n\n0}^{N-1} x_n e^{-\\frac{2\\pi i}{N} (k+N) n} \\sum_{n\n0}^{N-1} x_n e^{-\\frac{2\\pi i}{N} k n}  \\underbrace{e^{-2 \\pi i n}}_{1} \\sum_{n\n0}^{N-1} x_n e^{-\\frac{2\\pi i}{N} k n} = X_k. \n\nSimilarly, it can be shown that the IDFT formula leads to a periodic extension.\n\nShift theorem\n\nMultiplying x_n by a linear phase e^{\\frac{2\\pi i}{N}n m} for some integer m corresponds to a circular shift of the output X_k: X_k is replaced by X_{k-m}, where the subscript is interpreted modulo N (i.e., periodically).  Similarly, a circular shift of the input x_n corresponds to multiplying the output X_k by a linear phase. Mathematically, if \\{x_n\\} represents the vector x then\n\nif \\mathcal{F}(\\{x_n\\})_k=X_k\n\nthen \\mathcal{F}(\\{ x_n\\cdot e^{\\frac{2\\pi i}{N}n m} \\})_k=X_{k-m}\n\nand \\mathcal{F}(\\{x_{n-m}\\})_k=X_k\\cdot e^{-\\frac{2\\pi i}{N}k m}\n\nCircular convolution theorem and cross-correlation theorem\n\nThe convolution theorem for the discrete-time Fourier transform indicates that a convolution of two infinite sequences can be obtained as the inverse transform of the product of the individual transforms.  An important simplification occurs when the sequences are of finite length, N.  In terms of the DFT and inverse DFT, it can be written as follows:\n\n\\mathcal{F}^{-1} \\left \\{ \\mathbf{X\\cdot Y} \\right \\}_n \\ \\sum_{l\n0}^{N-1}x_l \\cdot (y_N)_{n-l} \\ \\ \\stackrel{\\mathrm{def}}{=} \\ \\ (\\mathbf{x * y_N})_n\\ ,\n\nwhich is the convolution of the \\mathbf{x} sequence with a \\mathbf{y} sequence extended by periodic summation:\n\n(\\mathbf{y_N})_n \\ \\stackrel{\\mathrm{def}}{} \\ \\sum_{p\n-\\infty}^{\\infty} y_{(n-pN)} = y_{n (mod N)}. \\,\n\nSimilarly, the cross-correlation of  \\mathbf{x}  and  \\mathbf{y_N}  is given by:\n\n\\mathcal{F}^{-1} \\left \\{ \\mathbf{X^* \\cdot Y} \\right \\}_n\n\\sum_{l\n0}^{N-1}x_l^* \\cdot (y_N)_{n+l} \\ \\ \\stackrel{\\mathrm{def}}{=} \\ \\ (\\mathbf{x \\star y_N})_n\\ .\n\nWhen either sequence contains a string of zeros, of length L,  L+1 of the circular convolution outputs are equivalent to values of  \\mathbf{x * y}.  Methods have also been developed to use this property as part of an efficient process that constructs  \\mathbf{x * y}  with an \\mathbf{x} or \\mathbf{y} sequence potentially much longer than the practical transform size (N).  Two such methods are called overlap-save and overlap-add.T. G. Stockham, Jr., \"[http://dl.acm.org/citation.cfm?id=1464209 High-speed convolution and correlation],\" in 1966 Proc. AFIPS Spring Joint Computing Conf. Reprinted in Digital Signal Processing, L. R. Rabiner and C. M. Rader, editors, New York: IEEE Press, 1972.  The efficiency results from the fact that a direct evaluation of either summation (above) requires \\scriptstyle O(N^2) operations for an output sequence of length N.  An indirect method, using transforms, can take advantage of the \\scriptstyle O(N\\log N) efficiency of the fast Fourier transform (FFT) to achieve much better performance.  Furthermore, convolutions can be used to efficiently compute DFTs via Rader's FFT algorithm and Bluestein's FFT algorithm.\n\nConvolution theorem duality \n\nIt can also be shown that:\n\n\\mathcal{F} \\left \\{ \\mathbf{x\\cdot y} \\right \\}_k \\ \\stackrel{\\mathrm{def}}{=}\n\\sum_{n=0}^{N-1} x_n \\cdot y_n \\cdot e^{-\\frac{2\\pi i}{N} k n}\n\n:=\\frac{1}{N} (\\mathbf{X * Y_N})_k, \\,   which is the circular convolution of \\mathbf{X} and \\mathbf{Y}.\n\nTrigonometric interpolation polynomial\n\nThe trigonometric interpolation polynomial\np(t) = \\frac{1}{N} \\left[ X_0 + X_1 e^{2\\pi it} + \\cdots + X_{N/2-1} e^{(N/2-1)2\\pi it} + X_{N/2} \\cos(N\\pi t) + X_{N/2+1} e^{(-N/2+1)2\\pi it} + \\cdots + X_{N-1} e^{-2\\pi it} \\right] for N even ,\np(t) = \\frac{1}{N} \\left[ X_0 + X_1 e^{2\\pi it} + \\cdots + X_{\\lfloor N/2 \\rfloor} e^{\\lfloor N/2 \\rfloor 2\\pi it} + X_{\\lfloor N/2 \\rfloor+1} e^{-\\lfloor N/2 \\rfloor 2\\pi it} + \\cdots + X_{N-1} e^{-2\\pi it} \\right]  for N odd,\nwhere the coefficients Xk are given by the DFT of xn above, satisfies the interpolation property p(n/N) x_n for n\n0,\\ldots,N-1.\n\nFor even N, notice that the Nyquist component \\frac{X_{N/2}}{N} \\cos(N\\pi t) is handled specially.\n\nThis interpolation is not unique: aliasing implies that one could add N to any of the complex-sinusoid frequencies (e.g. changing e^{-it} to e^{i(N-1)t} ) without changing the interpolation property, but giving different values in between the x_n points.  The choice above, however, is typical because it has two useful properties.  First, it consists of sinusoids whose frequencies have the smallest possible magnitudes: the interpolation is bandlimited. Second, if the  x_n are real numbers, then p(t) is real as well.\n\nIn contrast, the most obvious trigonometric interpolation polynomial is the one in which the frequencies range from 0 to N-1 (instead of roughly -N/2 to +N/2 as above), similar to the inverse DFT formula. This interpolation does not minimize the slope, and is not generally real-valued for real x_n; its use is a common mistake.\n\nThe unitary DFT \n\nAnother way of looking at the DFT is to note that in the above discussion, the DFT can be expressed as the DFT matrix, a Vandermonde matrix, \nintroduced by Sylvester in 1867,\n\\mathbf{F} =\n\\begin{bmatrix}\n \\omega_N^{0 \\cdot 0}     & \\omega_N^{0 \\cdot 1}     & \\ldots & \\omega_N^{0 \\cdot (N-1)}     \\\\\n \\omega_N^{1 \\cdot 0}     & \\omega_N^{1 \\cdot 1}     & \\ldots & \\omega_N^{1 \\cdot (N-1)}     \\\\\n \\vdots                   & \\vdots                   & \\ddots & \\vdots                       \\\\\n \\omega_N^{(N-1) \\cdot 0} & \\omega_N^{(N-1) \\cdot 1} & \\ldots & \\omega_N^{(N-1) \\cdot (N-1)} \\\\\n\\end{bmatrix}\n\nwhere\n\\omega_N = e^{-2 \\pi i/N}\\,\nis a primitive Nth root of unity.\n\nThe inverse transform is then given by the inverse of the above matrix,\n\\mathbf{F}^{-1}=\\frac{1}{N}\\mathbf{F}^*\n\nWith unitary normalization constants 1/\\sqrt{N}, the DFT becomes a unitary transformation, defined by a unitary matrix:\n\n\\mathbf{U}=\\mathbf{F}/\\sqrt{N}\n\\mathbf{U}^{-1}=\\mathbf{U}^*\n|\\det(\\mathbf{U})|=1\nwhere det()  is the determinant function. The determinant is the product of the eigenvalues, which are always \\pm 1 or \\pm i as described below.  In a real vector space, a unitary transformation can be thought of as simply a rigid rotation of the coordinate system, and all of the properties of a rigid rotation can be found in the unitary DFT.\n\nThe orthogonality of the DFT is now expressed as an orthonormality condition (which arises in many areas of mathematics as described in root of unity):\n\\sum_{m0}^{N-1}U_{km}U_{mn}^*\n\\delta_{kn}\n\nIf X  is defined as the unitary DFT of the vector x, then\nX_k\\sum_{n\n0}^{N-1} U_{kn}x_n\n\nand the Plancherel theorem is expressed as\n\\sum_{n0}^{N-1}x_n y_n^* \n \\sum_{k=0}^{N-1}X_k Y_k^*\n\nIf we view the DFT as just a coordinate transformation which simply specifies the components of a vector in a new coordinate system, then the above is just the statement that the dot product of two vectors is preserved under a unitary DFT transformation. For the special case \\mathbf{x} = \\mathbf{y}, this implies that the length of a vector is preserved as well—this is just Parseval's theorem,\n\\sum_{n0}^{N-1}|x_n|^2 \n \\sum_{k=0}^{N-1}|X_k|^2\n\nA consequence of the circular convolution theorem is that the DFT matrix  diagonalizes any circulant matrix.\n\nExpressing the inverse DFT in terms of the DFT \n\nA useful property of the DFT is that the inverse DFT can be easily expressed in terms of the (forward) DFT, via several well-known \"tricks\".  (For example, in computations, it is often convenient to only implement a fast Fourier transform corresponding to one transform direction and then to get the other transform direction from the first.)\n\nFirst, we can compute the inverse DFT by reversing all but one of the inputs (Duhamel et al., 1988):\n\n\\mathcal{F}^{-1}(\\{x_n\\}) = \\mathcal{F}(\\{x_{N - n}\\}) / N\n\n(As usual, the subscripts are interpreted modulo N; thus, for n0, we have x_{N-0}\nx_0.)\n\nSecond, one can also conjugate the inputs and outputs:\n\n\\mathcal{F}^{-1}(\\mathbf{x}) = \\mathcal{F}(\\mathbf{x}^*)^* / N\n\nThird, a variant of this conjugation trick, which is sometimes preferable because it requires no modification of the data values, involves swapping real and imaginary parts (which can be done on a computer simply by modifying pointers). Define swap(x_n) as x_n with its real and imaginary parts swapped—that is, if x_n = a + b i then swap(x_n) is b + a i.  Equivalently, swap(x_n) equals i x_n^*.  Then\n\n\\mathcal{F}^{-1}(\\mathbf{x}) = \\textrm{swap}(\\mathcal{F}(\\textrm{swap}(\\mathbf{x}))) / N\n\nThat is, the inverse transform is the same as the forward transform with the real and imaginary parts swapped for both input and output, up to a normalization (Duhamel et al., 1988).\n\nThe conjugation trick can also be used to define a new transform, closely related to the DFT, that is involutory—that is, which is its own inverse.  In particular, T(\\mathbf{x}) \\mathcal{F}(\\mathbf{x}^*) / \\sqrt{N} is clearly its own inverse: T(T(\\mathbf{x})) \n \\mathbf{x}.  A closely related involutory transformation (by a factor of (1+i) /√2) is H(\\mathbf{x}) = \\mathcal{F}((1+i) \\mathbf{x}^*) / \\sqrt{2N}, since the (1+i) factors in H(H(\\mathbf{x})) cancel the 2.  For real inputs \\mathbf{x}, the real part of H(\\mathbf{x}) is none other than the discrete Hartley transform, which is also involutory.\n\nEigenvalues and eigenvectors \n\nThe eigenvalues of the DFT matrix are simple and well-known, whereas the eigenvectors are complicated, not unique, and are the subject of ongoing research.\n\nConsider the unitary form \\mathbf{U} defined above for the DFT of length N, where\n\\mathbf{U}_{m,n} \\frac1{\\sqrt{N}}\\omega_N^{(m-1)(n-1)} \n \\frac1{\\sqrt{N}}e^{-\\frac{2\\pi i}N (m-1)(n-1)}.\nThis matrix satisfies the matrix polynomial equation:\n\\mathbf{U}^4 = \\mathbf{I}.\nThis can be seen from the inverse properties above: operating \\mathbf{U} twice gives the original data in reverse order, so operating \\mathbf{U} four times gives back the original data and is thus the identity matrix.  This means that the eigenvalues \\lambda satisfy the equation:\n\\lambda^4 = 1.\nTherefore, the eigenvalues of \\mathbf{U} are the fourth roots of unity: \\lambda is +1, −1, +i,  or −i.\n\nSince there are only four distinct eigenvalues for this N\\times N matrix, they have some multiplicity.  The multiplicity gives the number of linearly independent eigenvectors corresponding to each eigenvalue.  (Note that there are N independent eigenvectors; a unitary matrix is never defective.)\n\nThe problem of their multiplicity was solved by McClellan and Parks (1972), although it was later shown to have been equivalent to a problem solved by Gauss (Dickinson and Steiglitz, 1982).  The multiplicity depends on the value of N modulo 4, and is given by the following table:\n\nOtherwise stated, the characteristic polynomial of \\mathbf{U} is:\n\\det (\\lambda I - \\mathbf{U})=\n(\\lambda-1)^{\\left\\lfloor \\tfrac {N+4}{4}\\right\\rfloor}\n(\\lambda+1)^{\\left\\lfloor \\tfrac {N+2}{4}\\right\\rfloor}\n(\\lambda+i)^{\\left\\lfloor \\tfrac {N+1}{4}\\right\\rfloor}\n(\\lambda-i)^{\\left\\lfloor \\tfrac {N-1}{4}\\right\\rfloor}.\n\nNo simple analytical formula for general eigenvectors is known.   Moreover, the eigenvectors are not unique because any linear combination of eigenvectors for the same eigenvalue is also an eigenvector for that eigenvalue.  Various researchers have proposed different choices of eigenvectors, selected to satisfy useful properties like orthogonality and to have \"simple\" forms (e.g., McClellan and Parks, 1972; Dickinson and Steiglitz, 1982; Grünbaum, 1982; Atakishiyev and Wolf, 1997; Candan et al., 2000; Hanna et al., 2004; Gurevich and Hadani, 2008).\n\nA straightforward approach is to discretize an eigenfunction of the continuous Fourier transform,\nof which the most famous is the Gaussian function.\nSince periodic summation of the function means discretizing its frequency spectrum\nand discretization means periodic summation of the spectrum,\nthe discretized and periodically summed Gaussian function yields an eigenvector of the discrete transform:\n*F(m) = \\sum_{k\\in\\mathbb{Z}} \\exp\\left(-\\frac{\\pi\\cdot(m+N\\cdot k)^2}{N}\\right).\nA closed form expression for the series is not known, but it converges rapidly.\n\nTwo other simple closed-form analytical eigenvectors for special DFT period N were found (Kong, 2008):\n\nFor DFT period N 2L + 1 \n 4K +1, where K is an integer, the following is an eigenvector of DFT:\n*F(m)\\prod_{s\nK+1}^L\\left[\\cos\\left(\\frac{2\\pi}{N}m\\right)- \\cos\\left(\\frac{2\\pi}{N}s\\right)\\right]\n\nFor DFT period N 2L \n 4K, where K is an integer, the following is an eigenvector of DFT:\n*F(m)\\sin\\left(\\frac{2\\pi}{N}m\\right)\\prod_{s\nK+1}^{L-1}\\left[\\cos\\left(\\frac{2\\pi}{N}m\\right)- \\cos\\left(\\frac{2\\pi}{N}s\\right)\\right]\n\nThe choice of eigenvectors of the DFT matrix has become important in recent years in order to define a discrete analogue of the fractional Fourier transform—the DFT matrix can be taken to fractional powers by exponentiating the eigenvalues (e.g., Rubio and Santhanam, 2005).  For the continuous Fourier transform, the natural orthogonal eigenfunctions are the Hermite functions, so various discrete analogues of these have been employed as the eigenvectors of the DFT, such as the Kravchuk polynomials (Atakishiyev and Wolf, 1997).  The \"best\" choice of eigenvectors to define a fractional discrete Fourier transform remains an open question, however.\n\nUncertainty principles \n\nProbabilistic uncertainty principle \n\nIf the random variable  is constrained by\n\\sum_{n0}^{N-1}|X_n|^2\n1  ~,\nthen \nP_n=|X_n|^2 \nmay be considered to represent a discrete probability mass function of , with an associated probability mass function constructed from the transformed variable,\nQ_m=N|x_m|^2 ~.\n\nFor the case of continuous functions P(x) and Q(k), the Heisenberg uncertainty principle states that\nD_0(X)D_0(x)\\ge\\frac{1}{16\\pi^2}\nwhere  D_0(X) and D_0(x) are the variances of |X|^2 and |x|^2 respectively, with the equality attained in the case of a suitably normalized Gaussian distribution. Although the variances may be analogously defined for the DFT, an analogous uncertainty principle is not useful, because the uncertainty will not be shift-invariant. Still, a meaningful uncertainty principle has been introduced by Massar and Spindel.\n\nHowever, the Hirschman entropic uncertainty will have a useful analog for the case of the DFT. The Hirschman uncertainty principle is expressed in terms of the Shannon entropy of the two probability functions.\n\nIn the discrete case, the Shannon entropies are defined as\nH(X)-\\sum_{n\n0}^{N-1} P_n\\ln P_n\nand\nH(x)-\\sum_{m\n0}^{N-1} Q_m\\ln Q_m ~,\nand the entropic uncertainty principle becomes\nH(X)+H(x) \\ge \\ln(N) ~.\n\nThe equality is obtained for P_n equal to translations and modulations of a suitably normalized Kronecker comb of period A where A is any exact integer divisor of N. The probability mass function Q_m will then be proportional to a suitably translated Kronecker comb of period BN/A.\n\nDeterministic uncertainty principle \n\nThere is also a well-known deterministic uncertainty principle that uses signal sparsity (or the number of non-zero coefficients). Let \\|x\\|_0 and \\|X\\|_0 be the number of non-zero elements of the time and frequency sequences x_0,x_1,\\ldots,x_{N-1} and X_0,X_1,\\ldots,X_{N-1}, respectively. Then, \nN\\leq \\|x\\|_0 \\cdot \\|X\\|_0.\nAs an immediate consequence of the inequality of arithmetic and geometric means, one also has 2\\sqrt{N}\\leq\\|x\\|_0+\\|X\\|_0. Both uncertainty principles were shown to be tight for specifically-chosen \"picket-fence\" sequences (discrete impulse trains), and find practical use for signal recovery applications.\n\nThe real-input DFT \n\nIf x_0, \\ldots, x_{N-1} are real numbers, as they often are in practical applications, then the DFT obeys the symmetry:\n\nX_{N-k} \\equiv X_{-k} = X_k^*,  where X^*\\, denotes complex conjugation.\n\nIt follows that X0 and XN/2 are real-valued, and the remainder of the DFT is completely specified by just N/2-1 complex numbers.\n\nGeneralized DFT (shifted and non-linear phase)\n\nIt is possible to shift the transform sampling in time and/or frequency domain by some real shifts a and b, respectively. This is sometimes known as a generalized DFT (or GDFT), also called the shifted DFT or offset DFT, and has analogous properties to the ordinary DFT:\n\nX_k \\sum_{n\n0}^{N-1} x_n e^{-\\frac{2 \\pi i}{N} (k+b) (n+a)} \\quad \\quad k = 0, \\dots, N-1.\n\nMost often, shifts of 1/2 (half a sample) are used.\nWhile the ordinary DFT corresponds to a periodic signal in both time and frequency domains, a1/2 produces a signal that is anti-periodic in frequency domain (X_{k+N} \n - X_k) and vice versa for b=1/2.\nThus, the specific case of a b \n 1/2 is known as an odd-time odd-frequency discrete Fourier transform (or O2 DFT).\nSuch shifted transforms are most often used for symmetric data, to represent different boundary symmetries, and for real-symmetric data they correspond to different forms of the discrete cosine and sine transforms.\n\nAnother interesting choice is ab\n-(N-1)/2, which is called the centered DFT (or CDFT).  The centered DFT has the useful property that, when N is a multiple of four, all four of its eigenvalues (see above) have equal multiplicities (Rubio and Santhanam, 2005)Santhanam, Balu; Santhanam, Thalanayar S. [http://thamakau.usc.edu/Proceedings/ICASSP%202007/pdfs/0301385.pdf \"Discrete Gauss-Hermite functions and eigenvectors of the centered discrete Fourier transform\"], Proceedings of the 32nd IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2007, SPTM-P12.4), vol. III, pp. 1385-1388.\n\nThe term GDFT is also used for the non-linear phase extensions of DFT. Hence, GDFT method provides a generalization for constant amplitude orthogonal block transforms including linear and non-linear phase types. GDFT is a framework \nto improve time and frequency domain properties of the traditional DFT, e.g. auto/cross-correlations, by the addition of the properly designed phase shaping function (non-linear, in general) to the original linear phase functions (Akansu and Agirman-Tosun, 2010).Akansu, Ali N.; Agirman-Tosun, Handan \n[http://web.njit.edu/~akansu/PAPERS/AkansuIEEE-TSP2010.pdf \"Generalized Discrete Fourier Transform With Nonlinear Phase\"], IEEE Transactions on Signal Processing, vol. 58, no. 9, pp. 4547-4556, Sept. 2010.\n\nThe discrete Fourier transform can be viewed as a special case of the z-transform, evaluated on the unit circle in the complex plane; more general z-transforms correspond to complex shifts a and b above.\n\nMultidimensional DFT\n\nThe ordinary DFT transforms a one-dimensional sequence or array x_n that is a function of exactly one discrete variable n.  The multidimensional DFT of a multidimensional array x_{n_1, n_2, \\dots, n_d} that is a function of d discrete variables n_\\ell = 0, 1, \\dots, N_\\ell-1 for \\ell in 1, 2, \\dots, d is defined by:\n\nX_{k_1, k_2, \\dots, k_d} \\sum_{n_1\n0}^{N_1-1} \\left(\\omega_{N_1}^{~k_1 n_1} \\sum_{n_20}^{N_2-1} \\left( \\omega_{N_2}^{~k_2 n_2} \\cdots \\sum_{n_d\n0}^{N_d-1} \\omega_{N_d}^{~k_d n_d}\\cdot x_{n_1, n_2, \\dots, n_d} \\right) \\right) \\, , \n\nwhere \\omega_{N_\\ell} \\exp(-2\\pi i/N_\\ell) as above and the d output indices run from k_\\ell \n 0, 1, \\dots, N_\\ell-1.  This is more compactly expressed in vector notation, where we define \\mathbf{n} (n_1, n_2, \\dots, n_d) and \\mathbf{k} \n (k_1, k_2, \\dots, k_d) as d-dimensional vectors of indices from 0 to \\mathbf{N} - 1, which we define as \\mathbf{N} - 1 = (N_1 - 1, N_2 - 1, \\dots, N_d - 1):\n\nX_\\mathbf{k} \\sum_{\\mathbf{n}\n\\mathbf{0}}^{\\mathbf{N}-1} e^{-2\\pi i \\mathbf{k} \\cdot (\\mathbf{n} / \\mathbf{N})} x_\\mathbf{n} \\, ,\n\nwhere the division \\mathbf{n} / \\mathbf{N} is defined as \\mathbf{n} / \\mathbf{N} = (n_1/N_1, \\dots, n_d/N_d) to be performed element-wise, and the sum denotes the set of nested summations above.\n\nThe inverse of the multi-dimensional DFT is, analogous to the one-dimensional case, given by:\n\nx_\\mathbf{n} \\frac{1}{\\prod_{\\ell\n1}^d N_\\ell} \\sum_{\\mathbf{k}=\\mathbf{0}}^{\\mathbf{N}-1} e^{2\\pi i \\mathbf{n} \\cdot (\\mathbf{k} / \\mathbf{N})} X_\\mathbf{k} \\, .\n\nAs the one-dimensional DFT expresses the input x_n as a superposition of sinusoids, the multidimensional DFT expresses the input as a superposition of plane waves, or multidimensional sinusoids. The direction of oscillation in space is \\mathbf{k} / \\mathbf{N}. The amplitudes  are X_\\mathbf{k}.  This decomposition is of great importance for everything from digital image processing (two-dimensional) to solving partial differential equations. The solution is broken up into plane waves.\n\nThe multidimensional DFT can be computed by the composition of a sequence of one-dimensional DFTs along each dimension.  In the two-dimensional case x_{n_1,n_2} the N_1 independent DFTs of the rows (i.e., along n_2) are computed first to form a new array y_{n_1,k_2}. Then the N_2 independent DFTs of y along the columns (along n_1) are computed to form the final result X_{k_1,k_2}.  Alternatively the columns can be computed first and then the rows. The order is immaterial because the nested summations above commute.\n\nAn algorithm to compute a one-dimensional DFT is thus sufficient to efficiently compute a multidimensional DFT.  This approach is known as the row-column algorithm. There are also intrinsically multidimensional FFT algorithms.\n\nThe real-input multidimensional DFT \n\nFor input data x_{n_1, n_2, \\dots, n_d} consisting of real numbers, the DFT outputs have a conjugate symmetry similar to the one-dimensional case above:\n\nX_{k_1, k_2, \\dots, k_d} = X_{N_1 - k_1, N_2 - k_2, \\dots, N_d - k_d}^* ,\n\nwhere the star again denotes complex conjugation and the \\ell-th subscript is again interpreted modulo N_\\ell (for \\ell = 1,2,\\ldots,d).\n\nApplications \n\nThe DFT has seen wide usage across a large number of fields; we only sketch a few examples below (see also the references at the end). All applications of the DFT depend crucially on the availability of a fast algorithm to compute discrete Fourier transforms and their inverses, a fast Fourier transform.\n\nSpectral analysis \n\nWhen the DFT is used for signal spectral analysis, the \\{x_n\\}\\, sequence usually represents a finite set of uniformly spaced time-samples of some signal x(t)\\,, where t represents time.  The conversion from continuous time to samples (discrete-time) changes the underlying Fourier transform of x(t) into a discrete-time Fourier transform (DTFT), which generally entails a type of distortion called aliasing.  Choice of an appropriate sample-rate (see Nyquist rate) is the key to minimizing that distortion.  Similarly, the conversion from a very long (or infinite) sequence to a manageable size entails a type of distortion called leakage, which is manifested as a loss of detail (a.k.a. resolution) in the DTFT.  Choice of an appropriate sub-sequence length is the primary key to minimizing that effect.  When the available data (and time to process it) is more than the amount needed to attain the desired frequency resolution, a standard technique is to perform multiple DFTs, for example to create a spectrogram.  If the desired result is a power spectrum and noise or randomness is present in the data, averaging the magnitude components of the multiple DFTs is a useful procedure to reduce the variance of the spectrum (also called a periodogram in this context); two examples of such techniques are the Welch method and the Bartlett method; the general subject of estimating the power spectrum of a noisy signal is called spectral estimation.\n\nA final source of distortion (or perhaps illusion) is the DFT itself, because it is just a discrete sampling of the DTFT, which is a function of a continuous frequency domain.  That can be mitigated by increasing the resolution of the DFT.  That procedure is illustrated at Sampling the DTFT.\n*The procedure is sometimes referred to as zero-padding, which is a particular implementation used in conjunction with the fast Fourier transform (FFT) algorithm.  The inefficiency of performing multiplications and additions with zero-valued \"samples\" is more than offset by the inherent efficiency of the FFT.\n*As already noted, leakage imposes a limit on the inherent resolution of the DTFT.  So there is a practical limit to the benefit that can be obtained from a fine-grained DFT.\n\nFilter bank \n\nSee FFT filter banks and Sampling the DTFT.\n\nData compression\n\nThe field of digital signal processing relies heavily on operations in the frequency domain (i.e. on the Fourier transform). For example, several lossy image and sound compression methods employ the discrete Fourier transform: the signal is cut into short segments, each is transformed, and then the Fourier coefficients of high frequencies, which are assumed to be unnoticeable, are discarded. The decompressor computes the inverse transform based on this reduced number of Fourier coefficients. (Compression applications often use a specialized form of the DFT, the discrete cosine transform or sometimes the modified discrete cosine transform.)\nSome relatively recent compression algorithms, however, use wavelet transforms, which give a more uniform compromise between time and frequency domain than obtained by chopping data into segments and transforming each segment.  In the case of JPEG2000, this avoids the spurious image features that appear when images are highly compressed with the original JPEG.\n\nPartial differential equations\n\nDiscrete Fourier transforms are often used to solve partial differential equations, where again the DFT is used as an approximation for the Fourier series (which is recovered in the limit of infinite N). The advantage of this approach is that it expands the signal in complex exponentials e^{inx}, which are eigenfunctions of differentiation: {\\text{d} \\big( e^{inx} \\big) }/\\text{d}x = in e^{inx}. Thus, in the Fourier representation, differentiation is simple—we just multiply by in.  (Note, however, that the choice of n is not unique due to aliasing; for the method to be convergent, a choice similar to that in the trigonometric interpolation section above should be used.) A linear differential equation with constant coefficients is transformed into an easily solvable algebraic equation. One then uses the inverse DFT to transform the result back into the ordinary spatial representation. Such an approach is called a spectral method.\n\nPolynomial multiplication\n\nSuppose we wish to compute the polynomial product c(x) = a(x) · b(x).  The ordinary product expression for the coefficients of c involves a linear (acyclic) convolution, where indices do not \"wrap around.\"  This can be rewritten as a cyclic convolution by taking the coefficient vectors for a(x) and b(x) with constant term first, then appending zeros so that the resultant coefficient vectors a and b have dimension d > deg(a(x)) + deg(b(x)).  Then,\n\n\\mathbf{c} = \\mathbf{a} * \\mathbf{b}\n\nWhere c is the vector of coefficients for c(x), and the convolution operator *\\, is defined so\n\nc_n \\sum_{m\n0}^{d-1}a_m b_{n-m\\ \\mathrm{mod}\\ d} \\qquad\\qquad\\qquad n=0,1\\dots,d-1\n\nBut convolution becomes multiplication under the DFT:\n\n\\mathcal{F}(\\mathbf{c}) = \\mathcal{F}(\\mathbf{a})\\mathcal{F}(\\mathbf{b})\n\nHere the vector product is taken elementwise.  Thus the coefficients of the product polynomial c(x) are just the terms 0, ..., deg(a(x)) + deg(b(x)) of the coefficient vector\n\n\\mathbf{c} = \\mathcal{F}^{-1}(\\mathcal{F}(\\mathbf{a})\\mathcal{F}(\\mathbf{b})).\n\nWith a fast Fourier transform, the resulting algorithm takes O (N log N) arithmetic operations.  Due to its simplicity and speed, the Cooley–Tukey FFT algorithm, which is limited to composite sizes, is often chosen for the transform operation.  In this case, d should be chosen as the smallest integer greater than the sum of the input polynomial degrees that is factorizable into small prime factors (e.g. 2, 3, and 5, depending upon the FFT implementation).\n\nMultiplication of large integers\n\nThe fastest known algorithms for the multiplication of very large integers use the polynomial multiplication method outlined above.  Integers can be treated as the value of a polynomial evaluated specifically at the number base, with the coefficients of the polynomial corresponding to the digits in that base.  After polynomial multiplication, a relatively low-complexity carry-propagation step completes the multiplication.\n\nConvolution  \n\nWhen data is convolved with a function with wide support, such as for downsampling by a large sampling ratio, because of the Convolution theorem and the FFT algorithm, it may be faster to transform it, multiply pointwise by the transform of the filter and then reverse transform it.  Alternatively, a good filter is obtained by simply truncating the transformed data and re-transforming the shortened data set.\n\nSome discrete Fourier transform pairs\n\nGeneralizations\n\nRepresentation theory \n\nThe DFT can be interpreted as the complex-valued representation theory of the finite cyclic group. In other words, a sequence of n complex numbers can be thought of as an element of n-dimensional complex space Cn or equivalently a function f from the finite cyclic group of order n to the complex numbers, Zn → C. So  f is a class function on the finite cyclic group, and thus can be expressed as a linear combination of the irreducible characters of this group, which are the roots of unity.\n\nFrom this point of view, one may generalize the DFT to representation theory generally, or more narrowly to the representation theory of finite groups.\n\nMore narrowly still, one may generalize the DFT by either changing the target (taking values in a field other than the complex numbers), or the domain (a group other than a finite cyclic group), as detailed in the sequel.\n\nOther fields \n\nMany of the properties of the DFT only depend on the fact that e^{-\\frac{2 \\pi i}{N}} is a primitive root of unity, sometimes denoted \\omega_N or W_N (so that \\omega_N^N = 1).  Such properties include the completeness, orthogonality, Plancherel/Parseval, periodicity, shift, convolution, and unitarity properties above, as well as many FFT algorithms. For this reason, the discrete Fourier transform can be defined by using roots of unity in fields other than the complex numbers, and such generalizations are commonly called number-theoretic transforms (NTTs) in the case of finite fields. For more information, see number-theoretic transform and discrete Fourier transform (general).\n\nOther finite groups \n\nThe standard DFT acts on a sequence x0, x1, …, xN−1 of complex numbers, which can be viewed as a function {0, 1, …, N − 1} → C. The multidimensional DFT acts on multidimensional sequences, which can be viewed as functions\n \\{0, 1, \\ldots, N_1-1\\} \\times \\cdots \\times \\{0, 1, \\ldots, N_d-1\\} \\to \\mathbb{C}. \nThis suggests the generalization to Fourier transforms on arbitrary finite groups, which act on functions G → C where G is a finite group. In this framework, the standard DFT is seen as the Fourier transform on a cyclic group, while the multidimensional DFT is a Fourier transform on a direct sum of cyclic groups.\n\nAlternatives\n\n There are various alternatives to the DFT for various applications, prominent among which are wavelets. The analog of the DFT is the discrete wavelet transform (DWT). From the point of view of time–frequency analysis, a key limitation of the Fourier transform is that it does not include location information, only frequency information, and thus has difficulty in representing transients. As wavelets have location as well as frequency, they are better able to represent location, at the expense of greater difficulty representing frequency. For details, see comparison of the discrete wavelet transform with the discrete Fourier transform.",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Discrete Fourier transform" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=8811" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "In mathematics, the discrete Fourier transform (DFT) converts a finite sequence of equally-spaced samples of a function into a same-length sequence of equally-spaced samples of the discrete-time Fourier transform (DTFT), which is a complex-valued function of frequency. The interval at which the DTFT is sampled is the reciprocal of the duration of the input sequence.  An inverse DFT is a Fourier series, using the DTFT samples as coefficients of complex sinusoids at the corresponding DTFT frequencies.  It has the same sample-values as the original input sequence.  The DFT is therefore said to be a frequency domain representation of the original input sequence.  If the original sequence spans all the non-zero values of a function, its DTFT is continuous (and periodic), and the DFT provides discrete samples of one cycle.  If the original sequence is one cycle of a periodic function, the DFT provides all the non-zero values of one DTFT cycle.\n\nThe DFT is the most important discrete transform, used to perform Fourier analysis in many practical applications.  In digital signal processing, the function is any quantity or signal that varies over time, such as the pressure of a sound wave, a radio signal, or daily temperature readings, sampled over a finite time interval (often defined by a window function). In image processing, the samples can be the values of pixels along a row or column of a raster image. The DFT is also used to efficiently solve partial differential equations, and to perform other operations such as convolutions or multiplying large integers.\n\nSince it deals with a finite amount of data, it can be implemented in computers by numerical algorithms or even dedicated hardware. These implementations usually employ efficient fast Fourier transform (FFT) algorithms;Cooley et al., 1969 so much so that the terms \"FFT\" and \"DFT\" are often used interchangeably.  Prior to its current usage, the \"FFT\" initialism may have also been used for the ambiguous term \"finite Fourier transform\".\n\nDefinition\n\nThe discrete Fourier transform transforms a sequence of N complex numbers    \\left \\{ \\mathbf{ x_n } \\right \\} :x_0, x_1, \\ldots, x_{N-1} into another sequence of complex numbers,  \\left \\{ \\mathbf{X_k} \\right \\} :\n X_0, X_1, \\ldots, X_{N-1}, which is defined by\n\nwhere the last expression follows from the first one by Euler's formula.\n\nThe transform is sometimes denoted by the symbol \\mathcal{F}, as in \\mathbf{X} \\mathcal{F} \\left \\{ \\mathbf{x} \\right \\}  or \\mathcal{F} \\left ( \\mathbf{x} \\right ) or \\mathcal{F} \\mathbf{x}.As a linear transformation on a finite-dimensional vector space, the DFT expression can also be written in terms of a DFT matrix; when scaled appropriately it becomes a unitary matrix and the Xk can thus be viewed as coefficients of x in an orthonormal basis.\n\nMotivation\n\n can also be evaluated outside the domain , and that extended sequence is -periodic. Accordingly, other sequences of  indices are sometimes used,  such as  (if  is even) and  (if  is odd), which amounts to swapping the left and right halves of the result of the transform.\n\n can be interpreted or derived in various ways, for example:\n*It completely describes the discrete-time Fourier transform (DTFT) of an N-periodic sequence, which comprises only discrete frequency components.  (Using the DTFT with periodic data)\n*It can also provide uniformly spaced samples of the continuous DTFT of a finite length sequence.  (Sampling the DTFT)\n*It is the cross correlation of the input sequence, xn, and a complex sinusoid at frequency k/N.  Thus it acts like a matched filter for that frequency.\n*It is the discrete analogy of the formula for the coefficients of a Fourier series:\n\nwhich is also N-periodic.  In the domain  ,  this is the inverse transform of .  In this interpretation, each X_k is a complex number that encodes both amplitude and phase of a complex sinusoidal component  (e^{i 2 \\pi k n / N})  of function x_n.  The sinusoid's frequency is k cycles per N samples.  Its amplitude and phase are:\n\n:|X_k|/N = \\sqrt{\\operatorname{Re}(X_k)^2 + \\operatorname{Im}(X_k)^2}/N\n:\\arg(X_k) \\operatorname{atan2}\\big( \\operatorname{Im}(X_k), \\operatorname{Re}(X_k) \\big)\n-i\\cdot \\operatorname{ln}\\left(\\frac{X_k}\\right),\n\nwhere atan2 is the two-argument form of the arctan function. In polar form X_k |X_k| e^{i \\arg(X_k)} \n |X_k| \\operatorname{cis} \\arg(X_k) where cis is the mnemonic for cos + i sin.\n\nThe normalization factor multiplying the DFT and IDFT (here 1 and 1/N) and the signs of the exponents are merely conventions, and differ in some treatments. The only requirements of these conventions are that the DFT and IDFT have opposite-sign exponents and that the product of their normalization factors be 1/N.  A normalization of \\scriptstyle \\sqrt{1/N} for both the DFT and IDFT, for instance, makes the transforms unitary. A discrete impulse, x_n 1 at n \n 0 and 0 otherwise; might transform to X_k 1 for all k (use normalization factors 1 for DFT and 1/N for IDFT). A DC signal, X_k \n 1 at k 0 and 0 otherwise; might inversely transform to x_n \n 1 for all n (use 1/N for DFT and 1 for IDFT) which is consistent with viewing DC as the mean average of the signal.\n\nExample\n\nLet N=4 and\n\\mathbf{x} =\n\\begin{pmatrix}\nx_0 \\\\\nx_1 \\\\\nx_2 \\\\\nx_3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 \\\\\n2-i \\\\\n-i \\\\\n-1+2i\n\\end{pmatrix}\n. Here we demonstrate how to calculate the DFT of \\mathbf{x} using :\n\nX_0 e^{-i 2 \\pi 0 \\cdot 0 / 4} \\cdot 1 + e^{-i 2 \\pi 0 \\cdot 1 / 4} \\cdot (2-i) + e^{-i 2 \\pi 0 \\cdot 2 / 4} \\cdot (-i) + e^{-i 2 \\pi 0 \\cdot 3 / 4} \\cdot (-1+2i) \n 2\n\nX_1 e^{-i 2 \\pi 1 \\cdot 0 / 4} \\cdot 1 + e^{-i 2 \\pi 1 \\cdot 1 / 4} \\cdot (2-i) + e^{-i 2 \\pi 1 \\cdot 2 / 4} \\cdot (-i) + e^{-i 2 \\pi 1 \\cdot 3 / 4} \\cdot (-1+2i) \n -2-2i\n\nX_2 e^{-i 2 \\pi 2 \\cdot 0 / 4} \\cdot 1 + e^{-i 2 \\pi 2 \\cdot 1 / 4} \\cdot (2-i) + e^{-i 2 \\pi 2 \\cdot 2 / 4} \\cdot (-i) + e^{-i 2 \\pi 2 \\cdot 3 / 4} \\cdot (-1+2i) \n -2i\n\nX_3 e^{-i 2 \\pi 3 \\cdot 0 / 4} \\cdot 1 + e^{-i 2 \\pi 3 \\cdot 1 / 4} \\cdot (2-i) + e^{-i 2 \\pi 3 \\cdot 2 / 4} \\cdot (-i) + e^{-i 2 \\pi 3 \\cdot 3 / 4} \\cdot (-1+2i) \n 4+4i\n\n\\mathbf{X} =\n\\begin{pmatrix}\nX_0 \\\\\nX_1 \\\\\nX_2 \\\\\nX_3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n2 \\\\\n-2-2i \\\\\n-2i \\\\\n4+4i\n\\end{pmatrix}\n\nProperties\n\nCompleteness\n\nThe discrete Fourier transform is an invertible, linear transformation\n\n\\mathcal{F}\\colon\\mathbb{C}^N \\to \\mathbb{C}^N\n\nwith \\mathbb{C} denoting the set of complex numbers. In other words, for any N>0, an N-dimensional complex vector has a DFT and an IDFT which are in turn N-dimensional complex vectors.\n\nThe inverse transform is given by:\n\nx_n \\frac{1}{N} \\sum_{k\n0}^{N-1} X_k\\cdot e^{i 2 \\pi k n / N}\n\nOrthogonality \n\nThe vectors u_k\\left[ e^{ \\frac{2\\pi i}{N} kn} \\;|\\; n\n0,1,\\ldots,N-1 \\right]^T \nform an orthogonal basis over the set of N-dimensional complex vectors:\n\nu^T_k u_{k'}^* \n \\sum_{n\n0}^{N-1} \\left(e^{ \\frac{2\\pi i}{N} kn}\\right) \\left(e^{\\frac{2\\pi i}{N} (-k')n}\\right)\n \\sum_{n\n0}^{N-1} e^{ \\frac{2\\pi i}{N} (k-k') n} \n = N~\\delta_{kk'}\n\nwhere ~\\delta_{kk'} is the Kronecker delta. (In the last step, the summation is trivial if kk', where it is 1+1+⋅⋅⋅\nN, and otherwise is a geometric series that can be explicitly summed to obtain zero.)  This orthogonality condition can be used to derive the formula for the IDFT from the definition of the DFT, and is equivalent to the unitarity property below.\n\nThe Plancherel theorem and Parseval's theorem \n\nIf Xk and Yk are the DFTs of xn and yn respectively then the Parseval's theorem states:\n\n\\sum_{n0}^{N-1} x_n y^*_n \n \\frac{1}{N} \\sum_{k=0}^{N-1} X_k Y^*_k\n\nwhere the star denotes complex conjugation.  Plancherel theorem is a special case of the Parseval's theorem and states:\n\n\\sum_{n0}^{N-1} |x_n|^2 \n \\frac{1}{N} \\sum_{k=0}^{N-1} |X_k|^2.\n\nThese theorems are also equivalent to the unitary condition below.\n\nPeriodicity\n\nThe periodicity can be shown directly from the definition:\n\nX_{k+N} \\ \\stackrel{\\mathrm{def}}{} \\ \\sum_{n\n0}^{N-1} x_n e^{-\\frac{2\\pi i}{N} (k+N) n} \\sum_{n\n0}^{N-1} x_n e^{-\\frac{2\\pi i}{N} k n}  \\underbrace{e^{-2 \\pi i n}}_{1} \\sum_{n\n0}^{N-1} x_n e^{-\\frac{2\\pi i}{N} k n} = X_k. \n\nSimilarly, it can be shown that the IDFT formula leads to a periodic extension.\n\nShift theorem\n\nMultiplying x_n by a linear phase e^{\\frac{2\\pi i}{N}n m} for some integer m corresponds to a circular shift of the output X_k: X_k is replaced by X_{k-m}, where the subscript is interpreted modulo N (i.e., periodically).  Similarly, a circular shift of the input x_n corresponds to multiplying the output X_k by a linear phase. Mathematically, if \\{x_n\\} represents the vector x then\n\nif \\mathcal{F}(\\{x_n\\})_k=X_k\n\nthen \\mathcal{F}(\\{ x_n\\cdot e^{\\frac{2\\pi i}{N}n m} \\})_k=X_{k-m}\n\nand \\mathcal{F}(\\{x_{n-m}\\})_k=X_k\\cdot e^{-\\frac{2\\pi i}{N}k m}\n\nCircular convolution theorem and cross-correlation theorem\n\nThe convolution theorem for the discrete-time Fourier transform indicates that a convolution of two infinite sequences can be obtained as the inverse transform of the product of the individual transforms.  An important simplification occurs when the sequences are of finite length, N.  In terms of the DFT and inverse DFT, it can be written as follows:\n\n\\mathcal{F}^{-1} \\left \\{ \\mathbf{X\\cdot Y} \\right \\}_n \\ \\sum_{l\n0}^{N-1}x_l \\cdot (y_N)_{n-l} \\ \\ \\stackrel{\\mathrm{def}}{=} \\ \\ (\\mathbf{x * y_N})_n\\ ,\n\nwhich is the convolution of the \\mathbf{x} sequence with a \\mathbf{y} sequence extended by periodic summation:\n\n(\\mathbf{y_N})_n \\ \\stackrel{\\mathrm{def}}{} \\ \\sum_{p\n-\\infty}^{\\infty} y_{(n-pN)} = y_{n (mod N)}. \\,\n\nSimilarly, the cross-correlation of  \\mathbf{x}  and  \\mathbf{y_N}  is given by:\n\n\\mathcal{F}^{-1} \\left \\{ \\mathbf{X^* \\cdot Y} \\right \\}_n\n\\sum_{l\n0}^{N-1}x_l^* \\cdot (y_N)_{n+l} \\ \\ \\stackrel{\\mathrm{def}}{=} \\ \\ (\\mathbf{x \\star y_N})_n\\ .\n\nWhen either sequence contains a string of zeros, of length L,  L+1 of the circular convolution outputs are equivalent to values of  \\mathbf{x * y}.  Methods have also been developed to use this property as part of an efficient process that constructs  \\mathbf{x * y}  with an \\mathbf{x} or \\mathbf{y} sequence potentially much longer than the practical transform size (N).  Two such methods are called overlap-save and overlap-add.T. G. Stockham, Jr., \"[http://dl.acm.org/citation.cfm?id=1464209 High-speed convolution and correlation],\" in 1966 Proc. AFIPS Spring Joint Computing Conf. Reprinted in Digital Signal Processing, L. R. Rabiner and C. M. Rader, editors, New York: IEEE Press, 1972.  The efficiency results from the fact that a direct evaluation of either summation (above) requires \\scriptstyle O(N^2) operations for an output sequence of length N.  An indirect method, using transforms, can take advantage of the \\scriptstyle O(N\\log N) efficiency of the fast Fourier transform (FFT) to achieve much better performance.  Furthermore, convolutions can be used to efficiently compute DFTs via Rader's FFT algorithm and Bluestein's FFT algorithm.\n\nConvolution theorem duality \n\nIt can also be shown that:\n\n\\mathcal{F} \\left \\{ \\mathbf{x\\cdot y} \\right \\}_k \\ \\stackrel{\\mathrm{def}}{=}\n\\sum_{n=0}^{N-1} x_n \\cdot y_n \\cdot e^{-\\frac{2\\pi i}{N} k n}\n\n:=\\frac{1}{N} (\\mathbf{X * Y_N})_k, \\,   which is the circular convolution of \\mathbf{X} and \\mathbf{Y}.\n\nTrigonometric interpolation polynomial\n\nThe trigonometric interpolation polynomial\np(t) = \\frac{1}{N} \\left[ X_0 + X_1 e^{2\\pi it} + \\cdots + X_{N/2-1} e^{(N/2-1)2\\pi it} + X_{N/2} \\cos(N\\pi t) + X_{N/2+1} e^{(-N/2+1)2\\pi it} + \\cdots + X_{N-1} e^{-2\\pi it} \\right] for N even ,\np(t) = \\frac{1}{N} \\left[ X_0 + X_1 e^{2\\pi it} + \\cdots + X_{\\lfloor N/2 \\rfloor} e^{\\lfloor N/2 \\rfloor 2\\pi it} + X_{\\lfloor N/2 \\rfloor+1} e^{-\\lfloor N/2 \\rfloor 2\\pi it} + \\cdots + X_{N-1} e^{-2\\pi it} \\right]  for N odd,\nwhere the coefficients Xk are given by the DFT of xn above, satisfies the interpolation property p(n/N) x_n for n\n0,\\ldots,N-1.\n\nFor even N, notice that the Nyquist component \\frac{X_{N/2}}{N} \\cos(N\\pi t) is handled specially.\n\nThis interpolation is not unique: aliasing implies that one could add N to any of the complex-sinusoid frequencies (e.g. changing e^{-it} to e^{i(N-1)t} ) without changing the interpolation property, but giving different values in between the x_n points.  The choice above, however, is typical because it has two useful properties.  First, it consists of sinusoids whose frequencies have the smallest possible magnitudes: the interpolation is bandlimited. Second, if the  x_n are real numbers, then p(t) is real as well.\n\nIn contrast, the most obvious trigonometric interpolation polynomial is the one in which the frequencies range from 0 to N-1 (instead of roughly -N/2 to +N/2 as above), similar to the inverse DFT formula. This interpolation does not minimize the slope, and is not generally real-valued for real x_n; its use is a common mistake.\n\nThe unitary DFT \n\nAnother way of looking at the DFT is to note that in the above discussion, the DFT can be expressed as the DFT matrix, a Vandermonde matrix, \nintroduced by Sylvester in 1867,\n\\mathbf{F} =\n\\begin{bmatrix}\n \\omega_N^{0 \\cdot 0}     & \\omega_N^{0 \\cdot 1}     & \\ldots & \\omega_N^{0 \\cdot (N-1)}     \\\\\n \\omega_N^{1 \\cdot 0}     & \\omega_N^{1 \\cdot 1}     & \\ldots & \\omega_N^{1 \\cdot (N-1)}     \\\\\n \\vdots                   & \\vdots                   & \\ddots & \\vdots                       \\\\\n \\omega_N^{(N-1) \\cdot 0} & \\omega_N^{(N-1) \\cdot 1} & \\ldots & \\omega_N^{(N-1) \\cdot (N-1)} \\\\\n\\end{bmatrix}\n\nwhere\n\\omega_N = e^{-2 \\pi i/N}\\,\nis a primitive Nth root of unity.\n\nThe inverse transform is then given by the inverse of the above matrix,\n\\mathbf{F}^{-1}=\\frac{1}{N}\\mathbf{F}^*\n\nWith unitary normalization constants 1/\\sqrt{N}, the DFT becomes a unitary transformation, defined by a unitary matrix:\n\n\\mathbf{U}=\\mathbf{F}/\\sqrt{N}\n\\mathbf{U}^{-1}=\\mathbf{U}^*\n|\\det(\\mathbf{U})|=1\nwhere det()  is the determinant function. The determinant is the product of the eigenvalues, which are always \\pm 1 or \\pm i as described below.  In a real vector space, a unitary transformation can be thought of as simply a rigid rotation of the coordinate system, and all of the properties of a rigid rotation can be found in the unitary DFT.\n\nThe orthogonality of the DFT is now expressed as an orthonormality condition (which arises in many areas of mathematics as described in root of unity):\n\\sum_{m0}^{N-1}U_{km}U_{mn}^*\n\\delta_{kn}\n\nIf X  is defined as the unitary DFT of the vector x, then\nX_k\\sum_{n\n0}^{N-1} U_{kn}x_n\n\nand the Plancherel theorem is expressed as\n\\sum_{n0}^{N-1}x_n y_n^* \n \\sum_{k=0}^{N-1}X_k Y_k^*\n\nIf we view the DFT as just a coordinate transformation which simply specifies the components of a vector in a new coordinate system, then the above is just the statement that the dot product of two vectors is preserved under a unitary DFT transformation. For the special case \\mathbf{x} = \\mathbf{y}, this implies that the length of a vector is preserved as well—this is just Parseval's theorem,\n\\sum_{n0}^{N-1}|x_n|^2 \n \\sum_{k=0}^{N-1}|X_k|^2\n\nA consequence of the circular convolution theorem is that the DFT matrix  diagonalizes any circulant matrix.\n\nExpressing the inverse DFT in terms of the DFT \n\nA useful property of the DFT is that the inverse DFT can be easily expressed in terms of the (forward) DFT, via several well-known \"tricks\".  (For example, in computations, it is often convenient to only implement a fast Fourier transform corresponding to one transform direction and then to get the other transform direction from the first.)\n\nFirst, we can compute the inverse DFT by reversing all but one of the inputs (Duhamel et al., 1988):\n\n\\mathcal{F}^{-1}(\\{x_n\\}) = \\mathcal{F}(\\{x_{N - n}\\}) / N\n\n(As usual, the subscripts are interpreted modulo N; thus, for n0, we have x_{N-0}\nx_0.)\n\nSecond, one can also conjugate the inputs and outputs:\n\n\\mathcal{F}^{-1}(\\mathbf{x}) = \\mathcal{F}(\\mathbf{x}^*)^* / N\n\nThird, a variant of this conjugation trick, which is sometimes preferable because it requires no modification of the data values, involves swapping real and imaginary parts (which can be done on a computer simply by modifying pointers). Define swap(x_n) as x_n with its real and imaginary parts swapped—that is, if x_n = a + b i then swap(x_n) is b + a i.  Equivalently, swap(x_n) equals i x_n^*.  Then\n\n\\mathcal{F}^{-1}(\\mathbf{x}) = \\textrm{swap}(\\mathcal{F}(\\textrm{swap}(\\mathbf{x}))) / N\n\nThat is, the inverse transform is the same as the forward transform with the real and imaginary parts swapped for both input and output, up to a normalization (Duhamel et al., 1988).\n\nThe conjugation trick can also be used to define a new transform, closely related to the DFT, that is involutory—that is, which is its own inverse.  In particular, T(\\mathbf{x}) \\mathcal{F}(\\mathbf{x}^*) / \\sqrt{N} is clearly its own inverse: T(T(\\mathbf{x})) \n \\mathbf{x}.  A closely related involutory transformation (by a factor of (1+i) /√2) is H(\\mathbf{x}) = \\mathcal{F}((1+i) \\mathbf{x}^*) / \\sqrt{2N}, since the (1+i) factors in H(H(\\mathbf{x})) cancel the 2.  For real inputs \\mathbf{x}, the real part of H(\\mathbf{x}) is none other than the discrete Hartley transform, which is also involutory.\n\nEigenvalues and eigenvectors \n\nThe eigenvalues of the DFT matrix are simple and well-known, whereas the eigenvectors are complicated, not unique, and are the subject of ongoing research.\n\nConsider the unitary form \\mathbf{U} defined above for the DFT of length N, where\n\\mathbf{U}_{m,n} \\frac1{\\sqrt{N}}\\omega_N^{(m-1)(n-1)} \n \\frac1{\\sqrt{N}}e^{-\\frac{2\\pi i}N (m-1)(n-1)}.\nThis matrix satisfies the matrix polynomial equation:\n\\mathbf{U}^4 = \\mathbf{I}.\nThis can be seen from the inverse properties above: operating \\mathbf{U} twice gives the original data in reverse order, so operating \\mathbf{U} four times gives back the original data and is thus the identity matrix.  This means that the eigenvalues \\lambda satisfy the equation:\n\\lambda^4 = 1.\nTherefore, the eigenvalues of \\mathbf{U} are the fourth roots of unity: \\lambda is +1, −1, +i,  or −i.\n\nSince there are only four distinct eigenvalues for this N\\times N matrix, they have some multiplicity.  The multiplicity gives the number of linearly independent eigenvectors corresponding to each eigenvalue.  (Note that there are N independent eigenvectors; a unitary matrix is never defective.)\n\nThe problem of their multiplicity was solved by McClellan and Parks (1972), although it was later shown to have been equivalent to a problem solved by Gauss (Dickinson and Steiglitz, 1982).  The multiplicity depends on the value of N modulo 4, and is given by the following table:\n\nOtherwise stated, the characteristic polynomial of \\mathbf{U} is:\n\\det (\\lambda I - \\mathbf{U})=\n(\\lambda-1)^{\\left\\lfloor \\tfrac {N+4}{4}\\right\\rfloor}\n(\\lambda+1)^{\\left\\lfloor \\tfrac {N+2}{4}\\right\\rfloor}\n(\\lambda+i)^{\\left\\lfloor \\tfrac {N+1}{4}\\right\\rfloor}\n(\\lambda-i)^{\\left\\lfloor \\tfrac {N-1}{4}\\right\\rfloor}.\n\nNo simple analytical formula for general eigenvectors is known.   Moreover, the eigenvectors are not unique because any linear combination of eigenvectors for the same eigenvalue is also an eigenvector for that eigenvalue.  Various researchers have proposed different choices of eigenvectors, selected to satisfy useful properties like orthogonality and to have \"simple\" forms (e.g., McClellan and Parks, 1972; Dickinson and Steiglitz, 1982; Grünbaum, 1982; Atakishiyev and Wolf, 1997; Candan et al., 2000; Hanna et al., 2004; Gurevich and Hadani, 2008).\n\nA straightforward approach is to discretize an eigenfunction of the continuous Fourier transform,\nof which the most famous is the Gaussian function.\nSince periodic summation of the function means discretizing its frequency spectrum\nand discretization means periodic summation of the spectrum,\nthe discretized and periodically summed Gaussian function yields an eigenvector of the discrete transform:\n*F(m) = \\sum_{k\\in\\mathbb{Z}} \\exp\\left(-\\frac{\\pi\\cdot(m+N\\cdot k)^2}{N}\\right).\nA closed form expression for the series is not known, but it converges rapidly.\n\nTwo other simple closed-form analytical eigenvectors for special DFT period N were found (Kong, 2008):\n\nFor DFT period N 2L + 1 \n 4K +1, where K is an integer, the following is an eigenvector of DFT:\n*F(m)\\prod_{s\nK+1}^L\\left[\\cos\\left(\\frac{2\\pi}{N}m\\right)- \\cos\\left(\\frac{2\\pi}{N}s\\right)\\right]\n\nFor DFT period N 2L \n 4K, where K is an integer, the following is an eigenvector of DFT:\n*F(m)\\sin\\left(\\frac{2\\pi}{N}m\\right)\\prod_{s\nK+1}^{L-1}\\left[\\cos\\left(\\frac{2\\pi}{N}m\\right)- \\cos\\left(\\frac{2\\pi}{N}s\\right)\\right]\n\nThe choice of eigenvectors of the DFT matrix has become important in recent years in order to define a discrete analogue of the fractional Fourier transform—the DFT matrix can be taken to fractional powers by exponentiating the eigenvalues (e.g., Rubio and Santhanam, 2005).  For the continuous Fourier transform, the natural orthogonal eigenfunctions are the Hermite functions, so various discrete analogues of these have been employed as the eigenvectors of the DFT, such as the Kravchuk polynomials (Atakishiyev and Wolf, 1997).  The \"best\" choice of eigenvectors to define a fractional discrete Fourier transform remains an open question, however.\n\nUncertainty principles \n\nProbabilistic uncertainty principle \n\nIf the random variable  is constrained by\n\\sum_{n0}^{N-1}|X_n|^2\n1  ~,\nthen \nP_n=|X_n|^2 \nmay be considered to represent a discrete probability mass function of , with an associated probability mass function constructed from the transformed variable,\nQ_m=N|x_m|^2 ~.\n\nFor the case of continuous functions P(x) and Q(k), the Heisenberg uncertainty principle states that\nD_0(X)D_0(x)\\ge\\frac{1}{16\\pi^2}\nwhere  D_0(X) and D_0(x) are the variances of |X|^2 and |x|^2 respectively, with the equality attained in the case of a suitably normalized Gaussian distribution. Although the variances may be analogously defined for the DFT, an analogous uncertainty principle is not useful, because the uncertainty will not be shift-invariant. Still, a meaningful uncertainty principle has been introduced by Massar and Spindel.\n\nHowever, the Hirschman entropic uncertainty will have a useful analog for the case of the DFT. The Hirschman uncertainty principle is expressed in terms of the Shannon entropy of the two probability functions.\n\nIn the discrete case, the Shannon entropies are defined as\nH(X)-\\sum_{n\n0}^{N-1} P_n\\ln P_n\nand\nH(x)-\\sum_{m\n0}^{N-1} Q_m\\ln Q_m ~,\nand the entropic uncertainty principle becomes\nH(X)+H(x) \\ge \\ln(N) ~.\n\nThe equality is obtained for P_n equal to translations and modulations of a suitably normalized Kronecker comb of period A where A is any exact integer divisor of N. The probability mass function Q_m will then be proportional to a suitably translated Kronecker comb of period BN/A.\n\nDeterministic uncertainty principle \n\nThere is also a well-known deterministic uncertainty principle that uses signal sparsity (or the number of non-zero coefficients). Let \\|x\\|_0 and \\|X\\|_0 be the number of non-zero elements of the time and frequency sequences x_0,x_1,\\ldots,x_{N-1} and X_0,X_1,\\ldots,X_{N-1}, respectively. Then, \nN\\leq \\|x\\|_0 \\cdot \\|X\\|_0.\nAs an immediate consequence of the inequality of arithmetic and geometric means, one also has 2\\sqrt{N}\\leq\\|x\\|_0+\\|X\\|_0. Both uncertainty principles were shown to be tight for specifically-chosen \"picket-fence\" sequences (discrete impulse trains), and find practical use for signal recovery applications.\n\nThe real-input DFT \n\nIf x_0, \\ldots, x_{N-1} are real numbers, as they often are in practical applications, then the DFT obeys the symmetry:\n\nX_{N-k} \\equiv X_{-k} = X_k^*,  where X^*\\, denotes complex conjugation.\n\nIt follows that X0 and XN/2 are real-valued, and the remainder of the DFT is completely specified by just N/2-1 complex numbers.\n\nGeneralized DFT (shifted and non-linear phase)\n\nIt is possible to shift the transform sampling in time and/or frequency domain by some real shifts a and b, respectively. This is sometimes known as a generalized DFT (or GDFT), also called the shifted DFT or offset DFT, and has analogous properties to the ordinary DFT:\n\nX_k \\sum_{n\n0}^{N-1} x_n e^{-\\frac{2 \\pi i}{N} (k+b) (n+a)} \\quad \\quad k = 0, \\dots, N-1.\n\nMost often, shifts of 1/2 (half a sample) are used.\nWhile the ordinary DFT corresponds to a periodic signal in both time and frequency domains, a1/2 produces a signal that is anti-periodic in frequency domain (X_{k+N} \n - X_k) and vice versa for b=1/2.\nThus, the specific case of a b \n 1/2 is known as an odd-time odd-frequency discrete Fourier transform (or O2 DFT).\nSuch shifted transforms are most often used for symmetric data, to represent different boundary symmetries, and for real-symmetric data they correspond to different forms of the discrete cosine and sine transforms.\n\nAnother interesting choice is ab\n-(N-1)/2, which is called the centered DFT (or CDFT).  The centered DFT has the useful property that, when N is a multiple of four, all four of its eigenvalues (see above) have equal multiplicities (Rubio and Santhanam, 2005)Santhanam, Balu; Santhanam, Thalanayar S. [http://thamakau.usc.edu/Proceedings/ICASSP%202007/pdfs/0301385.pdf \"Discrete Gauss-Hermite functions and eigenvectors of the centered discrete Fourier transform\"], Proceedings of the 32nd IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2007, SPTM-P12.4), vol. III, pp. 1385-1388.\n\nThe term GDFT is also used for the non-linear phase extensions of DFT. Hence, GDFT method provides a generalization for constant amplitude orthogonal block transforms including linear and non-linear phase types. GDFT is a framework \nto improve time and frequency domain properties of the traditional DFT, e.g. auto/cross-correlations, by the addition of the properly designed phase shaping function (non-linear, in general) to the original linear phase functions (Akansu and Agirman-Tosun, 2010).Akansu, Ali N.; Agirman-Tosun, Handan \n[http://web.njit.edu/~akansu/PAPERS/AkansuIEEE-TSP2010.pdf \"Generalized Discrete Fourier Transform With Nonlinear Phase\"], IEEE Transactions on Signal Processing, vol. 58, no. 9, pp. 4547-4556, Sept. 2010.\n\nThe discrete Fourier transform can be viewed as a special case of the z-transform, evaluated on the unit circle in the complex plane; more general z-transforms correspond to complex shifts a and b above.\n\nMultidimensional DFT\n\nThe ordinary DFT transforms a one-dimensional sequence or array x_n that is a function of exactly one discrete variable n.  The multidimensional DFT of a multidimensional array x_{n_1, n_2, \\dots, n_d} that is a function of d discrete variables n_\\ell = 0, 1, \\dots, N_\\ell-1 for \\ell in 1, 2, \\dots, d is defined by:\n\nX_{k_1, k_2, \\dots, k_d} \\sum_{n_1\n0}^{N_1-1} \\left(\\omega_{N_1}^{~k_1 n_1} \\sum_{n_20}^{N_2-1} \\left( \\omega_{N_2}^{~k_2 n_2} \\cdots \\sum_{n_d\n0}^{N_d-1} \\omega_{N_d}^{~k_d n_d}\\cdot x_{n_1, n_2, \\dots, n_d} \\right) \\right) \\, , \n\nwhere \\omega_{N_\\ell} \\exp(-2\\pi i/N_\\ell) as above and the d output indices run from k_\\ell \n 0, 1, \\dots, N_\\ell-1.  This is more compactly expressed in vector notation, where we define \\mathbf{n} (n_1, n_2, \\dots, n_d) and \\mathbf{k} \n (k_1, k_2, \\dots, k_d) as d-dimensional vectors of indices from 0 to \\mathbf{N} - 1, which we define as \\mathbf{N} - 1 = (N_1 - 1, N_2 - 1, \\dots, N_d - 1):\n\nX_\\mathbf{k} \\sum_{\\mathbf{n}\n\\mathbf{0}}^{\\mathbf{N}-1} e^{-2\\pi i \\mathbf{k} \\cdot (\\mathbf{n} / \\mathbf{N})} x_\\mathbf{n} \\, ,\n\nwhere the division \\mathbf{n} / \\mathbf{N} is defined as \\mathbf{n} / \\mathbf{N} = (n_1/N_1, \\dots, n_d/N_d) to be performed element-wise, and the sum denotes the set of nested summations above.\n\nThe inverse of the multi-dimensional DFT is, analogous to the one-dimensional case, given by:\n\nx_\\mathbf{n} \\frac{1}{\\prod_{\\ell\n1}^d N_\\ell} \\sum_{\\mathbf{k}=\\mathbf{0}}^{\\mathbf{N}-1} e^{2\\pi i \\mathbf{n} \\cdot (\\mathbf{k} / \\mathbf{N})} X_\\mathbf{k} \\, .\n\nAs the one-dimensional DFT expresses the input x_n as a superposition of sinusoids, the multidimensional DFT expresses the input as a superposition of plane waves, or multidimensional sinusoids. The direction of oscillation in space is \\mathbf{k} / \\mathbf{N}. The amplitudes  are X_\\mathbf{k}.  This decomposition is of great importance for everything from digital image processing (two-dimensional) to solving partial differential equations. The solution is broken up into plane waves.\n\nThe multidimensional DFT can be computed by the composition of a sequence of one-dimensional DFTs along each dimension.  In the two-dimensional case x_{n_1,n_2} the N_1 independent DFTs of the rows (i.e., along n_2) are computed first to form a new array y_{n_1,k_2}. Then the N_2 independent DFTs of y along the columns (along n_1) are computed to form the final result X_{k_1,k_2}.  Alternatively the columns can be computed first and then the rows. The order is immaterial because the nested summations above commute.\n\nAn algorithm to compute a one-dimensional DFT is thus sufficient to efficiently compute a multidimensional DFT.  This approach is known as the row-column algorithm. There are also intrinsically multidimensional FFT algorithms.\n\nThe real-input multidimensional DFT \n\nFor input data x_{n_1, n_2, \\dots, n_d} consisting of real numbers, the DFT outputs have a conjugate symmetry similar to the one-dimensional case above:\n\nX_{k_1, k_2, \\dots, k_d} = X_{N_1 - k_1, N_2 - k_2, \\dots, N_d - k_d}^* ,\n\nwhere the star again denotes complex conjugation and the \\ell-th subscript is again interpreted modulo N_\\ell (for \\ell = 1,2,\\ldots,d).\n\nApplications \n\nThe DFT has seen wide usage across a large number of fields; we only sketch a few examples below (see also the references at the end). All applications of the DFT depend crucially on the availability of a fast algorithm to compute discrete Fourier transforms and their inverses, a fast Fourier transform.\n\nSpectral analysis \n\nWhen the DFT is used for signal spectral analysis, the \\{x_n\\}\\, sequence usually represents a finite set of uniformly spaced time-samples of some signal x(t)\\,, where t represents time.  The conversion from continuous time to samples (discrete-time) changes the underlying Fourier transform of x(t) into a discrete-time Fourier transform (DTFT), which generally entails a type of distortion called aliasing.  Choice of an appropriate sample-rate (see Nyquist rate) is the key to minimizing that distortion.  Similarly, the conversion from a very long (or infinite) sequence to a manageable size entails a type of distortion called leakage, which is manifested as a loss of detail (a.k.a. resolution) in the DTFT.  Choice of an appropriate sub-sequence length is the primary key to minimizing that effect.  When the available data (and time to process it) is more than the amount needed to attain the desired frequency resolution, a standard technique is to perform multiple DFTs, for example to create a spectrogram.  If the desired result is a power spectrum and noise or randomness is present in the data, averaging the magnitude components of the multiple DFTs is a useful procedure to reduce the variance of the spectrum (also called a periodogram in this context); two examples of such techniques are the Welch method and the Bartlett method; the general subject of estimating the power spectrum of a noisy signal is called spectral estimation.\n\nA final source of distortion (or perhaps illusion) is the DFT itself, because it is just a discrete sampling of the DTFT, which is a function of a continuous frequency domain.  That can be mitigated by increasing the resolution of the DFT.  That procedure is illustrated at Sampling the DTFT.\n*The procedure is sometimes referred to as zero-padding, which is a particular implementation used in conjunction with the fast Fourier transform (FFT) algorithm.  The inefficiency of performing multiplications and additions with zero-valued \"samples\" is more than offset by the inherent efficiency of the FFT.\n*As already noted, leakage imposes a limit on the inherent resolution of the DTFT.  So there is a practical limit to the benefit that can be obtained from a fine-grained DFT.\n\nFilter bank \n\nSee FFT filter banks and Sampling the DTFT.\n\nData compression\n\nThe field of digital signal processing relies heavily on operations in the frequency domain (i.e. on the Fourier transform). For example, several lossy image and sound compression methods employ the discrete Fourier transform: the signal is cut into short segments, each is transformed, and then the Fourier coefficients of high frequencies, which are assumed to be unnoticeable, are discarded. The decompressor computes the inverse transform based on this reduced number of Fourier coefficients. (Compression applications often use a specialized form of the DFT, the discrete cosine transform or sometimes the modified discrete cosine transform.)\nSome relatively recent compression algorithms, however, use wavelet transforms, which give a more uniform compromise between time and frequency domain than obtained by chopping data into segments and transforming each segment.  In the case of JPEG2000, this avoids the spurious image features that appear when images are highly compressed with the original JPEG.\n\nPartial differential equations\n\nDiscrete Fourier transforms are often used to solve partial differential equations, where again the DFT is used as an approximation for the Fourier series (which is recovered in the limit of infinite N). The advantage of this approach is that it expands the signal in complex exponentials e^{inx}, which are eigenfunctions of differentiation: {\\text{d} \\big( e^{inx} \\big) }/\\text{d}x = in e^{inx}. Thus, in the Fourier representation, differentiation is simple—we just multiply by in.  (Note, however, that the choice of n is not unique due to aliasing; for the method to be convergent, a choice similar to that in the trigonometric interpolation section above should be used.) A linear differential equation with constant coefficients is transformed into an easily solvable algebraic equation. One then uses the inverse DFT to transform the result back into the ordinary spatial representation. Such an approach is called a spectral method.\n\nPolynomial multiplication\n\nSuppose we wish to compute the polynomial product c(x) = a(x) · b(x).  The ordinary product expression for the coefficients of c involves a linear (acyclic) convolution, where indices do not \"wrap around.\"  This can be rewritten as a cyclic convolution by taking the coefficient vectors for a(x) and b(x) with constant term first, then appending zeros so that the resultant coefficient vectors a and b have dimension d > deg(a(x)) + deg(b(x)).  Then,\n\n\\mathbf{c} = \\mathbf{a} * \\mathbf{b}\n\nWhere c is the vector of coefficients for c(x), and the convolution operator *\\, is defined so\n\nc_n \\sum_{m\n0}^{d-1}a_m b_{n-m\\ \\mathrm{mod}\\ d} \\qquad\\qquad\\qquad n=0,1\\dots,d-1\n\nBut convolution becomes multiplication under the DFT:\n\n\\mathcal{F}(\\mathbf{c}) = \\mathcal{F}(\\mathbf{a})\\mathcal{F}(\\mathbf{b})\n\nHere the vector product is taken elementwise.  Thus the coefficients of the product polynomial c(x) are just the terms 0, ..., deg(a(x)) + deg(b(x)) of the coefficient vector\n\n\\mathbf{c} = \\mathcal{F}^{-1}(\\mathcal{F}(\\mathbf{a})\\mathcal{F}(\\mathbf{b})).\n\nWith a fast Fourier transform, the resulting algorithm takes O (N log N) arithmetic operations.  Due to its simplicity and speed, the Cooley–Tukey FFT algorithm, which is limited to composite sizes, is often chosen for the transform operation.  In this case, d should be chosen as the smallest integer greater than the sum of the input polynomial degrees that is factorizable into small prime factors (e.g. 2, 3, and 5, depending upon the FFT implementation).\n\nMultiplication of large integers\n\nThe fastest known algorithms for the multiplication of very large integers use the polynomial multiplication method outlined above.  Integers can be treated as the value of a polynomial evaluated specifically at the number base, with the coefficients of the polynomial corresponding to the digits in that base.  After polynomial multiplication, a relatively low-complexity carry-propagation step completes the multiplication.\n\nConvolution  \n\nWhen data is convolved with a function with wide support, such as for downsampling by a large sampling ratio, because of the Convolution theorem and the FFT algorithm, it may be faster to transform it, multiply pointwise by the transform of the filter and then reverse transform it.  Alternatively, a good filter is obtained by simply truncating the transformed data and re-transforming the shortened data set.\n\nSome discrete Fourier transform pairs\n\nGeneralizations\n\nRepresentation theory \n\nThe DFT can be interpreted as the complex-valued representation theory of the finite cyclic group. In other words, a sequence of n complex numbers can be thought of as an element of n-dimensional complex space Cn or equivalently a function f from the finite cyclic group of order n to the complex numbers, Zn → C. So  f is a class function on the finite cyclic group, and thus can be expressed as a linear combination of the irreducible characters of this group, which are the roots of unity.\n\nFrom this point of view, one may generalize the DFT to representation theory generally, or more narrowly to the representation theory of finite groups.\n\nMore narrowly still, one may generalize the DFT by either changing the target (taking values in a field other than the complex numbers), or the domain (a group other than a finite cyclic group), as detailed in the sequel.\n\nOther fields \n\nMany of the properties of the DFT only depend on the fact that e^{-\\frac{2 \\pi i}{N}} is a primitive root of unity, sometimes denoted \\omega_N or W_N (so that \\omega_N^N = 1).  Such properties include the completeness, orthogonality, Plancherel/Parseval, periodicity, shift, convolution, and unitarity properties above, as well as many FFT algorithms. For this reason, the discrete Fourier transform can be defined by using roots of unity in fields other than the complex numbers, and such generalizations are commonly called number-theoretic transforms (NTTs) in the case of finite fields. For more information, see number-theoretic transform and discrete Fourier transform (general).\n\nOther finite groups \n\nThe standard DFT acts on a sequence x0, x1, …, xN−1 of complex numbers, which can be viewed as a function {0, 1, …, N − 1} → C. The multidimensional DFT acts on multidimensional sequences, which can be viewed as functions\n \\{0, 1, \\ldots, N_1-1\\} \\times \\cdots \\times \\{0, 1, \\ldots, N_d-1\\} \\to \\mathbb{C}. \nThis suggests the generalization to Fourier transforms on arbitrary finite groups, which act on functions G → C where G is a finite group. In this framework, the standard DFT is seen as the Fourier transform on a cyclic group, while the multidimensional DFT is a Fourier transform on a direct sum of cyclic groups.\n\nAlternatives\n\n There are various alternatives to the DFT for various applications, prominent among which are wavelets. The analog of the DFT is the discrete wavelet transform (DWT). From the point of view of time–frequency analysis, a key limitation of the Fourier transform is that it does not include location information, only frequency information, and thus has difficulty in representing transients. As wavelets have location as well as frequency, they are better able to represent location, at the expense of greater difficulty representing frequency. For details, see comparison of the discrete wavelet transform with the discrete Fourier transform. Discrete Fourier transform. http://en.wikipedia.org/?curid=8811."
  }
}
