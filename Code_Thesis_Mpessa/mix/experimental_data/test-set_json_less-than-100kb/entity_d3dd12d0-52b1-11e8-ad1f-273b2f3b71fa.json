{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=5315",
  "eid" : "d3dd12d0-52b1-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778435197,
  "textBody" : "HTML (Hypertext Markup Language) has been in use since 1991, but HTML 4.0 (December 1997) was the first standardized version where international characters were given reasonably complete treatment. When an HTML document includes special characters outside the range of seven-bit ASCII two goals are worth considering: the information's integrity, and universal browser display.\n\nSpecifying the document's character encoding\n\nThere are several ways to specify which character encoding is used in the document. First, the web server can include the character encoding or \"charset\" in the Hypertext Transfer Protocol (HTTP) Content-Type header, which would typically look like this:\n Content-Type: text/html; charset=ISO-8859-4\nThis method gives the HTTP server a convenient way to alter document's encoding according to content negotiation; certain HTTP server software can do it, for example Apache with the module mod_charset_lite.[http://httpd.apache.org/docs/2.0/en/mod/mod_charset_lite.html Apache Module mod_charset_lite]\n\nFor HTML it is possible to include this information inside the head element near the top of the document:\n\nHTML5 also allows the following syntax to mean exactly the same:\n\nXHTML documents have a third option: to express the character encoding via XML declaration, as follows:\n\nNote that as the character encoding cannot be known until this declaration is parsed, there can be a problem knowing which encoding is used for the declaration itself. The main principle is that the declaration shall be encoded in pure ASCII, and therefore (if the declaration is inside the file) the encoding needs to be an ASCII extension. In order to allow encodings not backwards compatible with ASCII, browsers must be able to parse declarations in such encodings. Examples of such encodings are UTF-16BE and UTF-16LE.\n\nAs of HTML5 the recommended charset is UTF-8. An \"encoding sniffing algorithm\" is defined in the specification to determine the character encoding of the document based on multiple sources of input, including:\n# Explicit user instruction\n# An explicit meta tag within the first 1024 bytes of the document\n# A Byte order mark within the first three bytes of the document\n# The HTTP Content-Type or other transport layer information\n# Analysis of the document bytes looking for specific sequences or ranges of byte values,[http://www.w3.org/TR/html5/syntax.html#prescan-a-byte-stream-to-determine-its-encoding HTML5 prescan a byte stream to determine its encoding] and other tentative detection mechanisms.\n\nFor ASCII-compatible character encodings the consequence of choosing incorrectly is that characters outside the printable ASCII range (32 to 126) usually appear incorrectly. This presents few problems for English-speaking users, but other languages regularly—in some cases, always—require characters outside that range. In CJK environments where there are several different multi-byte encodings in use, auto-detection is also often employed. Finally, browsers usually permit the user to override incorrect charset label manually as well.\n\nIt is increasingly common for multilingual websites and websites in non-Western languages to use UTF-8, which allows use of the same encoding for all languages. UTF-16 or UTF-32, which can be used for all languages as well, are less widely used because they can be harder to handle in programming languages that assume a byte-oriented ASCII superset encoding, and they are less efficient for text with a high frequency of ASCII characters, which is usually the case for HTML documents.\n\nSuccessful viewing of a page is not necessarily an indication that its encoding is specified correctly. If the page's creator and reader are both assuming some platform-specific character encoding, and the server does not send any identifying information, then the reader will nonetheless see the page as the creator intended, but other readers on different platforms or with different native languages will not see the page as intended.\n\nCharacter references\n\nIn addition to native character encodings, characters can also be encoded as character references, which can be numeric character references (decimal or hexadecimal) or character entity references. Character entity references are also sometimes referred to as named entities, or HTML entities for HTML. HTML's usage of character references derives from SGML.\n\nHTML character references\n\nA numeric character reference in HTML refers to a character by its Universal Character Set/Unicode code point, and uses the format\n\n&#nnnn;\nor\n&#xhhhh;\n\nwhere nnnn is the code point in decimal form, and hhhh is the code point in hexadecimal form. The x must be lowercase in XML documents. The nnnn or hhhh may be any number of digits and may include leading zeros. The hhhh may mix uppercase and lowercase, though uppercase is the usual style.\n\nNot all web browsers or email clients used by receivers of HTML documents, or text editors used by authors of HTML documents, will be able to render all HTML characters. Most modern software is able to display most or all of the characters for the user's language, and will draw a box or other clear indicator for characters they cannot render.\n\nFor codes from 0 to 127, the original 7-bit ASCII standard set, most of these characters can be used without a character reference. Codes from 160 to 255 can all be created using character entity names. Only a few higher-numbered codes can be created using entity names, but all can be created by decimal number character reference.\n\nCharacter entity references can also have the format &name; where name is a case-sensitive alphanumeric string. For example, \"λ\" can also be encoded as λ in an HTML document. The character entity references , >, \" and & are predefined in HTML and SGML, because , >, \"  and & are already used to delimit markup. This notably does not include XML's &apos; (') entity. For a list of all named HTML character entity references (about 250), see List of XML and HTML character entity references.\n\nUnnecessary use of HTML character references may significantly reduce HTML readability. If the character encoding for a web page is chosen appropriately, then HTML character references are usually only required for markup delimiting characters as mentioned above, and for a few special characters (or none at all if a native Unicode encoding like UTF-8 is used). Incorrect HTML entity escaping may also open up security vulnerabilities for injection attacks such as cross-site scripting. If HTML attributes are left unquoted, certain characters, most importantly whitespace, such as space and tab, must be escaped using entities. Other languages related to HTML have their own methods of escaping characters.\n\nXML character references\n\nUnlike traditional HTML with its large range of character entity references, in XML there are only five predefined character entity references. These are used to escape characters that are markup sensitive in certain contexts:\n\n*&  → & (ampersand, U+0026)\n*   → >   → > (greater-than sign, U+003E)\n*\" → \" (quotation mark, U+0022)\n*&apos; → ' (apostrophe, U+0027)\n\nAll other character entity references have to be defined before they can be used. For example, use of é (which gives é, Latin lower-case E with acute accent, U+00E9 in Unicode) in an XML document will generate an error unless the entity has already been defined. XML also requires that the x in hexadecimal numeric references be in lowercase: for example &#xA1b rather than &#XA1b. XHTML, which is an XML application, supports the HTML entity set, along with XML's predefined entities.",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Character encodings in HTML" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=5315" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "HTML (Hypertext Markup Language) has been in use since 1991, but HTML 4.0 (December 1997) was the first standardized version where international characters were given reasonably complete treatment. When an HTML document includes special characters outside the range of seven-bit ASCII two goals are worth considering: the information's integrity, and universal browser display.\n\nSpecifying the document's character encoding\n\nThere are several ways to specify which character encoding is used in the document. First, the web server can include the character encoding or \"charset\" in the Hypertext Transfer Protocol (HTTP) Content-Type header, which would typically look like this:\n Content-Type: text/html; charset=ISO-8859-4\nThis method gives the HTTP server a convenient way to alter document's encoding according to content negotiation; certain HTTP server software can do it, for example Apache with the module mod_charset_lite.[http://httpd.apache.org/docs/2.0/en/mod/mod_charset_lite.html Apache Module mod_charset_lite]\n\nFor HTML it is possible to include this information inside the head element near the top of the document:\n\nHTML5 also allows the following syntax to mean exactly the same:\n\nXHTML documents have a third option: to express the character encoding via XML declaration, as follows:\n\nNote that as the character encoding cannot be known until this declaration is parsed, there can be a problem knowing which encoding is used for the declaration itself. The main principle is that the declaration shall be encoded in pure ASCII, and therefore (if the declaration is inside the file) the encoding needs to be an ASCII extension. In order to allow encodings not backwards compatible with ASCII, browsers must be able to parse declarations in such encodings. Examples of such encodings are UTF-16BE and UTF-16LE.\n\nAs of HTML5 the recommended charset is UTF-8. An \"encoding sniffing algorithm\" is defined in the specification to determine the character encoding of the document based on multiple sources of input, including:\n# Explicit user instruction\n# An explicit meta tag within the first 1024 bytes of the document\n# A Byte order mark within the first three bytes of the document\n# The HTTP Content-Type or other transport layer information\n# Analysis of the document bytes looking for specific sequences or ranges of byte values,[http://www.w3.org/TR/html5/syntax.html#prescan-a-byte-stream-to-determine-its-encoding HTML5 prescan a byte stream to determine its encoding] and other tentative detection mechanisms.\n\nFor ASCII-compatible character encodings the consequence of choosing incorrectly is that characters outside the printable ASCII range (32 to 126) usually appear incorrectly. This presents few problems for English-speaking users, but other languages regularly—in some cases, always—require characters outside that range. In CJK environments where there are several different multi-byte encodings in use, auto-detection is also often employed. Finally, browsers usually permit the user to override incorrect charset label manually as well.\n\nIt is increasingly common for multilingual websites and websites in non-Western languages to use UTF-8, which allows use of the same encoding for all languages. UTF-16 or UTF-32, which can be used for all languages as well, are less widely used because they can be harder to handle in programming languages that assume a byte-oriented ASCII superset encoding, and they are less efficient for text with a high frequency of ASCII characters, which is usually the case for HTML documents.\n\nSuccessful viewing of a page is not necessarily an indication that its encoding is specified correctly. If the page's creator and reader are both assuming some platform-specific character encoding, and the server does not send any identifying information, then the reader will nonetheless see the page as the creator intended, but other readers on different platforms or with different native languages will not see the page as intended.\n\nCharacter references\n\nIn addition to native character encodings, characters can also be encoded as character references, which can be numeric character references (decimal or hexadecimal) or character entity references. Character entity references are also sometimes referred to as named entities, or HTML entities for HTML. HTML's usage of character references derives from SGML.\n\nHTML character references\n\nA numeric character reference in HTML refers to a character by its Universal Character Set/Unicode code point, and uses the format\n\n&#nnnn;\nor\n&#xhhhh;\n\nwhere nnnn is the code point in decimal form, and hhhh is the code point in hexadecimal form. The x must be lowercase in XML documents. The nnnn or hhhh may be any number of digits and may include leading zeros. The hhhh may mix uppercase and lowercase, though uppercase is the usual style.\n\nNot all web browsers or email clients used by receivers of HTML documents, or text editors used by authors of HTML documents, will be able to render all HTML characters. Most modern software is able to display most or all of the characters for the user's language, and will draw a box or other clear indicator for characters they cannot render.\n\nFor codes from 0 to 127, the original 7-bit ASCII standard set, most of these characters can be used without a character reference. Codes from 160 to 255 can all be created using character entity names. Only a few higher-numbered codes can be created using entity names, but all can be created by decimal number character reference.\n\nCharacter entity references can also have the format &name; where name is a case-sensitive alphanumeric string. For example, \"λ\" can also be encoded as λ in an HTML document. The character entity references , >, \" and & are predefined in HTML and SGML, because , >, \"  and & are already used to delimit markup. This notably does not include XML's &apos; (') entity. For a list of all named HTML character entity references (about 250), see List of XML and HTML character entity references.\n\nUnnecessary use of HTML character references may significantly reduce HTML readability. If the character encoding for a web page is chosen appropriately, then HTML character references are usually only required for markup delimiting characters as mentioned above, and for a few special characters (or none at all if a native Unicode encoding like UTF-8 is used). Incorrect HTML entity escaping may also open up security vulnerabilities for injection attacks such as cross-site scripting. If HTML attributes are left unquoted, certain characters, most importantly whitespace, such as space and tab, must be escaped using entities. Other languages related to HTML have their own methods of escaping characters.\n\nXML character references\n\nUnlike traditional HTML with its large range of character entity references, in XML there are only five predefined character entity references. These are used to escape characters that are markup sensitive in certain contexts:\n\n*&  → & (ampersand, U+0026)\n*   → >   → > (greater-than sign, U+003E)\n*\" → \" (quotation mark, U+0022)\n*&apos; → ' (apostrophe, U+0027)\n\nAll other character entity references have to be defined before they can be used. For example, use of é (which gives é, Latin lower-case E with acute accent, U+00E9 in Unicode) in an XML document will generate an error unless the entity has already been defined. XML also requires that the x in hexadecimal numeric references be in lowercase: for example &#xA1b rather than &#XA1b. XHTML, which is an XML application, supports the HTML entity set, along with XML's predefined entities. Character encodings in HTML. http://en.wikipedia.org/?curid=5315."
  }
}
