{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=12424",
  "eid" : "024f2e00-52b2-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778513120,
  "textBody" : "In artificial intelligence, genetic programming (GP) is a technique whereby computer programs are encoded as a set of genes that are then modified (evolved) using an evolutionary algorithm (often a genetic algorithm, \"GA\") – it is an application of (for example) genetic algorithms where the space of solutions consists of computer programs. The results are computer programs able to perform well in a predefined task. The methods used to encode a computer program in an artificial chromosome and to evaluate its fitness with respect to the predefined task are central in the GP technique and still the subject of active research.\n\nHistory\n\nIn 1954, pioneering work on what is today known as artificial life was carried out by Nils Aall Barricelli using the very early computers. In the 1960s and early 1970s, evolutionary algorithms became widely recognized as optimization methods. Ingo Rechenberg and his group were able to solve complex engineering problems through evolution strategies as documented in his 1971 PhD thesis and the resulting 1973 book. John Holland was highly influential during the 1970s. The establishment of evolutionary algorithms in the scientific community allowed, by then, the first concrete steps to study the GP idea.\n\nIn 1964, Lawrence J. Fogel, one of the earliest practitioners of the GP methodology, applied evolutionary algorithms to the problem of discovering finite-state automata. Later GP-related work grew out of the learning classifier system community, which developed sets of sparse rules describing optimal policies for Markov decision processes. \nIn 1981 [http://www.cs.bham.ac.uk/~wbl/biblio/gp-html/RichardForsyth.html#kybernetes:forsyth Richard Forsyth] evolved tree rules to classify heart disease.\nThe first statement of modern \"tree-based\" genetic programming (that is, procedural languages organized in tree-based structures and operated on by suitably defined GA-operators) was given by Nichael L. Cramer (1985).Nichael L. Cramer [http://www.sover.net/~nichael/nlc-publications/icga85/index.html \"A Representation for the Adaptive Generation of Simple Sequential Programs\"]. This work was later greatly expanded by John R. Koza, a main proponent of GP who has pioneered the application of genetic programming in various complex optimization and search problems. Gianna Giavelli, a student of Koza's, later pioneered the use of genetic programming as a technique to model DNA expression.The Genetic Coding of Behavioral Attributes in Cellular Automata. Artificial Life at Stanford 1994 Stanford, California, 94305-3079 USA.\n\nIn the 1990s, GP was mainly used to solve relatively simple problems because it is very computationally intensive. Recently GP has produced many novel and outstanding results in areas such as quantum computing, electronic design, game playing, cyberterrorism prevention, sorting, and searching, due to improvements in GP technology and the exponential growth in CPU power.\nJohn R. Koza.\n[http://www.genetic-programming.com/humancompetitive.html \"36 Human-Competitive Results Produced by Genetic Programming\"].\nretrieved 2015-09-01.\n\nThese results include the replication or development of several post-year-2000 inventions. GP has also been applied to evolvable hardware as well as computer programs.\n\nDeveloping a theory for GP has been very difficult and so in the 1990s GP was considered a sort of outcast among search techniques.\n\nProgram representation\n\nGP evolves computer programs, traditionally represented in memory as tree structures. Trees can be easily evaluated in a recursive manner. Every tree node has an operator function and every terminal node has an operand, making mathematical expressions easy to evolve and evaluate. Thus traditionally GP favors the use of programming languages that naturally embody tree structures (for example, Lisp; other functional programming languages are also suitable).\n\nNon-tree representations have been suggested and successfully implemented, such as linear genetic programming which suits the more traditional imperative languages [see, for example, Banzhaf et al. (1998)].Garnett Wilson and Wolfgang Banzhaf. [http://www.cs.mun.ca/~banzhaf/papers/eurogp08_clgp.pdf \"A Comparison of Cartesian Genetic Programming and Linear Genetic Programming\"]. The commercial GP software Discipulus uses automatic induction of binary machine code (\"AIM\")(Peter Nordin, 1997, Banzhaf et al., 1998, Section 11.6.2-11.6.3) to achieve better performance. µGP uses directed multigraphs to generate programs that fully exploit the syntax of a given assembly language\n\nMost non-tree representations have structurally noneffective code (introns). Such non-coding genes may seem to be useless, because they have no effect on the performance of any one individual.\nHowever, experiments seem to show faster convergence when using program representations — such as linear genetic programming and Cartesian genetic programming — that allow such non-coding genes, compared to tree-based program representations that do not have any non-coding genes.\nJulian F. Miller.\n[https://www.springer.com/cda/content/document/cda_downloaddocument/9783642173097-c2.pdf \"Cartesian Genetic Programming\"].\np. 19.\nJanet Clegg; James Alfred Walker; Julian Francis Miller.\n[http://www.cs.bham.ac.uk/~wbl/biblio/gecco2007/docs/p1580.pdf A New Crossover Technique for Cartesian Genetic Programming\"].\n2007.\n\nOther approaches \n\nThe basic ideas of genetic programming have been modified and extended in a variety of ways:\n* Extended compact genetic programming (ECGP)\n* Embedded Cartesian genetic programming (ECGP)\n* Probabilistic incremental program evolution (PIPE)\n* Strongly typed genetic programming (STGP)\n\nMeta-genetic programming\n\nMeta-genetic programming is the proposed meta learning technique of evolving a genetic programming system using genetic programming itself. It suggests that chromosomes, crossover, and mutation were themselves evolved, therefore like their real life counterparts should be allowed to change on their own rather than being determined by a human programmer. Meta-GP was formally proposed by Jürgen Schmidhuber in 1987. Doug Lenat's Eurisko is an earlier effort that may be the same technique. It is a recursive but terminating algorithm, allowing it to avoid infinite recursion.\n\nCritics of this idea often say this approach is overly broad in scope. However, it might be possible to constrain the fitness criterion onto a general class of results, and so obtain an evolved GP that would more efficiently produce results for sub-classes. This might take the form of a meta evolved GP for producing human walking algorithms which is then used to evolve human running, jumping, etc. The fitness criterion applied to the meta GP would simply be one of efficiency.\n\nFor general problem classes there may be no way to show that meta GP will reliably produce results more efficiently than a created algorithm other than exhaustion.",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Genetic programming" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=12424" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "In artificial intelligence, genetic programming (GP) is a technique whereby computer programs are encoded as a set of genes that are then modified (evolved) using an evolutionary algorithm (often a genetic algorithm, \"GA\") – it is an application of (for example) genetic algorithms where the space of solutions consists of computer programs. The results are computer programs able to perform well in a predefined task. The methods used to encode a computer program in an artificial chromosome and to evaluate its fitness with respect to the predefined task are central in the GP technique and still the subject of active research.\n\nHistory\n\nIn 1954, pioneering work on what is today known as artificial life was carried out by Nils Aall Barricelli using the very early computers. In the 1960s and early 1970s, evolutionary algorithms became widely recognized as optimization methods. Ingo Rechenberg and his group were able to solve complex engineering problems through evolution strategies as documented in his 1971 PhD thesis and the resulting 1973 book. John Holland was highly influential during the 1970s. The establishment of evolutionary algorithms in the scientific community allowed, by then, the first concrete steps to study the GP idea.\n\nIn 1964, Lawrence J. Fogel, one of the earliest practitioners of the GP methodology, applied evolutionary algorithms to the problem of discovering finite-state automata. Later GP-related work grew out of the learning classifier system community, which developed sets of sparse rules describing optimal policies for Markov decision processes. \nIn 1981 [http://www.cs.bham.ac.uk/~wbl/biblio/gp-html/RichardForsyth.html#kybernetes:forsyth Richard Forsyth] evolved tree rules to classify heart disease.\nThe first statement of modern \"tree-based\" genetic programming (that is, procedural languages organized in tree-based structures and operated on by suitably defined GA-operators) was given by Nichael L. Cramer (1985).Nichael L. Cramer [http://www.sover.net/~nichael/nlc-publications/icga85/index.html \"A Representation for the Adaptive Generation of Simple Sequential Programs\"]. This work was later greatly expanded by John R. Koza, a main proponent of GP who has pioneered the application of genetic programming in various complex optimization and search problems. Gianna Giavelli, a student of Koza's, later pioneered the use of genetic programming as a technique to model DNA expression.The Genetic Coding of Behavioral Attributes in Cellular Automata. Artificial Life at Stanford 1994 Stanford, California, 94305-3079 USA.\n\nIn the 1990s, GP was mainly used to solve relatively simple problems because it is very computationally intensive. Recently GP has produced many novel and outstanding results in areas such as quantum computing, electronic design, game playing, cyberterrorism prevention, sorting, and searching, due to improvements in GP technology and the exponential growth in CPU power.\nJohn R. Koza.\n[http://www.genetic-programming.com/humancompetitive.html \"36 Human-Competitive Results Produced by Genetic Programming\"].\nretrieved 2015-09-01.\n\nThese results include the replication or development of several post-year-2000 inventions. GP has also been applied to evolvable hardware as well as computer programs.\n\nDeveloping a theory for GP has been very difficult and so in the 1990s GP was considered a sort of outcast among search techniques.\n\nProgram representation\n\nGP evolves computer programs, traditionally represented in memory as tree structures. Trees can be easily evaluated in a recursive manner. Every tree node has an operator function and every terminal node has an operand, making mathematical expressions easy to evolve and evaluate. Thus traditionally GP favors the use of programming languages that naturally embody tree structures (for example, Lisp; other functional programming languages are also suitable).\n\nNon-tree representations have been suggested and successfully implemented, such as linear genetic programming which suits the more traditional imperative languages [see, for example, Banzhaf et al. (1998)].Garnett Wilson and Wolfgang Banzhaf. [http://www.cs.mun.ca/~banzhaf/papers/eurogp08_clgp.pdf \"A Comparison of Cartesian Genetic Programming and Linear Genetic Programming\"]. The commercial GP software Discipulus uses automatic induction of binary machine code (\"AIM\")(Peter Nordin, 1997, Banzhaf et al., 1998, Section 11.6.2-11.6.3) to achieve better performance. µGP uses directed multigraphs to generate programs that fully exploit the syntax of a given assembly language\n\nMost non-tree representations have structurally noneffective code (introns). Such non-coding genes may seem to be useless, because they have no effect on the performance of any one individual.\nHowever, experiments seem to show faster convergence when using program representations — such as linear genetic programming and Cartesian genetic programming — that allow such non-coding genes, compared to tree-based program representations that do not have any non-coding genes.\nJulian F. Miller.\n[https://www.springer.com/cda/content/document/cda_downloaddocument/9783642173097-c2.pdf \"Cartesian Genetic Programming\"].\np. 19.\nJanet Clegg; James Alfred Walker; Julian Francis Miller.\n[http://www.cs.bham.ac.uk/~wbl/biblio/gecco2007/docs/p1580.pdf A New Crossover Technique for Cartesian Genetic Programming\"].\n2007.\n\nOther approaches \n\nThe basic ideas of genetic programming have been modified and extended in a variety of ways:\n* Extended compact genetic programming (ECGP)\n* Embedded Cartesian genetic programming (ECGP)\n* Probabilistic incremental program evolution (PIPE)\n* Strongly typed genetic programming (STGP)\n\nMeta-genetic programming\n\nMeta-genetic programming is the proposed meta learning technique of evolving a genetic programming system using genetic programming itself. It suggests that chromosomes, crossover, and mutation were themselves evolved, therefore like their real life counterparts should be allowed to change on their own rather than being determined by a human programmer. Meta-GP was formally proposed by Jürgen Schmidhuber in 1987. Doug Lenat's Eurisko is an earlier effort that may be the same technique. It is a recursive but terminating algorithm, allowing it to avoid infinite recursion.\n\nCritics of this idea often say this approach is overly broad in scope. However, it might be possible to constrain the fitness criterion onto a general class of results, and so obtain an evolved GP that would more efficiently produce results for sub-classes. This might take the form of a meta evolved GP for producing human walking algorithms which is then used to evolve human running, jumping, etc. The fitness criterion applied to the meta GP would simply be one of efficiency.\n\nFor general problem classes there may be no way to show that meta GP will reliably produce results more efficiently than a created algorithm other than exhaustion. Genetic programming. http://en.wikipedia.org/?curid=12424."
  }
}
