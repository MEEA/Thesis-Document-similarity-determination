{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=8904",
  "eid" : "eb4d4980-52b1-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778474520,
  "textBody" : "In computer science, a  double-ended queue (dequeue, often abbreviated to deque) is an abstract data type that generalizes a queue, for which elements can be added to or removed from either the front (head) or back (tail).Donald Knuth. The Art of Computer Programming, Volume 1: Fundamental Algorithms, Third Edition. Addison-Wesley, 1997. . Section 2.2.1: Stacks, Queues, and Deques, pp. 238–243. It is also often called a head-tail linked list, though properly this refers to a specific data structure implementation of a deque (see below).\n\nNaming conventions\n\nDeque is sometimes written dequeue, but this use is generally deprecated in technical literature or technical writing because dequeue is also a verb meaning \"to remove from a queue\".  Nevertheless, several libraries and some writers, such as Aho, Hopcroft, and Ullman in their textbook Data Structures and Algorithms, spell it dequeue. John Mitchell, author of Concepts in Programming Languages, also uses this terminology.\n\nDistinctions and sub-types\n\nThis differs from the queue abstract data type or First-In-First-Out List (FIFO), where elements can only be added to one end and removed from the other. This general data class has some possible sub-types:\n\n*An input-restricted deque is one where deletion can be made from both ends, but insertion can be made at one end only.\n*An output-restricted deque is one where insertion can be made at both ends, but deletion can be made from one end only.\n\nBoth the basic and most common list types in computing, queues and stacks can be considered specializations of deques, and can be implemented using deques.\n\nOperations \n\nThe basic operations on a deque are enqueue and dequeue on either end. Also generally implemented are peek operations, which return the value at that end without dequeuing it.\n\nNames vary between languages; major implementations include:\n\nImplementations \n\nThere are at least two common ways to efficiently implement a deque: with a modified dynamic array or with a doubly linked list.\n\nThe dynamic array approach uses a variant of a dynamic array that can grow from both ends, sometimes called array deques. These array deques have all the properties of a dynamic array, such as constant-time random access, good locality of reference, and inefficient insertion/removal in the middle, with the addition of amortized constant-time insertion/removal at both ends, instead of just one end. Three common implementations include:\n* Storing deque contents in a circular buffer, and only resizing when the buffer becomes full. This decreases the frequency of resizings.\n* Allocating deque contents from the center of the underlying array, and resizing the underlying array when either end is reached. This approach may require more frequent resizings and waste more space, particularly when elements are only inserted at one end.\n* Storing contents in multiple smaller arrays, allocating additional arrays at the beginning or end as needed. Indexing is implemented by keeping a dynamic array containing pointers to each of the smaller arrays.\n\nPurely functional implementation\n\nDouble-ended queues can also be implemented as a purely functional data structure.http://www.cs.cmu.edu/~rwh/theses/okasaki.pdf C. Okasaki, \"Purely Functional Data Structures\", September 1996 Two versions of the implementation exist. The first one, called real-time deque, is presented below. It allows the queue to be persistent with operations in O(1) worst-case time, but requires lazy lists with memoization.  The second one, with no lazy lists nor memoization is presented at the end of the sections. Its amortized time is O(1) if the persistency is not used; but the worst-time complexity of an operation is O(n) where n is the number of elements in the double-ended queue.\n\nLet us recall that, for a list l, |l| denotes its length, that NIL represents an empty list and CONS(h,t) represents the list whose head is h and whose tail is t. The functions drop(i,l)  and take(i,l) return the list l without its first i elements, and the i's first elements respectively. Or, if |l| , they return the empty list and l respectively.\n\nA double-ended queue is represented as a sixtuple lenf,f,sf,lenr,r,sr where f is a linked list which contains the front of the queue of length lenf. Similarly,  r is a linked list which represents the reverse of the rear of the queue, of length lenr. Furthermore, it is assured that |f|  and |r|  - intuitively, it means that neither the front nor the rear contains more than a third of the list plus one element. Finally,  sf  and  sr are tails of f and of r, they allow to schedule the moment where some lazy operations are forced. Note that, when a double-ended queue contains n elements in the front list and n elements in the rear list, then the inequality invariant remains satisfied after  i insertions and d deletions when (i+d)/2 . That is, at most n/2 operations can happen between each rebalancing.\n\nIntuitively, inserting an element x in front of the double-ended queue lenf, f, sf, lenr, sr leads almost to the double-ended queue lenf+1, CONS(x,f), drop(2,sf), lenr, r, drop(2,sr), the head and the tail of the double-ended queue lenf, CONS(x,f), sf, lenr, r, sr are x and almost lenf-1, f, drop(2,sf), lenr, r, drop(2,sr) respectively, and the head and the tail of lenf, NIL, NIL, lenr, CONS(x,NIL), drop(2,sr) are x and 0, NIL, NIL, 0, NIL, NIL respectively.  The function to insert an element in the rear, or to drop the last element of the double-ended queue, are similar to the above function which deal with the front of the double-ended queue. It is said almost because, after insertion and after an application of tail, the invariant |r|  may not be satisfied anymore. In this case it is required to rebalance the double-ended queue.\n\nIn order to avoid an operation with an O(n) costs, the algorithm uses laziness with memoization, and force the rebalancing to be partly done during the following (|l| + |r|)/2 operations, that is, before the following rebalancing. In order to create the scheduling, some auxiliary lazy functions are required. The function rotateRev(f,r,a) returns the list f, followed by the list r, and followed by the list a. It is required in this function that |r|-2|f| is 2 or 3. This function is defined by induction as rotateRev(NIL,r,a)reverse(r++a) where ++ is the concatenation operation, and by rotateRev(CONS(x,f),r,a)\nCONS(x,rotateRev(f,drop(2,r),reverse (take(2,r))++a)). It should be noted that, rotateRev(f,r,NIL) returns the list f followed by the list r reversed. The function rotateDrop(f,j,r) which returns f followed by (r without j's first element) reversed is also required, for j . It is defined by rotateDrop(f,0,r) rotateRev(f,r,NIL), rotateDrop(f,1,r) \n rotateRev(f,drop(1,r),NIL) and rotateDrop(CONS(x,f),j,r) \n CONS(x,rotateDrop(f,j-2),drop(2,r)).\n\nThe balancing function can now be defined with\n\nfun balance(q as (lenf, f,sf, lenr,r,sr))=\n  if lenf > 2*lenr+1 then\n    let val i= (left+lenr)div 2\n        val j=lenf + lenr -i\n        val f'=take(i,f)\n        val r'=rotateDrop(r,i,f)\n    in (i,f',f',j,r',r')\n  else if lenf > 2*lenr+1 then\n    let val j= (left+lenr)div 2\n        val i=lenf + lenr -j\n        val r'=take(i,r)\n        val f'=rotateDrop(f,i,r)\n    in (i,f',f',j,r',r')\n  else q\n\nNote that, without the lazy part of the implementation, this would  be a non-persistent implementation of queue   in O(1) amortized time. In this case, the lists sf and sr can be removed from the representation of the double-ended queue.\n\nLanguage support \n\nAda's containers provides the generic packages Ada.Containers.Vectors and Ada.Containers.Doubly_Linked_Lists, for the dynamic array and linked list implementations, respectively.\n\nC++'s Standard Template Library provides the class templates std::deque and std::list, for the multiple array and linked list implementations, respectively.\n\nAs of Java 6, Java's Collections Framework provides a new  interface that provides the functionality of insertion and removal at both ends. It is implemented by classes such as  (also new in Java 6) and , providing the dynamic array and linked list implementations, respectively. However, the ArrayDeque, contrary to its name, does not support random access.\n\nPerl's arrays have native support for both removing ([http://perldoc.perl.org/functions/shift.html shift] and [http://perldoc.perl.org/functions/pop.html pop]) and adding ([http://perldoc.perl.org/functions/unshift.html unshift] and [http://perldoc.perl.org/functions/push.html push]) elements on both ends.\n\nPython 2.4 introduced the collections module with support for [https://docs.python.org/2.7/library/collections.html#deque-objects deque objects].  It is implemented using a doubly linked list of fixed-length subarrays.\n\nAs of PHP 5.3, PHP's SPL extension contains the 'SplDoublyLinkedList' class that can be used to implement Deque datastructures. Previously to make a Deque structure the array functions array_shift/unshift/pop/push had to be used instead.\n\nGHC's [https://web.archive.org/web/20091015073943/http://www.haskell.org/ghc/docs/latest/html/libraries/containers/Data-Sequence.html Data.Sequence] module implements an efficient, functional deque structure in Haskell. The implementation uses 2–3 finger trees annotated with sizes. There are other (fast) possibilities to implement purely functional (thus also persistent) double queues (most using heavily lazy evaluation).http://www.cs.cmu.edu/~rwh/theses/okasaki.pdf C. Okasaki, \"Purely Functional Data Structures\", September 1996Adam L. Buchsbaum and Robert E. Tarjan. Confluently persistent deques via data structural bootstrapping. Journal of Algorithms, 18(3):513–547, May 1995. (pp. 58, 101, 125) Kaplan and Tarjan were the first to implement optimal confluently persistent catenable deques.Haim Kaplan and Robert E. Tarjan. Purely functional representations of catenable sorted lists. In ACM Symposium on Theory of Computing, pages 202–211, May  1996. (pp. 4, 82, 84, 124) Their implementation was strictly purely functional in the sense that it did not use lazy evaluation. Okasaki simplified the data structure by using lazy evaluation with a bootstrapped data structure and degrading the performance bounds from worst-case to amortized. Kaplan, Okasaki, and Tarjan produced a simpler, non-bootstrapped, amortized version that can be implemented either using lazy evaluation or more efficiently using mutation in a broader but still restricted fashion. Mihaesau and Tarjan created a simpler (but still highly complex) strictly purely functional implementation of catenable deques, and also a much simpler implementation of strictly purely functional non-catenable deques, both of which have optimal worst-case bounds.\n\nComplexity \n\n* In a doubly-linked list implementation and assuming no allocation/deallocation overhead, the time complexity of all deque operations is O(1). Additionally, the time complexity of insertion or deletion in the middle, given an iterator, is O(1); however, the time complexity of random access by index is O(n).\n* In a growing array, the amortized time complexity of all deque operations is O(1). Additionally, the time complexity of random access by index is O(1); but the time complexity of insertion or deletion in the middle is O(n).\n\nApplications \n\nOne example where a deque can be used is the A-Steal job scheduling algorithm. See p.22. This algorithm implements task scheduling for several processors. A separate deque with threads to be executed is maintained for each processor. To execute the next thread, the processor gets the first element from the deque (using the \"remove first element\" deque operation). If the current thread forks, it is put back to the front of the deque (\"insert element at front\") and a new thread is executed. When one of the processors finishes execution of its own threads (i.e. its deque is empty), it can \"steal\" a thread from another processor: it gets the last element from the deque of another processor (\"remove last element\") and executes it. The steal-job scheduling algorithm is used by Intel's Threading Building Blocks (TBB) library for parallel programming.",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Double-ended queue" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=8904" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "In computer science, a  double-ended queue (dequeue, often abbreviated to deque) is an abstract data type that generalizes a queue, for which elements can be added to or removed from either the front (head) or back (tail).Donald Knuth. The Art of Computer Programming, Volume 1: Fundamental Algorithms, Third Edition. Addison-Wesley, 1997. . Section 2.2.1: Stacks, Queues, and Deques, pp. 238–243. It is also often called a head-tail linked list, though properly this refers to a specific data structure implementation of a deque (see below).\n\nNaming conventions\n\nDeque is sometimes written dequeue, but this use is generally deprecated in technical literature or technical writing because dequeue is also a verb meaning \"to remove from a queue\".  Nevertheless, several libraries and some writers, such as Aho, Hopcroft, and Ullman in their textbook Data Structures and Algorithms, spell it dequeue. John Mitchell, author of Concepts in Programming Languages, also uses this terminology.\n\nDistinctions and sub-types\n\nThis differs from the queue abstract data type or First-In-First-Out List (FIFO), where elements can only be added to one end and removed from the other. This general data class has some possible sub-types:\n\n*An input-restricted deque is one where deletion can be made from both ends, but insertion can be made at one end only.\n*An output-restricted deque is one where insertion can be made at both ends, but deletion can be made from one end only.\n\nBoth the basic and most common list types in computing, queues and stacks can be considered specializations of deques, and can be implemented using deques.\n\nOperations \n\nThe basic operations on a deque are enqueue and dequeue on either end. Also generally implemented are peek operations, which return the value at that end without dequeuing it.\n\nNames vary between languages; major implementations include:\n\nImplementations \n\nThere are at least two common ways to efficiently implement a deque: with a modified dynamic array or with a doubly linked list.\n\nThe dynamic array approach uses a variant of a dynamic array that can grow from both ends, sometimes called array deques. These array deques have all the properties of a dynamic array, such as constant-time random access, good locality of reference, and inefficient insertion/removal in the middle, with the addition of amortized constant-time insertion/removal at both ends, instead of just one end. Three common implementations include:\n* Storing deque contents in a circular buffer, and only resizing when the buffer becomes full. This decreases the frequency of resizings.\n* Allocating deque contents from the center of the underlying array, and resizing the underlying array when either end is reached. This approach may require more frequent resizings and waste more space, particularly when elements are only inserted at one end.\n* Storing contents in multiple smaller arrays, allocating additional arrays at the beginning or end as needed. Indexing is implemented by keeping a dynamic array containing pointers to each of the smaller arrays.\n\nPurely functional implementation\n\nDouble-ended queues can also be implemented as a purely functional data structure.http://www.cs.cmu.edu/~rwh/theses/okasaki.pdf C. Okasaki, \"Purely Functional Data Structures\", September 1996 Two versions of the implementation exist. The first one, called real-time deque, is presented below. It allows the queue to be persistent with operations in O(1) worst-case time, but requires lazy lists with memoization.  The second one, with no lazy lists nor memoization is presented at the end of the sections. Its amortized time is O(1) if the persistency is not used; but the worst-time complexity of an operation is O(n) where n is the number of elements in the double-ended queue.\n\nLet us recall that, for a list l, |l| denotes its length, that NIL represents an empty list and CONS(h,t) represents the list whose head is h and whose tail is t. The functions drop(i,l)  and take(i,l) return the list l without its first i elements, and the i's first elements respectively. Or, if |l| , they return the empty list and l respectively.\n\nA double-ended queue is represented as a sixtuple lenf,f,sf,lenr,r,sr where f is a linked list which contains the front of the queue of length lenf. Similarly,  r is a linked list which represents the reverse of the rear of the queue, of length lenr. Furthermore, it is assured that |f|  and |r|  - intuitively, it means that neither the front nor the rear contains more than a third of the list plus one element. Finally,  sf  and  sr are tails of f and of r, they allow to schedule the moment where some lazy operations are forced. Note that, when a double-ended queue contains n elements in the front list and n elements in the rear list, then the inequality invariant remains satisfied after  i insertions and d deletions when (i+d)/2 . That is, at most n/2 operations can happen between each rebalancing.\n\nIntuitively, inserting an element x in front of the double-ended queue lenf, f, sf, lenr, sr leads almost to the double-ended queue lenf+1, CONS(x,f), drop(2,sf), lenr, r, drop(2,sr), the head and the tail of the double-ended queue lenf, CONS(x,f), sf, lenr, r, sr are x and almost lenf-1, f, drop(2,sf), lenr, r, drop(2,sr) respectively, and the head and the tail of lenf, NIL, NIL, lenr, CONS(x,NIL), drop(2,sr) are x and 0, NIL, NIL, 0, NIL, NIL respectively.  The function to insert an element in the rear, or to drop the last element of the double-ended queue, are similar to the above function which deal with the front of the double-ended queue. It is said almost because, after insertion and after an application of tail, the invariant |r|  may not be satisfied anymore. In this case it is required to rebalance the double-ended queue.\n\nIn order to avoid an operation with an O(n) costs, the algorithm uses laziness with memoization, and force the rebalancing to be partly done during the following (|l| + |r|)/2 operations, that is, before the following rebalancing. In order to create the scheduling, some auxiliary lazy functions are required. The function rotateRev(f,r,a) returns the list f, followed by the list r, and followed by the list a. It is required in this function that |r|-2|f| is 2 or 3. This function is defined by induction as rotateRev(NIL,r,a)reverse(r++a) where ++ is the concatenation operation, and by rotateRev(CONS(x,f),r,a)\nCONS(x,rotateRev(f,drop(2,r),reverse (take(2,r))++a)). It should be noted that, rotateRev(f,r,NIL) returns the list f followed by the list r reversed. The function rotateDrop(f,j,r) which returns f followed by (r without j's first element) reversed is also required, for j . It is defined by rotateDrop(f,0,r) rotateRev(f,r,NIL), rotateDrop(f,1,r) \n rotateRev(f,drop(1,r),NIL) and rotateDrop(CONS(x,f),j,r) \n CONS(x,rotateDrop(f,j-2),drop(2,r)).\n\nThe balancing function can now be defined with\n\nfun balance(q as (lenf, f,sf, lenr,r,sr))=\n  if lenf > 2*lenr+1 then\n    let val i= (left+lenr)div 2\n        val j=lenf + lenr -i\n        val f'=take(i,f)\n        val r'=rotateDrop(r,i,f)\n    in (i,f',f',j,r',r')\n  else if lenf > 2*lenr+1 then\n    let val j= (left+lenr)div 2\n        val i=lenf + lenr -j\n        val r'=take(i,r)\n        val f'=rotateDrop(f,i,r)\n    in (i,f',f',j,r',r')\n  else q\n\nNote that, without the lazy part of the implementation, this would  be a non-persistent implementation of queue   in O(1) amortized time. In this case, the lists sf and sr can be removed from the representation of the double-ended queue.\n\nLanguage support \n\nAda's containers provides the generic packages Ada.Containers.Vectors and Ada.Containers.Doubly_Linked_Lists, for the dynamic array and linked list implementations, respectively.\n\nC++'s Standard Template Library provides the class templates std::deque and std::list, for the multiple array and linked list implementations, respectively.\n\nAs of Java 6, Java's Collections Framework provides a new  interface that provides the functionality of insertion and removal at both ends. It is implemented by classes such as  (also new in Java 6) and , providing the dynamic array and linked list implementations, respectively. However, the ArrayDeque, contrary to its name, does not support random access.\n\nPerl's arrays have native support for both removing ([http://perldoc.perl.org/functions/shift.html shift] and [http://perldoc.perl.org/functions/pop.html pop]) and adding ([http://perldoc.perl.org/functions/unshift.html unshift] and [http://perldoc.perl.org/functions/push.html push]) elements on both ends.\n\nPython 2.4 introduced the collections module with support for [https://docs.python.org/2.7/library/collections.html#deque-objects deque objects].  It is implemented using a doubly linked list of fixed-length subarrays.\n\nAs of PHP 5.3, PHP's SPL extension contains the 'SplDoublyLinkedList' class that can be used to implement Deque datastructures. Previously to make a Deque structure the array functions array_shift/unshift/pop/push had to be used instead.\n\nGHC's [https://web.archive.org/web/20091015073943/http://www.haskell.org/ghc/docs/latest/html/libraries/containers/Data-Sequence.html Data.Sequence] module implements an efficient, functional deque structure in Haskell. The implementation uses 2–3 finger trees annotated with sizes. There are other (fast) possibilities to implement purely functional (thus also persistent) double queues (most using heavily lazy evaluation).http://www.cs.cmu.edu/~rwh/theses/okasaki.pdf C. Okasaki, \"Purely Functional Data Structures\", September 1996Adam L. Buchsbaum and Robert E. Tarjan. Confluently persistent deques via data structural bootstrapping. Journal of Algorithms, 18(3):513–547, May 1995. (pp. 58, 101, 125) Kaplan and Tarjan were the first to implement optimal confluently persistent catenable deques.Haim Kaplan and Robert E. Tarjan. Purely functional representations of catenable sorted lists. In ACM Symposium on Theory of Computing, pages 202–211, May  1996. (pp. 4, 82, 84, 124) Their implementation was strictly purely functional in the sense that it did not use lazy evaluation. Okasaki simplified the data structure by using lazy evaluation with a bootstrapped data structure and degrading the performance bounds from worst-case to amortized. Kaplan, Okasaki, and Tarjan produced a simpler, non-bootstrapped, amortized version that can be implemented either using lazy evaluation or more efficiently using mutation in a broader but still restricted fashion. Mihaesau and Tarjan created a simpler (but still highly complex) strictly purely functional implementation of catenable deques, and also a much simpler implementation of strictly purely functional non-catenable deques, both of which have optimal worst-case bounds.\n\nComplexity \n\n* In a doubly-linked list implementation and assuming no allocation/deallocation overhead, the time complexity of all deque operations is O(1). Additionally, the time complexity of insertion or deletion in the middle, given an iterator, is O(1); however, the time complexity of random access by index is O(n).\n* In a growing array, the amortized time complexity of all deque operations is O(1). Additionally, the time complexity of random access by index is O(1); but the time complexity of insertion or deletion in the middle is O(n).\n\nApplications \n\nOne example where a deque can be used is the A-Steal job scheduling algorithm. See p.22. This algorithm implements task scheduling for several processors. A separate deque with threads to be executed is maintained for each processor. To execute the next thread, the processor gets the first element from the deque (using the \"remove first element\" deque operation). If the current thread forks, it is put back to the front of the deque (\"insert element at front\") and a new thread is executed. When one of the processors finishes execution of its own threads (i.e. its deque is empty), it can \"steal\" a thread from another processor: it gets the last element from the deque of another processor (\"remove last element\") and executes it. The steal-job scheduling algorithm is used by Intel's Threading Building Blocks (TBB) library for parallel programming. Double-ended queue. http://en.wikipedia.org/?curid=8904."
  }
}
