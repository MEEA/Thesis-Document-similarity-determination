{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=6113",
  "eid" : "d9eff1b0-52b1-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778445387,
  "textBody" : "In calculus, the chain rule is a formula for computing the derivative of the composition of two or more functions. That is, if f and g are functions, then the chain rule expresses the derivative of their composition  (the function which maps x to f(g(x)) ) in terms of the derivatives of f and g and the product of functions as follows:\n\n(f\\circ g)'=(f'\\circ g)\\cdot g'.\n\nThis can be written more explicitly in terms of the variable. Let , or equivalently,  for all x. Then one can also write\nF'(x) = f'(g(x)) g'(x).\n\nThe chain rule may be written in Leibniz's notation in the following way. If a variable z depends on the variable y, which itself depends on the variable x, so that y and z are therefore dependent variables, then z, via the intermediate variable of y, depends on x as well.  The chain rule then states,\n\n\\frac{dz}{dx} = \\frac{dz}{dy} \\cdot \\frac{dy}{dx}. \n\nThe two versions of the chain rule are related; if zf(y) and y\ng(x), then\n\n\\frac{dz}{dx}\\frac{dz}{dy}\\cdot\\frac{dy}{dx} \n f'(y)g'(x) = f'(g(x))g'(x).\n\nIn integration, the counterpart to the chain rule is the substitution rule.\n\nHistory \n\nThe chain rule seems to have first been used by Leibniz. He used it to calculate the derivative of \\sqrt{a + bz + cz^2} as the composite of the square root function and the function a + bz + cz^2.  He first mentioned it in a 1676 memoir (with a sign error in the calculation). The common notation of chain rule is due to Leibniz. L'Hôpital uses the chain rule implicitly in his Analyse des infiniment petits. The chain rule does not appear in any of Leonhard Euler's analysis books, even though they were written over a hundred years after Leibniz's discovery.\n\nOne dimension \n\nFirst example \n\nSuppose that a skydiver jumps from an aircraft.  Assume that t seconds after his jump, his height above sea level in meters is given by .  One model for the atmospheric pressure at a height h is .  These two equations can be differentiated and combined in various ways to produce the following data:\n*  is the velocity of the skydiver at time t.\n*  is the rate of change in atmospheric pressure with respect to height at the height h and is proportional to the buoyant force on the skydiver at h meters above sea level.  (The true buoyant force depends on the volume of the skydiver.)\n*  is the atmospheric pressure the skydiver experiences t seconds after his jump.\n*  is the rate of change in atmospheric pressure with respect to time at t seconds after the skydiver's jump and is proportional to the buoyant force on the skydiver at t seconds after his jump.\nThe chain rule gives a method for computing  in terms of  and .  While it is always possible to directly apply the definition of the derivative to compute the derivative of a composite function, this is usually very difficult.  The utility of the chain rule is that it turns a complicated derivative into several easy derivatives.\n\nThe chain rule states that, under appropriate conditions,\n(f \\circ g)'(t) = f'(g(t))\\cdot g'(t).\nIn this example, this equals\n(f \\circ g)'(t) = \\big(\\mathord{-}10.1325e^{-0.0001(4000 - 4.9t^2)}\\big)\\cdot\\big(\\mathord{-}9.8t\\big).\n\nIn the statement of the chain rule, f and g play slightly different roles because f′ is evaluated at g(t) whereas g′ is evaluated at t.  This is necessary to make the units work out correctly.  For example, suppose that we want to compute the rate of change in atmospheric pressure ten seconds after the skydiver jumps.  This is  and has units of pascals per second.  The factor g′(10) in the chain rule is the velocity of the skydiver ten seconds after his jump, and it is expressed in meters per second.  f′(g(10)) is the change in pressure with respect to height at the height g(10) and is expressed in pascals per meter.  The product of f′(g(10)) and g′(10) therefore has the correct units of pascals per second.  It is not possible to evaluate f anywhere else.  For instance, because the 10 in the problem represents ten seconds, the expression f′(10) represents the change in pressure at a height of ten seconds, which is nonsense.  Similarly, because  meters per second, the expression f′(g′(10)) represents the change in pressure at a height of −98 meters per second, which is also nonsense.  However, g(10) is 3020 meters above sea level, the height of the skydiver ten seconds after his jump.  This has the correct units for an input to f.\n\nStatement \n\nThe simplest form of the chain rule is for real-valued functions of one real variable.  It says that if g is a function that is differentiable at a point c (i.e. the derivative g′(c) exists) and f is a function that is differentiable at g(c), then the composite function  is differentiable at c, and the derivative is\n\n (f\\circ g)'(c) = f'(g(c))\\cdot g'(c). \n\nThe rule is sometimes abbreviated as\n\n(f\\circ g)' = (f'\\circ g) \\cdot g'.\n\nIf  and , then this abbreviated form is written in Leibniz notation as:\n\n\\frac{dy}{dx} = \\frac{dy}{du} \\cdot \\frac{du}{dx}.\n\nThe points where the derivatives are evaluated may also be stated explicitly:\n\n\\left.\\frac{dy}{dx}\\right|_{xc} \n \\left.\\frac{dy}{du}\\right|_{u g(c)} \\cdot \\left.\\frac{du}{dx}\\right|_{x\nc}.\n\nFurther examples \n\nAbsence of formulas \n\nIt may be possible to apply the chain rule even when there are no formulas for the functions which are being differentiated.  This can happen when the derivatives are measured directly.  Suppose that a car is driving up a tall mountain.  The car's speedometer measures its speed directly.  If the grade is known, then the rate of ascent can be calculated using trigonometry.  Suppose that the car is ascending at .  Standard models for the Earth's atmosphere imply that the temperature drops about  per kilometer ascended (called the lapse rate).  To find the temperature drop per hour, we apply the chain rule.  Let the function  be the altitude of the car at time , and let the function  be the temperature  kilometers above sea level.   and  are not known exactly: For example, the altitude where the car starts is not known and the temperature on the mountain is not known.  However, their derivatives are known:  is , and  is .  The chain rule says that the derivative of the composite function is the product of the derivative of  and the derivative of .  This is .\n\nOne of the reasons why this computation is possible is because  is a constant function.  This is because the above model is very simple.  A more accurate description of how the temperature near the car varies over time would require an accurate model of how the temperature varies at different altitudes.  This model may not have a constant derivative.  To compute the temperature change in such a model, it would be necessary to know  and not just , because without knowing  it is not possible to know where to evaluate .\n\nComposites of more than two functions \n\nThe chain rule can be applied to composites of more than two functions.  To take the derivative of a composite of more than two functions, notice that the composite of f, g, and h (in that order) is the composite of f with .  The chain rule says that to compute the derivative of , it is sufficient to compute the derivative of f and the derivative of .  The derivative of f can be calculated directly, and the derivative of  can be calculated by applying the chain rule again.\n\nFor concreteness, consider the function\ny = e^{\\sin {x^2}}.\nThis can be decomposed as the composite of three functions:\n\\begin{align}\ny &f(u) \n e^u, \\\\\nu &g(v) \n \\sin v, \\\\\nv &h(x) \n x^2.\n\\end{align}\nTheir derivatives are:\n\\begin{align}\n\\frac{dy}{du} &f'(u) \n e^u, \\\\\n\\frac{du}{dv} &g'(v) \n \\cos v, \\\\\n\\frac{dv}{dx} &h'(x) \n 2x.\n\\end{align}\nThe chain rule says that the derivative of their composite at the point  is:\n(f \\circ g \\circ h)'(a) f'((g \\circ h)(a))\\cdot (g \\circ h)'(a) \n f'((g \\circ h)(a)) \\cdot g'(h(a)) \\cdot h'(a) = (f' \\circ g \\circ h)(a) \\cdot (g' \\circ h)(a) \\cdot h'(a).\nIn Leibniz notation, this is:\n\\frac{dy}{dx} \\left.\\frac{dy}{du}\\right|_{u\ng(h(a))}\\cdot\\left.\\frac{du}{dv}\\right|_{vh(a)}\\cdot\\left.\\frac{dv}{dx}\\right|_{x\na},\nor for short,\n\\frac{dy}{dx} = \\frac{dy}{du}\\cdot\\frac{du}{dv}\\cdot\\frac{dv}{dx}.\nThe derivative function is therefore:\n\\frac{dy}{dx} = e^{\\sin {x^2}}\\cdot\\cos{x^2}\\cdot 2x.\n\nAnother way of computing this derivative is to view the composite function  as the composite of  and h.  Applying the chain rule to this situation gives:\n(f \\circ g \\circ h)'(a) (f \\circ g)'(h(a))\\cdot h'(a) \n f'(g(h(a)))\\cdot g'(h(a))\\cdot h'(a).\nThis is the same as what was computed above.  This should be expected because .\n\nSometimes it is necessary to differentiate an arbitrarily long composition of the form f_1 \\circ f_2 \\circ \\dotso \\circ f_{n-1} \\circ f_n. In this case, define\nf_{a..b} = f_{a} \\circ f_{a+1} \\circ \\dotso \\circ f_{b-1} \\circ f_{b}\nwhere f_{a..a} f_a and f_{a..b}(x) \n x when b . Then the chain rule takes the form\nDf_{1..n} (Df_1 \\circ f_{2..n}) (Df_2 \\circ f_{3..n}) \\dotso (Df_{n-1} \\circ f_{n..n}) Df_n \n \\prod_{k=1}^{n} \\left[Df_k \\circ f_{(k+1)..n}\\right]\nor, in the Lagrange notation,\nf_{1..n}'(x) f_1' \\left( f_{2..n}(x) \\right) \\; f_2' \\left( f_{3..n}(x) \\right) \\; \\dotso \\; f_{n-1}' \\left(f_{n..n}(x)\\right) \\; f_n'(x) \n \\prod_{k=1}^{n} f_k' \\left(f_{(k+1..n)}(x) \\right)\n\nQuotient rule \n\nThe chain rule can be used to derive some well-known differentiation rules.  For example, the quotient rule is a consequence of the chain rule and the product rule.  To see this, write the function f(x)/g(x) as the product .  First apply the product rule:\n\\begin{align}\n\\frac{d}{dx}\\left(\\frac{f(x)}{g(x)}\\right)\n&= \\frac{d}{dx}\\left(f(x)\\cdot\\frac{1}{g(x)}\\right) \\\\\n&= f'(x)\\cdot\\frac{1}{g(x)} + f(x)\\cdot\\frac{d}{dx}\\left(\\frac{1}{g(x)}\\right).\n\\end{align}\nTo compute the derivative of 1/g(x), notice that it is the composite of g with the reciprocal function, that is, the function that sends x to 1/x.  The derivative of the reciprocal function is −1/x2.  By applying the chain rule, the last expression becomes:\nf'(x)\\cdot\\frac{1}{g(x)} + f(x)\\cdot\\left(-\\frac{1}{g(x)^2}\\cdot g'(x)\\right)\n= \\frac{f'(x) g(x) - f(x) g'(x)}{g(x)^2},\nwhich is the usual formula for the quotient rule.\n\nDerivatives of inverse functions \n\nSuppose that  has an inverse function.  Call its inverse function f so that we have .  There is a formula for the derivative of f in terms of the derivative of g.  To see this, note that f and g satisfy the formula\nf(g(x)) = x.\nBecause the functions f(g(x)) and x are equal, their derivatives must be equal.  The derivative of x is the constant function with value 1, and the derivative of f(g(x)) is determined by the chain rule.  Therefore, we have:\nf'(g(x)) g'(x) = 1.\nTo express f′ as a function of an independent variable y, we substitute f(y) for x wherever it appears.  Then we can solve for f′.\n\\begin{align}\nf'(g(f(y))) g'(f(y)) &= 1 \\\\\nf'(y) g'(f(y)) &= 1 \\\\\nf'(y) = \\frac{1}{g'(f(y))}.\n\\end{align}\n\nFor example, consider the function .  It has an inverse .  Because , the above formula says that\n\\frac{d}{dy}\\ln y \\frac{1}{e^{\\ln y}} \n \\frac{1}{y}.\n\nThis formula is true whenever g is differentiable and its inverse f is also differentiable.  This formula can fail when one of these conditions is not true.  For example, consider .  Its inverse is , which is not differentiable at zero.  If we attempt to use the above formula to compute the derivative of f at zero, then we must evaluate 1/g′(f(0)).   and , so we must evaluate 1/0, which is undefined.  Therefore, the formula fails in this case.  This is not surprising because f is not differentiable at zero.\n\nHigher derivatives \n\nFaà di Bruno's formula generalizes the chain rule to higher derivatives.  Assuming that  and , then the first few derivatives are:\n\n\\begin{align}\n\\frac{dy}{dx} & = \\frac{dy}{du} \\frac{du}{dx} \\\\[4pt]\n\\frac{d^2 y }{d x^2} & = \\frac{d^2 y}{d u^2} \\left(\\frac{du}{dx}\\right)^2\n    + \\frac{dy}{du} \\frac{d^2 u}{dx^2} \\\\[4pt]\n\\frac{d^3 y }{d x^3} & = \\frac{d^3 y}{d u^3} \\left(\\frac{du}{dx}\\right)^3\n    + 3 \\, \\frac{d^2 y}{d u^2} \\frac{du}{dx} \\frac{d^2 u}{d x^2}\n    + \\frac{dy}{du} \\frac{d^3 u}{d x^3} \\\\[4pt]\n\\frac{d^4 y}{d x^4} & =\\frac{d^4 y}{du^4} \\left(\\frac{du}{dx}\\right)^4\n    + 6 \\, \\frac{d^3 y}{d u^3} \\left(\\frac{du}{dx}\\right)^2 \\frac{d^2 u}{d x^2}\n    + \\frac{d^2 y}{d u^2} \\left( 4 \\, \\frac{du}{dx} \\frac{d^3 u}{dx^3}\n    + 3 \\, \\left(\\frac{d^2 u}{dx^2}\\right)^2\\right)\n    + \\frac{dy}{du} \\frac{d^4 u}{dx^4}.\n\\end{align}\n\nProofs \n\nFirst proof \n\nOne proof of the chain rule begins with the definition of the derivative:\n(f \\circ g)'(a) = \\lim_{x \\to a} \\frac{f(g(x)) - f(g(a))}{x - a}.\nAssume for the moment that g(x) does not equal g(a) for any x near a.  Then the previous expression is equal to the product of two factors:\n\\lim_{x \\to a} \\frac{f(g(x)) - f(g(a))}{g(x) - g(a)} \\cdot \\frac{g(x) - g(a)}{x - a}.\nWhen g oscillates near a, then it might happen that no matter how close one gets to a, there is always an even closer x such that g(x) equals g(a).  For example, this happens for  near the point .  Whenever this happens, the above expression is undefined because it involves division by zero.  To work around this, introduce a function Q as follows:\nQ(y) = \\begin{cases}\n\\frac{f(y) - f(g(a))}{y - g(a)}, & y \\neq g(a), \\\\\nf'(g(a)), & y = g(a).\n\\end{cases}\nWe will show that the difference quotient for  is always equal to:\nQ(g(x)) \\cdot \\frac{g(x) - g(a)}{x - a}.\nWhenever g(x) is not equal to g(a), this is clear because the factors of  cancel.  When g(x) equals g(a), then the difference quotient for  is zero because f(g(x)) equals f(g(a)), and the above product is zero because it equals f′(g(a)) times zero.  So the above product is always equal to the difference quotient, and to show that the derivative of  at a exists and to determine its value, we need only show that the limit as x goes to a of the above product exists and determine its value.\n\nTo do this, recall that the limit of a product exists if the limits of its factors exist.  When this happens, the limit of the product of these two factors will equal the product of the limits of the factors.  The two factors are Q(g(x)) and .  The latter is the difference quotient for g at a, and because g is differentiable at a by assumption, its limit as x tends to a exists and equals g′(a).\n\nIt remains to study Q(g(x)).  Q is defined wherever f is.  Furthermore, because f is differentiable at g(a) by assumption, Q is continuous at g(a).  g is continuous at a because it is differentiable at a, and therefore  is continuous at a.  So its limit as x goes to a exists and equals Q(g(a)), which is f′(g(a)).\n\nThis shows that the limits of both factors exist and that they equal f′(g(a)) and g′(a), respectively.  Therefore, the derivative of  at a exists and equals f′(g(a))g′(a).\n\nSecond proof \n\nAnother way of proving the chain rule is to measure the error in the linear approximation determined by the derivative.  This proof has the advantage that it generalizes to several variables.  It relies on the following equivalent definition of differentiability at a point: A function g is differentiable at a if there exists a real number g′(a) and a function ε(h) that tends to zero as h tends to zero, and furthermore\ng(a + h) - g(a) = g'(a) h + \\varepsilon(h) h.\nHere the left-hand side represents the true difference between the value of g at a and at , whereas the right-hand side represents the approximation determined by the derivative plus an error term.\n\nIn the situation of the chain rule, such a function ε exists because g is assumed to be differentiable at a.  Again by assumption, a similar function also exists for f at g(a).  Calling this function η, we have\nf(g(a) + k) - f(g(a)) = f'(g(a)) k + \\eta(k) k.\nThe above definition imposes no constraints on η(0), even though it is assumed that η(k) tends to zero as k tends to zero.  If we set , then η is continuous at 0.\n\nProving the theorem requires studying the difference  as h tends to zero.  The first step is to substitute for  using the definition of differentiability of g at a:\nf(g(a + h)) - f(g(a)) = f(g(a) + g'(a) h + \\varepsilon(h) h) - f(g(a)).\nThe next step is to use the definition of differentiability of f at g(a).  This requires a term of the form  for some k.  In the above equation, the correct k varies with h.  Set  and the right hand side becomes .  Applying the definition of the derivative gives:\nf(g(a) + k_h) - f(g(a)) = f'(g(a)) k_h + \\eta(k_h) k_h.\nTo study the behavior of this expression as h tends to zero, expand kh. After regrouping the terms, the right-hand side becomes:\nf'(g(a)) g'(a)h + [f'(g(a)) \\varepsilon(h) + \\eta(k_h) g'(a) + \\eta(k_h) \\varepsilon(h)] h.\nBecause ε(h) and η(kh) tend to zero as h tends to zero, the first two bracketed terms tend to zero as h tends to zero.  Applying the same theorem on products of limits as in the first proof, the third bracketed term also tends zero.  Because the above expression is equal to the difference , by the definition of the derivative  is differentiable at a and its derivative is \n\nThe role of Q in the first proof is played by η in this proof.  They are related by the equation:\nQ(y) = f'(g(a)) + \\eta(y - g(a)). \nThe need to define Q at g(a) is analogous to the need to define η at zero.\n\nThird proof \n\nCarathéodory's alternative definition of the differentiability of a function can be used to give an elegant proof of the chain rule.\n\nUnder this definition, a function  is differentiable at a point  if and only if there is a function , continuous at  and such that . There is at most one such function, and if  is differentiable at  then .\n\nGiven the assumptions of the chain rule and the fact that differentiable functions and compositions of continuous functions are continuous, we have that there exist functions , continuous at  and , continuous at  and such that,\nf(g(x))-f(g(a))=q(g(x))(g(x)-g(a))\nand\ng(x)-g(a)=r(x)(x-a).\nTherefore,\nf(g(x))-f(g(a))=q(g(x))r(x)(x-a),\nbut the function given by  is continuous at , and we get, for this \n(f(g(a)))'q(g(a))r(a)\nf'(g(a))g'(a).\nA similar approach works for continuously differentiable (vector-)functions of many variables. This ideology of factoring also allows a unified approach to stronger forms of differentiability, when the derivative is required to be Lipschitz, Holder, etc. Differentiation itself can be viewed as the polynomial remainder theorem (the little Bezout, or factor theorem), generalized to an appropriate class of functions. \n\nProof via infinitesimals \n\nIf yf(x) and x\ng(t) then choosing infinitesimal \\Delta t\\not0 we compute the corresponding \\Delta x\ng(t+\\Delta t)-g(t) and then the corresponding \\Delta y=f(x+\\Delta x)-f(x), so that\n\\frac{\\Delta y}{\\Delta t}=\\frac{\\Delta y}{\\Delta x} \\frac{\\Delta x}{\\Delta t}\nand applying the standard part we obtain\n\\frac{d y}{d t}=\\frac{d y}{d x} \\frac{dx}{dt}\nwhich is the chain rule.\n\nHigher dimensions \n\nThe simplest generalization of the chain rule to higher dimensions uses the total derivative. The total derivative is a linear transformation that captures how the function changes in all directions.  Fix differentiable functions  and  and a point a in Rn.  Let Dag denote the total derivative of g at a and Dg(a)f denote the total derivative of f at g(a).  These two derivatives are linear transformations  and , respectively, so they can be composed.  The chain rule for total derivatives says that their composite is the total derivative of  at a:\nD_{\\mathbf{a}}(f \\circ g) = D_{g(\\mathbf{a})}f \\circ D_{\\mathbf{a}}g,\nor for short,\nD(f \\circ g) = Df \\circ Dg.\nThe higher-dimensional chain rule can be proved using a technique similar to the second proof given above.\n\nBecause the total derivative is a linear transformation, the functions appearing in the formula can be rewritten as matrices.  The matrix corresponding to a total derivative is called a Jacobian matrix, and the composite of two derivatives corresponds to the product of their Jacobian matrices.  From this perspective the chain rule therefore says:\nJ_{f \\circ g}(\\mathbf{a}) = J_{f}(g(\\mathbf{a})) J_{g}(\\mathbf{a}),\nor for short,\nJ_{f \\circ g} = (J_f \\circ g)J_g.\n\nThat is, the Jacobian of a composite function is the product of the Jacobians of the composed functions (evaluated at the appropriate points).\n\nThe higher-dimensional chain rule is a generalization of the one-dimensional chain rule.  If k, m, and n are 1, so that  and , then the Jacobian matrices of f and g are .  Specifically, they are:\n\\begin{align}\nJ_g(a) &= \\begin{pmatrix} g'(a) \\end{pmatrix}, \\\\\nJ_{f}(g(a)) &= \\begin{pmatrix} f'(g(a)) \\end{pmatrix}.\n\\end{align}\nThe Jacobian of f ∘ g is the product of these  matrices, so it is , as expected from the one-dimensional chain rule.  In the language of linear transformations, Da(g) is the function which scales a vector by a factor of g′(a) and Dg(a)(f) is the function which scales a vector by a factor of f′(g(a)).  The chain rule says that the composite of these two linear transformations is the linear transformation , and therefore it is the function that scales a vector by f′(g(a))⋅g′(a).\n\nAnother way of writing the chain rule is used when f and g are expressed in terms of their components as  and .  In this case, the above rule for Jacobian matrices is usually written as:\n\\frac{\\partial(y_1, \\ldots, y_k)}{\\partial(x_1, \\ldots, x_n)} = \\frac{\\partial(y_1, \\ldots, y_k)}{\\partial(u_1, \\ldots, u_m)} \\frac{\\partial(u_1, \\ldots, u_m)}{\\partial(x_1, \\ldots, x_n)}.\n\nThe chain rule for total derivatives implies a chain rule for partial derivatives.  Recall that when the total derivative exists, the partial derivative in the ith coordinate direction is found by multiplying the Jacobian matrix by the ith basis vector.  By doing this to the formula above, we find:\n\\frac{\\partial(y_1, \\ldots, y_k)}{\\partial x_i} = \\frac{\\partial(y_1, \\ldots, y_k)}{\\partial(u_1, \\ldots, u_m)} \\frac{\\partial(u_1, \\ldots, u_m)}{\\partial x_i}.\nSince the entries of the Jacobian matrix are partial derivatives, we may simplify the above formula to get:\n\\frac{\\partial(y_1, \\ldots, y_k)}{\\partial x_i} \\sum_{\\ell \n 1}^m \\frac{\\partial(y_1, \\ldots, y_k)}{\\partial u_\\ell} \\frac{\\partial u_\\ell}{\\partial x_i}.\nMore conceptually, this rule expresses the fact that a change in the xi direction may change all of g1 through gm, and any of these changes may affect f.\n\nIn the special case where , so that f is a real-valued function, then this formula simplifies even further:\n\\frac{\\partial y}{\\partial x_i} \\sum_{\\ell \n 1}^m \\frac{\\partial y}{\\partial u_\\ell} \\frac{\\partial u_\\ell}{\\partial x_i}.\nThis can be rewritten as a dot product.  Recalling that , the partial derivative  is also a vector, and the chain rule says that:\n\\frac{\\partial y}{\\partial x_i} = \\nabla y \\cdot \\frac{\\partial \\mathbf{u}}{\\partial x_i}.\n\nExample \n\nGiven  where  and , determine the value of  and  using the chain rule.\n\\frac{\\partial u}{\\partial r}\\frac{\\partial u}{\\partial x} \\frac{\\partial x}{\\partial r}+\\frac{\\partial u}{\\partial y} \\frac{\\partial y}{\\partial r} \n (2x)(\\sin(t)) + (2)(0) = 2r \\sin^2(t),\nand\n\\begin{align}\\frac{\\partial u}{\\partial t}\n&= \\frac{\\partial u}{\\partial x} \\frac{\\partial x}{\\partial t}+\\frac{\\partial u}{\\partial y} \\frac{\\partial y}{\\partial t} \\\\\n&= (2x)(r\\cos(t)) + (2)(2\\sin(t)\\cos(t)) \\\\\n&= (2r\\sin(t))(r\\cos(t)) + 4\\sin(t)\\cos(t) \\\\\n&= 2(r^2 + 2) \\sin(t)\\cos(t) \\\\\n&= (r^2 + 2) \\sin(2t).\\end{align}\n\nHigher derivatives of multivariable functions \n\nFaà di Bruno's formula for higher-order derivatives of single-variable functions generalizes to the multivariable case.  If  is a function of  as above, then the second derivative of  is:\n\\frac{\\partial^2 y}{\\partial x_i \\partial x_j} = \\sum_k \\left(\\frac{\\partial y}{\\partial u_k}\\frac{\\partial^2 u_k}{\\partial x_i \\partial x_j}\\right) + \\sum_{k, \\ell} \\left(\\frac{\\partial^2 y}{\\partial u_k \\partial u_\\ell}\\frac{\\partial u_k}{\\partial x_i}\\frac{\\partial u_\\ell}{\\partial x_j}\\right).\n\nFurther generalizations \n\nAll extensions of calculus have a chain rule. In most of these, the formula remains the same, though the meaning of that formula may be vastly different.\n\nOne generalization is to manifolds. In this situation, the chain rule represents the fact that the derivative of  is the composite of the derivative of f and the derivative of g. This theorem is an immediate consequence of the higher dimensional chain rule given above, and it has exactly the same formula.\n\nThe chain rule is also valid for Fréchet derivatives in Banach spaces.  The same formula holds as before. This case and the previous one admit a simultaneous generalization to Banach manifolds.\n\nIn abstract algebra, the derivative is interpreted as a morphism of modules of Kähler differentials. A ring homomorphism of commutative rings  determines a morphism of Kähler differentials  which sends an element dr to d(f(r)), the exterior differential of f(r). The formula  holds in this context as well.\n\nThe common feature of these examples is that they are expressions of the idea that the derivative is part of a functor. A functor is an operation on spaces and functions between them. It associates to each space a new space and to each function between two spaces a new function between the corresponding new spaces. In each of the above cases, the functor sends each space to its tangent bundle and it sends each function to its derivative. For example, in the manifold case, the derivative sends a Cr-manifold to a Cr−1-manifold (its tangent bundle) and a Cr-function to its total derivative. There is one requirement for this to be a functor, namely that the derivative of a composite must be the composite of the derivatives.  This is exactly the formula .\n\nThere are also chain rules in stochastic calculus. One of these, Itō's lemma, expresses the composite of an Itō process (or more generally a semimartingale) dXt with a twice-differentiable function f.  In Itō's lemma, the derivative of the composite function depends not only on dXt and the derivative of f but also on the second derivative of f. The dependence on the second derivative is a consequence of the non-zero quadratic variation of the stochastic process, which broadly speaking means that the process can move up and down in a very rough way. This variant of the chain rule is not an example of a functor because the two functions being composed are of different types.",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Chain rule" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=6113" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "In calculus, the chain rule is a formula for computing the derivative of the composition of two or more functions. That is, if f and g are functions, then the chain rule expresses the derivative of their composition  (the function which maps x to f(g(x)) ) in terms of the derivatives of f and g and the product of functions as follows:\n\n(f\\circ g)'=(f'\\circ g)\\cdot g'.\n\nThis can be written more explicitly in terms of the variable. Let , or equivalently,  for all x. Then one can also write\nF'(x) = f'(g(x)) g'(x).\n\nThe chain rule may be written in Leibniz's notation in the following way. If a variable z depends on the variable y, which itself depends on the variable x, so that y and z are therefore dependent variables, then z, via the intermediate variable of y, depends on x as well.  The chain rule then states,\n\n\\frac{dz}{dx} = \\frac{dz}{dy} \\cdot \\frac{dy}{dx}. \n\nThe two versions of the chain rule are related; if zf(y) and y\ng(x), then\n\n\\frac{dz}{dx}\\frac{dz}{dy}\\cdot\\frac{dy}{dx} \n f'(y)g'(x) = f'(g(x))g'(x).\n\nIn integration, the counterpart to the chain rule is the substitution rule.\n\nHistory \n\nThe chain rule seems to have first been used by Leibniz. He used it to calculate the derivative of \\sqrt{a + bz + cz^2} as the composite of the square root function and the function a + bz + cz^2.  He first mentioned it in a 1676 memoir (with a sign error in the calculation). The common notation of chain rule is due to Leibniz. L'Hôpital uses the chain rule implicitly in his Analyse des infiniment petits. The chain rule does not appear in any of Leonhard Euler's analysis books, even though they were written over a hundred years after Leibniz's discovery.\n\nOne dimension \n\nFirst example \n\nSuppose that a skydiver jumps from an aircraft.  Assume that t seconds after his jump, his height above sea level in meters is given by .  One model for the atmospheric pressure at a height h is .  These two equations can be differentiated and combined in various ways to produce the following data:\n*  is the velocity of the skydiver at time t.\n*  is the rate of change in atmospheric pressure with respect to height at the height h and is proportional to the buoyant force on the skydiver at h meters above sea level.  (The true buoyant force depends on the volume of the skydiver.)\n*  is the atmospheric pressure the skydiver experiences t seconds after his jump.\n*  is the rate of change in atmospheric pressure with respect to time at t seconds after the skydiver's jump and is proportional to the buoyant force on the skydiver at t seconds after his jump.\nThe chain rule gives a method for computing  in terms of  and .  While it is always possible to directly apply the definition of the derivative to compute the derivative of a composite function, this is usually very difficult.  The utility of the chain rule is that it turns a complicated derivative into several easy derivatives.\n\nThe chain rule states that, under appropriate conditions,\n(f \\circ g)'(t) = f'(g(t))\\cdot g'(t).\nIn this example, this equals\n(f \\circ g)'(t) = \\big(\\mathord{-}10.1325e^{-0.0001(4000 - 4.9t^2)}\\big)\\cdot\\big(\\mathord{-}9.8t\\big).\n\nIn the statement of the chain rule, f and g play slightly different roles because f′ is evaluated at g(t) whereas g′ is evaluated at t.  This is necessary to make the units work out correctly.  For example, suppose that we want to compute the rate of change in atmospheric pressure ten seconds after the skydiver jumps.  This is  and has units of pascals per second.  The factor g′(10) in the chain rule is the velocity of the skydiver ten seconds after his jump, and it is expressed in meters per second.  f′(g(10)) is the change in pressure with respect to height at the height g(10) and is expressed in pascals per meter.  The product of f′(g(10)) and g′(10) therefore has the correct units of pascals per second.  It is not possible to evaluate f anywhere else.  For instance, because the 10 in the problem represents ten seconds, the expression f′(10) represents the change in pressure at a height of ten seconds, which is nonsense.  Similarly, because  meters per second, the expression f′(g′(10)) represents the change in pressure at a height of −98 meters per second, which is also nonsense.  However, g(10) is 3020 meters above sea level, the height of the skydiver ten seconds after his jump.  This has the correct units for an input to f.\n\nStatement \n\nThe simplest form of the chain rule is for real-valued functions of one real variable.  It says that if g is a function that is differentiable at a point c (i.e. the derivative g′(c) exists) and f is a function that is differentiable at g(c), then the composite function  is differentiable at c, and the derivative is\n\n (f\\circ g)'(c) = f'(g(c))\\cdot g'(c). \n\nThe rule is sometimes abbreviated as\n\n(f\\circ g)' = (f'\\circ g) \\cdot g'.\n\nIf  and , then this abbreviated form is written in Leibniz notation as:\n\n\\frac{dy}{dx} = \\frac{dy}{du} \\cdot \\frac{du}{dx}.\n\nThe points where the derivatives are evaluated may also be stated explicitly:\n\n\\left.\\frac{dy}{dx}\\right|_{xc} \n \\left.\\frac{dy}{du}\\right|_{u g(c)} \\cdot \\left.\\frac{du}{dx}\\right|_{x\nc}.\n\nFurther examples \n\nAbsence of formulas \n\nIt may be possible to apply the chain rule even when there are no formulas for the functions which are being differentiated.  This can happen when the derivatives are measured directly.  Suppose that a car is driving up a tall mountain.  The car's speedometer measures its speed directly.  If the grade is known, then the rate of ascent can be calculated using trigonometry.  Suppose that the car is ascending at .  Standard models for the Earth's atmosphere imply that the temperature drops about  per kilometer ascended (called the lapse rate).  To find the temperature drop per hour, we apply the chain rule.  Let the function  be the altitude of the car at time , and let the function  be the temperature  kilometers above sea level.   and  are not known exactly: For example, the altitude where the car starts is not known and the temperature on the mountain is not known.  However, their derivatives are known:  is , and  is .  The chain rule says that the derivative of the composite function is the product of the derivative of  and the derivative of .  This is .\n\nOne of the reasons why this computation is possible is because  is a constant function.  This is because the above model is very simple.  A more accurate description of how the temperature near the car varies over time would require an accurate model of how the temperature varies at different altitudes.  This model may not have a constant derivative.  To compute the temperature change in such a model, it would be necessary to know  and not just , because without knowing  it is not possible to know where to evaluate .\n\nComposites of more than two functions \n\nThe chain rule can be applied to composites of more than two functions.  To take the derivative of a composite of more than two functions, notice that the composite of f, g, and h (in that order) is the composite of f with .  The chain rule says that to compute the derivative of , it is sufficient to compute the derivative of f and the derivative of .  The derivative of f can be calculated directly, and the derivative of  can be calculated by applying the chain rule again.\n\nFor concreteness, consider the function\ny = e^{\\sin {x^2}}.\nThis can be decomposed as the composite of three functions:\n\\begin{align}\ny &f(u) \n e^u, \\\\\nu &g(v) \n \\sin v, \\\\\nv &h(x) \n x^2.\n\\end{align}\nTheir derivatives are:\n\\begin{align}\n\\frac{dy}{du} &f'(u) \n e^u, \\\\\n\\frac{du}{dv} &g'(v) \n \\cos v, \\\\\n\\frac{dv}{dx} &h'(x) \n 2x.\n\\end{align}\nThe chain rule says that the derivative of their composite at the point  is:\n(f \\circ g \\circ h)'(a) f'((g \\circ h)(a))\\cdot (g \\circ h)'(a) \n f'((g \\circ h)(a)) \\cdot g'(h(a)) \\cdot h'(a) = (f' \\circ g \\circ h)(a) \\cdot (g' \\circ h)(a) \\cdot h'(a).\nIn Leibniz notation, this is:\n\\frac{dy}{dx} \\left.\\frac{dy}{du}\\right|_{u\ng(h(a))}\\cdot\\left.\\frac{du}{dv}\\right|_{vh(a)}\\cdot\\left.\\frac{dv}{dx}\\right|_{x\na},\nor for short,\n\\frac{dy}{dx} = \\frac{dy}{du}\\cdot\\frac{du}{dv}\\cdot\\frac{dv}{dx}.\nThe derivative function is therefore:\n\\frac{dy}{dx} = e^{\\sin {x^2}}\\cdot\\cos{x^2}\\cdot 2x.\n\nAnother way of computing this derivative is to view the composite function  as the composite of  and h.  Applying the chain rule to this situation gives:\n(f \\circ g \\circ h)'(a) (f \\circ g)'(h(a))\\cdot h'(a) \n f'(g(h(a)))\\cdot g'(h(a))\\cdot h'(a).\nThis is the same as what was computed above.  This should be expected because .\n\nSometimes it is necessary to differentiate an arbitrarily long composition of the form f_1 \\circ f_2 \\circ \\dotso \\circ f_{n-1} \\circ f_n. In this case, define\nf_{a..b} = f_{a} \\circ f_{a+1} \\circ \\dotso \\circ f_{b-1} \\circ f_{b}\nwhere f_{a..a} f_a and f_{a..b}(x) \n x when b . Then the chain rule takes the form\nDf_{1..n} (Df_1 \\circ f_{2..n}) (Df_2 \\circ f_{3..n}) \\dotso (Df_{n-1} \\circ f_{n..n}) Df_n \n \\prod_{k=1}^{n} \\left[Df_k \\circ f_{(k+1)..n}\\right]\nor, in the Lagrange notation,\nf_{1..n}'(x) f_1' \\left( f_{2..n}(x) \\right) \\; f_2' \\left( f_{3..n}(x) \\right) \\; \\dotso \\; f_{n-1}' \\left(f_{n..n}(x)\\right) \\; f_n'(x) \n \\prod_{k=1}^{n} f_k' \\left(f_{(k+1..n)}(x) \\right)\n\nQuotient rule \n\nThe chain rule can be used to derive some well-known differentiation rules.  For example, the quotient rule is a consequence of the chain rule and the product rule.  To see this, write the function f(x)/g(x) as the product .  First apply the product rule:\n\\begin{align}\n\\frac{d}{dx}\\left(\\frac{f(x)}{g(x)}\\right)\n&= \\frac{d}{dx}\\left(f(x)\\cdot\\frac{1}{g(x)}\\right) \\\\\n&= f'(x)\\cdot\\frac{1}{g(x)} + f(x)\\cdot\\frac{d}{dx}\\left(\\frac{1}{g(x)}\\right).\n\\end{align}\nTo compute the derivative of 1/g(x), notice that it is the composite of g with the reciprocal function, that is, the function that sends x to 1/x.  The derivative of the reciprocal function is −1/x2.  By applying the chain rule, the last expression becomes:\nf'(x)\\cdot\\frac{1}{g(x)} + f(x)\\cdot\\left(-\\frac{1}{g(x)^2}\\cdot g'(x)\\right)\n= \\frac{f'(x) g(x) - f(x) g'(x)}{g(x)^2},\nwhich is the usual formula for the quotient rule.\n\nDerivatives of inverse functions \n\nSuppose that  has an inverse function.  Call its inverse function f so that we have .  There is a formula for the derivative of f in terms of the derivative of g.  To see this, note that f and g satisfy the formula\nf(g(x)) = x.\nBecause the functions f(g(x)) and x are equal, their derivatives must be equal.  The derivative of x is the constant function with value 1, and the derivative of f(g(x)) is determined by the chain rule.  Therefore, we have:\nf'(g(x)) g'(x) = 1.\nTo express f′ as a function of an independent variable y, we substitute f(y) for x wherever it appears.  Then we can solve for f′.\n\\begin{align}\nf'(g(f(y))) g'(f(y)) &= 1 \\\\\nf'(y) g'(f(y)) &= 1 \\\\\nf'(y) = \\frac{1}{g'(f(y))}.\n\\end{align}\n\nFor example, consider the function .  It has an inverse .  Because , the above formula says that\n\\frac{d}{dy}\\ln y \\frac{1}{e^{\\ln y}} \n \\frac{1}{y}.\n\nThis formula is true whenever g is differentiable and its inverse f is also differentiable.  This formula can fail when one of these conditions is not true.  For example, consider .  Its inverse is , which is not differentiable at zero.  If we attempt to use the above formula to compute the derivative of f at zero, then we must evaluate 1/g′(f(0)).   and , so we must evaluate 1/0, which is undefined.  Therefore, the formula fails in this case.  This is not surprising because f is not differentiable at zero.\n\nHigher derivatives \n\nFaà di Bruno's formula generalizes the chain rule to higher derivatives.  Assuming that  and , then the first few derivatives are:\n\n\\begin{align}\n\\frac{dy}{dx} & = \\frac{dy}{du} \\frac{du}{dx} \\\\[4pt]\n\\frac{d^2 y }{d x^2} & = \\frac{d^2 y}{d u^2} \\left(\\frac{du}{dx}\\right)^2\n    + \\frac{dy}{du} \\frac{d^2 u}{dx^2} \\\\[4pt]\n\\frac{d^3 y }{d x^3} & = \\frac{d^3 y}{d u^3} \\left(\\frac{du}{dx}\\right)^3\n    + 3 \\, \\frac{d^2 y}{d u^2} \\frac{du}{dx} \\frac{d^2 u}{d x^2}\n    + \\frac{dy}{du} \\frac{d^3 u}{d x^3} \\\\[4pt]\n\\frac{d^4 y}{d x^4} & =\\frac{d^4 y}{du^4} \\left(\\frac{du}{dx}\\right)^4\n    + 6 \\, \\frac{d^3 y}{d u^3} \\left(\\frac{du}{dx}\\right)^2 \\frac{d^2 u}{d x^2}\n    + \\frac{d^2 y}{d u^2} \\left( 4 \\, \\frac{du}{dx} \\frac{d^3 u}{dx^3}\n    + 3 \\, \\left(\\frac{d^2 u}{dx^2}\\right)^2\\right)\n    + \\frac{dy}{du} \\frac{d^4 u}{dx^4}.\n\\end{align}\n\nProofs \n\nFirst proof \n\nOne proof of the chain rule begins with the definition of the derivative:\n(f \\circ g)'(a) = \\lim_{x \\to a} \\frac{f(g(x)) - f(g(a))}{x - a}.\nAssume for the moment that g(x) does not equal g(a) for any x near a.  Then the previous expression is equal to the product of two factors:\n\\lim_{x \\to a} \\frac{f(g(x)) - f(g(a))}{g(x) - g(a)} \\cdot \\frac{g(x) - g(a)}{x - a}.\nWhen g oscillates near a, then it might happen that no matter how close one gets to a, there is always an even closer x such that g(x) equals g(a).  For example, this happens for  near the point .  Whenever this happens, the above expression is undefined because it involves division by zero.  To work around this, introduce a function Q as follows:\nQ(y) = \\begin{cases}\n\\frac{f(y) - f(g(a))}{y - g(a)}, & y \\neq g(a), \\\\\nf'(g(a)), & y = g(a).\n\\end{cases}\nWe will show that the difference quotient for  is always equal to:\nQ(g(x)) \\cdot \\frac{g(x) - g(a)}{x - a}.\nWhenever g(x) is not equal to g(a), this is clear because the factors of  cancel.  When g(x) equals g(a), then the difference quotient for  is zero because f(g(x)) equals f(g(a)), and the above product is zero because it equals f′(g(a)) times zero.  So the above product is always equal to the difference quotient, and to show that the derivative of  at a exists and to determine its value, we need only show that the limit as x goes to a of the above product exists and determine its value.\n\nTo do this, recall that the limit of a product exists if the limits of its factors exist.  When this happens, the limit of the product of these two factors will equal the product of the limits of the factors.  The two factors are Q(g(x)) and .  The latter is the difference quotient for g at a, and because g is differentiable at a by assumption, its limit as x tends to a exists and equals g′(a).\n\nIt remains to study Q(g(x)).  Q is defined wherever f is.  Furthermore, because f is differentiable at g(a) by assumption, Q is continuous at g(a).  g is continuous at a because it is differentiable at a, and therefore  is continuous at a.  So its limit as x goes to a exists and equals Q(g(a)), which is f′(g(a)).\n\nThis shows that the limits of both factors exist and that they equal f′(g(a)) and g′(a), respectively.  Therefore, the derivative of  at a exists and equals f′(g(a))g′(a).\n\nSecond proof \n\nAnother way of proving the chain rule is to measure the error in the linear approximation determined by the derivative.  This proof has the advantage that it generalizes to several variables.  It relies on the following equivalent definition of differentiability at a point: A function g is differentiable at a if there exists a real number g′(a) and a function ε(h) that tends to zero as h tends to zero, and furthermore\ng(a + h) - g(a) = g'(a) h + \\varepsilon(h) h.\nHere the left-hand side represents the true difference between the value of g at a and at , whereas the right-hand side represents the approximation determined by the derivative plus an error term.\n\nIn the situation of the chain rule, such a function ε exists because g is assumed to be differentiable at a.  Again by assumption, a similar function also exists for f at g(a).  Calling this function η, we have\nf(g(a) + k) - f(g(a)) = f'(g(a)) k + \\eta(k) k.\nThe above definition imposes no constraints on η(0), even though it is assumed that η(k) tends to zero as k tends to zero.  If we set , then η is continuous at 0.\n\nProving the theorem requires studying the difference  as h tends to zero.  The first step is to substitute for  using the definition of differentiability of g at a:\nf(g(a + h)) - f(g(a)) = f(g(a) + g'(a) h + \\varepsilon(h) h) - f(g(a)).\nThe next step is to use the definition of differentiability of f at g(a).  This requires a term of the form  for some k.  In the above equation, the correct k varies with h.  Set  and the right hand side becomes .  Applying the definition of the derivative gives:\nf(g(a) + k_h) - f(g(a)) = f'(g(a)) k_h + \\eta(k_h) k_h.\nTo study the behavior of this expression as h tends to zero, expand kh. After regrouping the terms, the right-hand side becomes:\nf'(g(a)) g'(a)h + [f'(g(a)) \\varepsilon(h) + \\eta(k_h) g'(a) + \\eta(k_h) \\varepsilon(h)] h.\nBecause ε(h) and η(kh) tend to zero as h tends to zero, the first two bracketed terms tend to zero as h tends to zero.  Applying the same theorem on products of limits as in the first proof, the third bracketed term also tends zero.  Because the above expression is equal to the difference , by the definition of the derivative  is differentiable at a and its derivative is \n\nThe role of Q in the first proof is played by η in this proof.  They are related by the equation:\nQ(y) = f'(g(a)) + \\eta(y - g(a)). \nThe need to define Q at g(a) is analogous to the need to define η at zero.\n\nThird proof \n\nCarathéodory's alternative definition of the differentiability of a function can be used to give an elegant proof of the chain rule.\n\nUnder this definition, a function  is differentiable at a point  if and only if there is a function , continuous at  and such that . There is at most one such function, and if  is differentiable at  then .\n\nGiven the assumptions of the chain rule and the fact that differentiable functions and compositions of continuous functions are continuous, we have that there exist functions , continuous at  and , continuous at  and such that,\nf(g(x))-f(g(a))=q(g(x))(g(x)-g(a))\nand\ng(x)-g(a)=r(x)(x-a).\nTherefore,\nf(g(x))-f(g(a))=q(g(x))r(x)(x-a),\nbut the function given by  is continuous at , and we get, for this \n(f(g(a)))'q(g(a))r(a)\nf'(g(a))g'(a).\nA similar approach works for continuously differentiable (vector-)functions of many variables. This ideology of factoring also allows a unified approach to stronger forms of differentiability, when the derivative is required to be Lipschitz, Holder, etc. Differentiation itself can be viewed as the polynomial remainder theorem (the little Bezout, or factor theorem), generalized to an appropriate class of functions. \n\nProof via infinitesimals \n\nIf yf(x) and x\ng(t) then choosing infinitesimal \\Delta t\\not0 we compute the corresponding \\Delta x\ng(t+\\Delta t)-g(t) and then the corresponding \\Delta y=f(x+\\Delta x)-f(x), so that\n\\frac{\\Delta y}{\\Delta t}=\\frac{\\Delta y}{\\Delta x} \\frac{\\Delta x}{\\Delta t}\nand applying the standard part we obtain\n\\frac{d y}{d t}=\\frac{d y}{d x} \\frac{dx}{dt}\nwhich is the chain rule.\n\nHigher dimensions \n\nThe simplest generalization of the chain rule to higher dimensions uses the total derivative. The total derivative is a linear transformation that captures how the function changes in all directions.  Fix differentiable functions  and  and a point a in Rn.  Let Dag denote the total derivative of g at a and Dg(a)f denote the total derivative of f at g(a).  These two derivatives are linear transformations  and , respectively, so they can be composed.  The chain rule for total derivatives says that their composite is the total derivative of  at a:\nD_{\\mathbf{a}}(f \\circ g) = D_{g(\\mathbf{a})}f \\circ D_{\\mathbf{a}}g,\nor for short,\nD(f \\circ g) = Df \\circ Dg.\nThe higher-dimensional chain rule can be proved using a technique similar to the second proof given above.\n\nBecause the total derivative is a linear transformation, the functions appearing in the formula can be rewritten as matrices.  The matrix corresponding to a total derivative is called a Jacobian matrix, and the composite of two derivatives corresponds to the product of their Jacobian matrices.  From this perspective the chain rule therefore says:\nJ_{f \\circ g}(\\mathbf{a}) = J_{f}(g(\\mathbf{a})) J_{g}(\\mathbf{a}),\nor for short,\nJ_{f \\circ g} = (J_f \\circ g)J_g.\n\nThat is, the Jacobian of a composite function is the product of the Jacobians of the composed functions (evaluated at the appropriate points).\n\nThe higher-dimensional chain rule is a generalization of the one-dimensional chain rule.  If k, m, and n are 1, so that  and , then the Jacobian matrices of f and g are .  Specifically, they are:\n\\begin{align}\nJ_g(a) &= \\begin{pmatrix} g'(a) \\end{pmatrix}, \\\\\nJ_{f}(g(a)) &= \\begin{pmatrix} f'(g(a)) \\end{pmatrix}.\n\\end{align}\nThe Jacobian of f ∘ g is the product of these  matrices, so it is , as expected from the one-dimensional chain rule.  In the language of linear transformations, Da(g) is the function which scales a vector by a factor of g′(a) and Dg(a)(f) is the function which scales a vector by a factor of f′(g(a)).  The chain rule says that the composite of these two linear transformations is the linear transformation , and therefore it is the function that scales a vector by f′(g(a))⋅g′(a).\n\nAnother way of writing the chain rule is used when f and g are expressed in terms of their components as  and .  In this case, the above rule for Jacobian matrices is usually written as:\n\\frac{\\partial(y_1, \\ldots, y_k)}{\\partial(x_1, \\ldots, x_n)} = \\frac{\\partial(y_1, \\ldots, y_k)}{\\partial(u_1, \\ldots, u_m)} \\frac{\\partial(u_1, \\ldots, u_m)}{\\partial(x_1, \\ldots, x_n)}.\n\nThe chain rule for total derivatives implies a chain rule for partial derivatives.  Recall that when the total derivative exists, the partial derivative in the ith coordinate direction is found by multiplying the Jacobian matrix by the ith basis vector.  By doing this to the formula above, we find:\n\\frac{\\partial(y_1, \\ldots, y_k)}{\\partial x_i} = \\frac{\\partial(y_1, \\ldots, y_k)}{\\partial(u_1, \\ldots, u_m)} \\frac{\\partial(u_1, \\ldots, u_m)}{\\partial x_i}.\nSince the entries of the Jacobian matrix are partial derivatives, we may simplify the above formula to get:\n\\frac{\\partial(y_1, \\ldots, y_k)}{\\partial x_i} \\sum_{\\ell \n 1}^m \\frac{\\partial(y_1, \\ldots, y_k)}{\\partial u_\\ell} \\frac{\\partial u_\\ell}{\\partial x_i}.\nMore conceptually, this rule expresses the fact that a change in the xi direction may change all of g1 through gm, and any of these changes may affect f.\n\nIn the special case where , so that f is a real-valued function, then this formula simplifies even further:\n\\frac{\\partial y}{\\partial x_i} \\sum_{\\ell \n 1}^m \\frac{\\partial y}{\\partial u_\\ell} \\frac{\\partial u_\\ell}{\\partial x_i}.\nThis can be rewritten as a dot product.  Recalling that , the partial derivative  is also a vector, and the chain rule says that:\n\\frac{\\partial y}{\\partial x_i} = \\nabla y \\cdot \\frac{\\partial \\mathbf{u}}{\\partial x_i}.\n\nExample \n\nGiven  where  and , determine the value of  and  using the chain rule.\n\\frac{\\partial u}{\\partial r}\\frac{\\partial u}{\\partial x} \\frac{\\partial x}{\\partial r}+\\frac{\\partial u}{\\partial y} \\frac{\\partial y}{\\partial r} \n (2x)(\\sin(t)) + (2)(0) = 2r \\sin^2(t),\nand\n\\begin{align}\\frac{\\partial u}{\\partial t}\n&= \\frac{\\partial u}{\\partial x} \\frac{\\partial x}{\\partial t}+\\frac{\\partial u}{\\partial y} \\frac{\\partial y}{\\partial t} \\\\\n&= (2x)(r\\cos(t)) + (2)(2\\sin(t)\\cos(t)) \\\\\n&= (2r\\sin(t))(r\\cos(t)) + 4\\sin(t)\\cos(t) \\\\\n&= 2(r^2 + 2) \\sin(t)\\cos(t) \\\\\n&= (r^2 + 2) \\sin(2t).\\end{align}\n\nHigher derivatives of multivariable functions \n\nFaà di Bruno's formula for higher-order derivatives of single-variable functions generalizes to the multivariable case.  If  is a function of  as above, then the second derivative of  is:\n\\frac{\\partial^2 y}{\\partial x_i \\partial x_j} = \\sum_k \\left(\\frac{\\partial y}{\\partial u_k}\\frac{\\partial^2 u_k}{\\partial x_i \\partial x_j}\\right) + \\sum_{k, \\ell} \\left(\\frac{\\partial^2 y}{\\partial u_k \\partial u_\\ell}\\frac{\\partial u_k}{\\partial x_i}\\frac{\\partial u_\\ell}{\\partial x_j}\\right).\n\nFurther generalizations \n\nAll extensions of calculus have a chain rule. In most of these, the formula remains the same, though the meaning of that formula may be vastly different.\n\nOne generalization is to manifolds. In this situation, the chain rule represents the fact that the derivative of  is the composite of the derivative of f and the derivative of g. This theorem is an immediate consequence of the higher dimensional chain rule given above, and it has exactly the same formula.\n\nThe chain rule is also valid for Fréchet derivatives in Banach spaces.  The same formula holds as before. This case and the previous one admit a simultaneous generalization to Banach manifolds.\n\nIn abstract algebra, the derivative is interpreted as a morphism of modules of Kähler differentials. A ring homomorphism of commutative rings  determines a morphism of Kähler differentials  which sends an element dr to d(f(r)), the exterior differential of f(r). The formula  holds in this context as well.\n\nThe common feature of these examples is that they are expressions of the idea that the derivative is part of a functor. A functor is an operation on spaces and functions between them. It associates to each space a new space and to each function between two spaces a new function between the corresponding new spaces. In each of the above cases, the functor sends each space to its tangent bundle and it sends each function to its derivative. For example, in the manifold case, the derivative sends a Cr-manifold to a Cr−1-manifold (its tangent bundle) and a Cr-function to its total derivative. There is one requirement for this to be a functor, namely that the derivative of a composite must be the composite of the derivatives.  This is exactly the formula .\n\nThere are also chain rules in stochastic calculus. One of these, Itō's lemma, expresses the composite of an Itō process (or more generally a semimartingale) dXt with a twice-differentiable function f.  In Itō's lemma, the derivative of the composite function depends not only on dXt and the derivative of f but also on the second derivative of f. The dependence on the second derivative is a consequence of the non-zero quadratic variation of the stochastic process, which broadly speaking means that the process can move up and down in a very rough way. This variant of the chain rule is not an example of a functor because the two functions being composed are of different types. Chain rule. http://en.wikipedia.org/?curid=6113."
  }
}
