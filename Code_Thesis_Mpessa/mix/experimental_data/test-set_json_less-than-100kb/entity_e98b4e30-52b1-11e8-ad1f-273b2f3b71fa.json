{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=8640",
  "eid" : "e98b4e30-52b1-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778471571,
  "textBody" : "Database normalization, or simply normalization, is the process of restructuring a relational database in accordance with a series of so-called normal forms in order to reduce data redundancy and improve data integrity. It was first proposed by Edgar F. Codd as an integral part of his relational model.\n\nNormalization entails organizing the columns (attributes) and tables (relations) of a database to ensure that their dependencies are properly enforced by database integrity constraints. It is accomplished by applying some formal rules either by a process of synthesis (creating a new database design) or decomposition (improving an existing database design).\n\nObjectives\n\nA basic objective of the first normal form defined by Codd in 1970 was to permit data to be queried and manipulated using a \"universal data sub-language\" grounded in first-order logic.\"The adoption of a relational model of data ... permits the development of a universal data sub-language based on an applied predicate calculus. A first-order predicate calculus suffices if the collection of relations is in first normal form. Such a language would provide a yardstick of linguistic power for all other proposed data languages, and would itself be a strong candidate for embedding (with appropriate syntactic modification) in a variety of host languages (programming, command- or problem-oriented).\"  Codd, [http://www.acm.org/classics/nov95/toc.html \"A Relational Model of Data for Large Shared Data Banks\"], p. 381 (SQL is an example of such a data sub-language, albeit one that Codd regarded as seriously flawed.)Codd, E.F. Chapter 23, \"Serious Flaws in SQL\", in The Relational Model for Database Management: Version 2. Addison-Wesley (1990), pp. 371–389\n\nThe objectives of normalization beyond 1NF (first normal form) were stated as follows by Codd:\n\nWhen an attempt is made to modify (update, insert into, or delete from) a relation, the following undesirable side-effects may arise in relations that have not been sufficiently normalized:\n\n* Update anomaly. The same information can be expressed on multiple rows; therefore updates to the relation may result in logical inconsistencies. For example, each record in an \"Employees' Skills\" relation might contain an Employee ID, Employee Address, and Skill; thus a change of address for a particular employee may need to be applied to multiple records (one for each skill). If the update is only partially successful – the employee's address is updated on some records but not others – then the relation is left in an inconsistent state. Specifically, the relation provides conflicting answers to the question of what this particular employee's address is. This phenomenon is known as an update anomaly.\n* Insertion anomaly. There are circumstances in which certain facts cannot be recorded at all. For example, each record in a \"Faculty and Their Courses\" relation might contain a Faculty ID, Faculty Name, Faculty Hire Date, and Course Code. Therefore we can record the details of any faculty member who teaches at least one course, but we cannot record a newly hired faculty member who has not yet been assigned to teach any courses, except by setting the Course Code to null. This phenomenon is known as an insertion anomaly.\n* Deletion anomaly. Under certain circumstances, deletion of data representing certain facts necessitates deletion of data representing completely different facts. The \"Faculty and Their Courses\" relation described in the previous example suffers from this type of anomaly, for if a faculty member temporarily ceases to be assigned to any courses, we must delete the last of the records on which that faculty member appears, effectively also deleting the faculty member, unless we set the Course Code to null. This phenomenon is known as a deletion anomaly.\n\nMinimize redesign when extending the database structure\n\nWhen a fully normalized database structure is extended to allow it to accommodate new types of data, the pre-existing aspects of the database structure can remain largely or entirely unchanged. As a result, applications interacting with the database are minimally affected.\n\nNormalized relations, and the relationship between one normalized relation and another, mirror real-world concepts and their interrelationships.\n\nExample\n\nQuerying and manipulating the data within a data structure that is not normalized, such as the following non-1NF representation of customers, credit card transactions, involves more complexity than is really necessary:\n\nTo each customer corresponds a 'repeating group' of transactions. The automated evaluation of any query relating to customers' transactions, therefore, would broadly involve two stages:\n# Unpacking one or more customers' groups of transactions allowing the individual transactions in a group to be examined, and\n# Deriving a query result based on the results of the first stage\n\nFor example, in order to find out the monetary sum of all transactions that occurred in October 2003 for all customers, the system would have to know that it must first unpack the Transactions group of each customer, then sum the Amounts of all transactions thus obtained where the Date of the transaction falls in October 2003.\n\nOne of Codd's important insights was that structural complexity can be reduced, leading to much greater power and flexibility in the way queries could be formulated (by users and applications) and evaluated (by the DBMS). A more normalized equivalent of the structure above might look like this:\n\nIn the modified structure, the key is {Cust. ID} in the first relation, {Cust. ID, Tr ID} in the second relation.\n\nNow each row represents an individual credit card transaction, and the DBMS can obtain the answer of interest, simply by finding all rows with a Date falling in October, and summing their Amounts. The data structure places all of the values on an equal footing, exposing each to the DBMS directly, so each can potentially participate directly in queries; whereas in the previous situation some values were embedded in lower-level structures that had to be handled specially. Accordingly, the normalized design lends itself to general-purpose query processing, whereas the unnormalized design does not. The normalized version also allows the user to change the customer name in one place and guards against errors that arise if the customer name is misspelled on some records.\n\nNormal forms\n\nCodd introduced the concept of normalization and what is now known as the first normal form (1NF) in 1970. Codd went on to define the second normal form (2NF) and third normal form (3NF) in 1971,Codd, E.F. \"Further Normalization of the Data Base Relational Model\". (Presented at Courant Computer Science Symposia Series 6, \"Data Base Systems\", New York City, May 24–25, 1971.) IBM Research Report RJ909 (August 31, 1971). Republished in Randall J. Rustin (ed.), Data Base Systems: Courant Computer Science Symposia Series 6. Prentice-Hall, 1972. and Codd and Raymond F. Boyce defined the Boyce-Codd normal form (BCNF) in 1974.Codd, E. F. \"Recent Investigations into Relational Data Base Systems\". IBM Research Report RJ1385 (April 23, 1974). Republished in Proc. 1974 Congress (Stockholm, Sweden, 1974), N.Y.: North-Holland (1974).\n\nInformally, a relational database relation is often described as \"normalized\" if it meets third normal form.C.J. Date. An Introduction to Database Systems. Addison-Wesley (1999), p. 290 Most 3NF relations are free of insertion, update, and deletion anomalies.\n\n* Unnormalized form (UNF)\n* First normal form (1NF)\n* Second normal form (2NF)\n* Third normal form (3NF)\n* Elementary key normal form (EKNF)\n* Boyce–Codd normal form (BCNF)\n* Fourth normal form (4NF)\n* Essential tuple normal form (ETNF)\n* Fifth normal form (5NF)\n* Sixth normal form (6NF)\n* Domain/key normal form (DKNF)",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Database normalization" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=8640" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "Database normalization, or simply normalization, is the process of restructuring a relational database in accordance with a series of so-called normal forms in order to reduce data redundancy and improve data integrity. It was first proposed by Edgar F. Codd as an integral part of his relational model.\n\nNormalization entails organizing the columns (attributes) and tables (relations) of a database to ensure that their dependencies are properly enforced by database integrity constraints. It is accomplished by applying some formal rules either by a process of synthesis (creating a new database design) or decomposition (improving an existing database design).\n\nObjectives\n\nA basic objective of the first normal form defined by Codd in 1970 was to permit data to be queried and manipulated using a \"universal data sub-language\" grounded in first-order logic.\"The adoption of a relational model of data ... permits the development of a universal data sub-language based on an applied predicate calculus. A first-order predicate calculus suffices if the collection of relations is in first normal form. Such a language would provide a yardstick of linguistic power for all other proposed data languages, and would itself be a strong candidate for embedding (with appropriate syntactic modification) in a variety of host languages (programming, command- or problem-oriented).\"  Codd, [http://www.acm.org/classics/nov95/toc.html \"A Relational Model of Data for Large Shared Data Banks\"], p. 381 (SQL is an example of such a data sub-language, albeit one that Codd regarded as seriously flawed.)Codd, E.F. Chapter 23, \"Serious Flaws in SQL\", in The Relational Model for Database Management: Version 2. Addison-Wesley (1990), pp. 371–389\n\nThe objectives of normalization beyond 1NF (first normal form) were stated as follows by Codd:\n\nWhen an attempt is made to modify (update, insert into, or delete from) a relation, the following undesirable side-effects may arise in relations that have not been sufficiently normalized:\n\n* Update anomaly. The same information can be expressed on multiple rows; therefore updates to the relation may result in logical inconsistencies. For example, each record in an \"Employees' Skills\" relation might contain an Employee ID, Employee Address, and Skill; thus a change of address for a particular employee may need to be applied to multiple records (one for each skill). If the update is only partially successful – the employee's address is updated on some records but not others – then the relation is left in an inconsistent state. Specifically, the relation provides conflicting answers to the question of what this particular employee's address is. This phenomenon is known as an update anomaly.\n* Insertion anomaly. There are circumstances in which certain facts cannot be recorded at all. For example, each record in a \"Faculty and Their Courses\" relation might contain a Faculty ID, Faculty Name, Faculty Hire Date, and Course Code. Therefore we can record the details of any faculty member who teaches at least one course, but we cannot record a newly hired faculty member who has not yet been assigned to teach any courses, except by setting the Course Code to null. This phenomenon is known as an insertion anomaly.\n* Deletion anomaly. Under certain circumstances, deletion of data representing certain facts necessitates deletion of data representing completely different facts. The \"Faculty and Their Courses\" relation described in the previous example suffers from this type of anomaly, for if a faculty member temporarily ceases to be assigned to any courses, we must delete the last of the records on which that faculty member appears, effectively also deleting the faculty member, unless we set the Course Code to null. This phenomenon is known as a deletion anomaly.\n\nMinimize redesign when extending the database structure\n\nWhen a fully normalized database structure is extended to allow it to accommodate new types of data, the pre-existing aspects of the database structure can remain largely or entirely unchanged. As a result, applications interacting with the database are minimally affected.\n\nNormalized relations, and the relationship between one normalized relation and another, mirror real-world concepts and their interrelationships.\n\nExample\n\nQuerying and manipulating the data within a data structure that is not normalized, such as the following non-1NF representation of customers, credit card transactions, involves more complexity than is really necessary:\n\nTo each customer corresponds a 'repeating group' of transactions. The automated evaluation of any query relating to customers' transactions, therefore, would broadly involve two stages:\n# Unpacking one or more customers' groups of transactions allowing the individual transactions in a group to be examined, and\n# Deriving a query result based on the results of the first stage\n\nFor example, in order to find out the monetary sum of all transactions that occurred in October 2003 for all customers, the system would have to know that it must first unpack the Transactions group of each customer, then sum the Amounts of all transactions thus obtained where the Date of the transaction falls in October 2003.\n\nOne of Codd's important insights was that structural complexity can be reduced, leading to much greater power and flexibility in the way queries could be formulated (by users and applications) and evaluated (by the DBMS). A more normalized equivalent of the structure above might look like this:\n\nIn the modified structure, the key is {Cust. ID} in the first relation, {Cust. ID, Tr ID} in the second relation.\n\nNow each row represents an individual credit card transaction, and the DBMS can obtain the answer of interest, simply by finding all rows with a Date falling in October, and summing their Amounts. The data structure places all of the values on an equal footing, exposing each to the DBMS directly, so each can potentially participate directly in queries; whereas in the previous situation some values were embedded in lower-level structures that had to be handled specially. Accordingly, the normalized design lends itself to general-purpose query processing, whereas the unnormalized design does not. The normalized version also allows the user to change the customer name in one place and guards against errors that arise if the customer name is misspelled on some records.\n\nNormal forms\n\nCodd introduced the concept of normalization and what is now known as the first normal form (1NF) in 1970. Codd went on to define the second normal form (2NF) and third normal form (3NF) in 1971,Codd, E.F. \"Further Normalization of the Data Base Relational Model\". (Presented at Courant Computer Science Symposia Series 6, \"Data Base Systems\", New York City, May 24–25, 1971.) IBM Research Report RJ909 (August 31, 1971). Republished in Randall J. Rustin (ed.), Data Base Systems: Courant Computer Science Symposia Series 6. Prentice-Hall, 1972. and Codd and Raymond F. Boyce defined the Boyce-Codd normal form (BCNF) in 1974.Codd, E. F. \"Recent Investigations into Relational Data Base Systems\". IBM Research Report RJ1385 (April 23, 1974). Republished in Proc. 1974 Congress (Stockholm, Sweden, 1974), N.Y.: North-Holland (1974).\n\nInformally, a relational database relation is often described as \"normalized\" if it meets third normal form.C.J. Date. An Introduction to Database Systems. Addison-Wesley (1999), p. 290 Most 3NF relations are free of insertion, update, and deletion anomalies.\n\n* Unnormalized form (UNF)\n* First normal form (1NF)\n* Second normal form (2NF)\n* Third normal form (3NF)\n* Elementary key normal form (EKNF)\n* Boyce–Codd normal form (BCNF)\n* Fourth normal form (4NF)\n* Essential tuple normal form (ETNF)\n* Fifth normal form (5NF)\n* Sixth normal form (6NF)\n* Domain/key normal form (DKNF). Database normalization. http://en.wikipedia.org/?curid=8640."
  }
}
