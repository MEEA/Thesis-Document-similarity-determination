{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=2218",
  "eid" : "beefdd80-52b1-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778400088,
  "textBody" : "Additive synthesis is a sound synthesis technique that creates timbre by adding sine waves together.\n\nThe timbre of musical instruments can be considered in the light of Fourier theory to consist of multiple harmonic or inharmonic partials or overtones. Each partial is a sine wave of different frequency and amplitude that swells and decays over time due to modulation from an ADSR envelope or low frequency oscillator.\n\nAdditive synthesis most directly generates sound by adding the output of multiple sine wave generators. Alternative implementations may use pre-computed wavetables or the inverse Fast Fourier transform.\n\nExplanation \n\nThe sounds that are heard in everyday life are not characterized by a single frequency. Instead, they consist of a sum of pure sine frequencies, each one at a different amplitude. When humans hear these frequencies simultaneously, we can recognize the sound. This is true for both \"non-musical\" sounds (e.g. water splashing, leaves rustling, etc.) and for \"musical sounds\" (e.g. a piano note, a bird's tweet, etc.). This set of parameters (frequencies, their relative amplitudes, and how the relative amplitudes change over time) are encapsulated by the timbre of the sound. Fourier analysis is the technique that is used to determine these exact timbre parameters from an overall sound signal; conversely, the resulting set of frequencies and amplitudes is called the Fourier series of the original sound signal.\n\nIn the case of a musical note, the lowest frequency of its timbre is designated as the sound's fundamental frequency. For simplicity, we often say that the note is playing at that fundamental frequency (e.g. \"middle C is 261.6 Hz\"), even though the sound of that note consists of many other frequencies as well. The set of the remaining frequencies is called the overtones (or the harmonics) of the sound. In other words, the fundamental frequency alone is responsible for the pitch of the note, while the overtones define the timbre of the sound. The overtones of a piano playing middle C will be quite different from the overtones of a violin playing the same note; that's what allows us to differentiate the sounds of the two instruments. There are even subtle differences in timbre between different versions of the same instrument (for example, an upright piano vs. a grand piano).\n\nAdditive synthesis aims to exploit this property of sound in order to construct timbre from the ground up. By adding together pure frequencies (sine waves) of varying frequencies and amplitudes, we can precisely define the timbre of the sound that we want to create.\n\nDefinitions\n\nHarmonic additive synthesis is closely related to the concept of a Fourier series which is a way of expressing a periodic function as the sum of sinusoidal functions with frequencies equal to integer multiples of a common fundamental frequency.  These sinusoids are called harmonics, overtones, or generally, partials.  In general, a Fourier series contains an infinite number of sinusoidal components, with no upper limit to the frequency of the sinusoidal functions and includes a DC component (one with frequency of 0 Hz).  Frequencies outside of the human audible range can be omitted in additive synthesis.  As a result, only a finite number of sinusoidal terms with frequencies that lie within the audible range are modeled in additive synthesis.\n\nA waveform or function is said to be periodic if\n\n y(t) = y(t+P) \\ \n\nfor all  t \\, and for some period  P \\,.\n\nThe Fourier series of a periodic function is mathematically expressed as:\n\n \\begin{align}\n  y(t) &\\frac{a_0}{2} + \\sum_{k\n1}^{\\infty} \\left[ a_k \\cos(2 \\pi k f_0 t ) - b_k \\sin(2 \\pi k f_0 t ) \\right] \\\\\n       &\\frac{a_0}{2} + \\sum_{k\n1}^{\\infty} r_k \\cos\\left(2 \\pi k f_0 t + \\phi_k \\right) \\\\\n   \\end{align} \n\nwhere\n\n: f_0 = 1/P\\, is the fundamental frequency of the waveform and is equal to the reciprocal of the period,\n: a_k r_k \\cos(\\phi_k) \n 2 f_0 \\int_{0}^P y(t) \\cos(2 \\pi k f_0 t)\\, dt, \\quad k \\ge 0\\,\n: b_k r_k \\sin(\\phi_k) \n -2 f_0 \\int_{0}^P y(t) \\sin(2 \\pi k f_0 t)\\, dt, \\quad k \\ge 1\\,\n: r_k = \\sqrt{a_k^2 + b_k^2}\\, is the amplitude of the k\\,th harmonic,\n: \\phi_k = \\operatorname{atan2}(b_k, a_k)\\, is the phase offset of the k\\,th harmonic. atan2(Â ) is the four-quadrant arctangent function,\n\nBeing inaudible, the DC component, a_0/2\\,, and all components with frequencies higher than some finite limit, K f_0\\,, are omitted in the following expressions of additive synthesis.\n\nHarmonic form\n\nThe simplest harmonic additive synthesis can be mathematically expressed as:\n\nwhere y(t)\\, is the synthesis output, r_k\\,, k f_0\\,, and \\phi_k\\, are the amplitude, frequency, and the phase offset, respectively, of the k\\,th harmonic partial of a total of K\\, harmonic partials, and f_0\\, is the fundamental frequency of the waveform and the frequency of the musical note.\n\nTime-dependent amplitudes\n\nMore generally, the amplitude of each harmonic can be prescribed as a function of time, r_k(t)\\,, in which case the synthesis output is\n\nEach envelope r_k(t)\\, should vary slowly relative to the frequency spacing between adjacent sinusoids.  The bandwidth of r_k(t)\\, should be significantly less than f_0\\,.\n\nInharmonic form\n\nAdditive synthesis can also produce inharmonic sounds (which are aperiodic waveforms) in which the individual overtones need not have frequencies that are integer multiples of some common fundamental frequency.\n ([https://ccrma.stanford.edu/STANM/stanms/stanm43/stanm43.pdf online reprint])\n  While many conventional musical instruments have harmonic partials (e.g. an oboe), some have inharmonic partials (e.g. bells).  Inharmonic additive synthesis can be described as\n\ny(t) \\sum_{k\n1}^{K} r_k(t) \\cos\\left(2 \\pi f_k t + \\phi_k \\right),\n\nwhere f_k\\, is the constant frequency of k\\,th partial.\n\nTime-dependent frequencies\n\nIn the general case, the instantaneous frequency of a sinusoid is the derivative (with respect to time) of the argument of the sine or cosine function.  If this frequency is represented in hertz, rather than in angular frequency form, then this derivative is divided by 2 \\pi\\,.  This is the case whether the partial is harmonic or inharmonic and whether its frequency is constant or time-varying.\n\nIn the most general form, the frequency of each non-harmonic partial is a non-negative function of time, f_k(t)\\,, yielding\n\nBroader definitions\n\nAdditive synthesis more broadly may mean sound synthesis techniques that sum simple elements to create more complex timbres, even when the elements are not sine waves.\n\n For example, F. Richard Moore listed additive synthesis as one of the \"four basic categories\" of sound synthesis alongside subtractive synthesis, nonlinear synthesis, and physical modeling. In this broad sense, pipe organs, which also have pipes producing non-sinusoidal waveforms, can be considered as a variant form of additive synthesizers. Summation of principal components and Walsh functions have also been classified as additive synthesis.\n\nImplementation methods\n\nModern-day implementations of additive synthesis are mainly digital. (See section Discrete-time equations for the underlying discrete-time theory)\n\nOscillator bank synthesis\n\nAdditive synthesis can be implemented using a bank of sinusoidal oscillators, one for each partial.\n\nWavetable synthesis\n\nIn the case of harmonic, quasi-periodic musical tones, wavetable synthesis can be as general as time-varying additive synthesis, but requires less computation during synthesis.\n\n As a result, an efficient implementation of time-varying additive synthesis of harmonic tones can be accomplished by use of wavetable synthesis.\n\nGroup additive synthesis\n\nGroup additive synthesis\n \n\n is a method to group partials into harmonic groups (having different fundamental frequencies) and synthesize each group separately with wavetable synthesis before mixing the results.\n\nInverse FFT synthesis\n\nAn inverse Fast Fourier transform can be used to efficiently synthesize frequencies that evenly divide the transform period or \"frame\". By careful consideration of the DFT frequency-domain representation it is also possible to efficiently synthesize sinusoids of arbitrary frequencies using a series of overlapping frames and the inverse Fast Fourier transform.\n\nAdditive analysis/resynthesis\n\nIt is possible to analyze the frequency components of a recorded sound giving a \"sum of sinusoids\" representation. This representation can be re-synthesized using additive synthesis. One method of decomposing a sound into time varying sinusoidal partials is short-time Fourier transform (STFT)-based McAulay-Quatieri Analysis.\n\nBy modifying the sum of sinusoids representation, timbral alterations can be made prior to resynthesis. For example, a harmonic sound could be restructured to sound inharmonic, and vice versa. Sound hybridisation or \"morphing\" has been implemented by additive resynthesis.\n\nAdditive analysis/resynthesis has been employed in a number of techniques including Sinusoidal Modelling,\n Spectral Modelling Synthesis (SMS), and the Reassigned Bandwidth-Enhanced Additive Sound Model.\n Software that implements additive analysis/resynthesis includes: SPEAR,[http://www.klingbeil.com/spear/ SPEAR Sinusoidal Partial Editing Analysis and Resynthesis for Mac OS X, MacOS 9 and Windows] LEMUR, LORIS,[http://www.hakenaudio.com/Loris/ Loris Software for Sound Modeling, Morphing, and Manipulation] SMSTools,[http://mtg.upf.edu/technologies/sms SMSTools application for Windows] ARSS.[http://arss.sourceforge.net/ ARSS: The Analysis & Resynthesis Sound Spectrograph]\n\nProducts\n\nNew England Digital Synclavier had a resynthesis feature where samples could be analyzed and converted into âtimbre framesâ which were part of its additive synthesis engine. Technos acxel, launched in 1987, utilized the additive analysis/resynthesis model, in an FFT implementation.\n\nAlso a vocal synthesizer, Vocaloid have been implemented on the basis of additive analysis/resynthesis: its spectral voice model called Excitation plus Resonances (EpR) model\n ([http://mtg.upf.edu/files/publications/icmc2001-celma.pdf PDF])\n ([http://www.tdx.cat/bitstream/handle/10803/7542/talm.pdf?sequence=1 PDF]).\nSee \"Excitation plus resonances voice model\" (p. 51)\n is extended based on Spectral Modeling Synthesis (SMS),\nand its diphone concatenative synthesis is processed using\nspectral peak processing (SPP), \"Spectral peak processing\" technique similar to modified phase-locked vocoder, \"Phase locked vocoder\" (an improved phase vocoder for formant processing).\n  Using these techniques, spectral components (formants) consisting of purely harmonic partials can be appropriately transformed into desired form for sound modeling, and sequence of short samples (diphones or phonemes) constituting desired phrase, can be smoothly connected by interpolating matched partials and formant peaks, respectively, in the inserted transition region between different samples. (See also Dynamic timbres)\n\nApplications\n\nMusical instruments\n\nAdditive synthesis is used in electronic musical instruments. It is the principal sound generation technique used by Eminent organs.\n\nSpeech synthesis\n\nIn linguistics research, harmonic additive synthesis was used in 1950s to play back modified and synthetic speech spectrograms.\n\nLater, in early 1980s, listening tests were carried out on synthetic speech stripped of acoustic cues to assess their significance. Time-varying formant frequencies and amplitudes derived by linear predictive coding were synthesized additively as pure tone whistles. This method is called sinewave synthesis.\n\n Also the composite sinusoidal modeling (CSM)\n\n used on a singing speech synthesis feature on Yamaha CX5M (1984), is known to use a similar approach which was independently developed during 1966â1979.\n\n These methods are characterized by extraction and recomposition of a set of significant spectral peaks corresponding to the several resonance modes occurred in the oral cavity and nasal cavity, in a viewpoint of acoustics. This principle was also utilized on a physical modeling synthesis method, called modal synthesis.\n\n Â (See also [http://www2.ph.ed.ac.uk/~sbilbao/nsstop.html companion page])\n\nHistory\n\nHarmonic analysis was discovered by Joseph Fourier,\n who published an extensive treatise of his research in the context of heat transfer in 1822.\n The theory found an early application in prediction of tides. Around 1876, Lord Kelvin constructed a mechanical tide predictor. It consisted of a harmonic analyzer and a harmonic synthesizer, as they were called already in the 19th century.\n\n The analysis of tide measurements was done using James Thomson's integrating machine. The resulting Fourier coefficients were input into the synthesizer, which then used a system of cords and pulleys to generate and sum harmonic sinusoidal partials for prediction of future tides. In 1910, a similar machine was built for the analysis of periodic waveforms of sound. The synthesizer drew a graph of the combination waveform, which was used chiefly for visual validation of the analysis.\n\nGeorg Ohm applied Fourier's theory to sound in 1843. The line of work was greatly advanced by Hermann von Helmholtz, who published his eight years worth of research in 1863.\n Helmholtz believed that the psychological perception of tone color is subject to learning, while hearing in the sensory sense is purely physiological.\n He supported the idea that perception of sound derives from signals from nerve cells of the basilar membrane and that the elastic appendages of these cells are sympathetically vibrated by pure sinusoidal tones of appropriate frequencies.\n Helmholtz agreed with the finding of Ernst Chladni from 1787 that certain sound sources have inharmonic vibration modes.\n\nIn Helmholtz's time, electronic amplification was unavailable. For synthesis of tones with harmonic partials, Helmholtz built an electrically excited array of tuning forks and acoustic resonance chambers that allowed adjustment of the amplitudes of the partials.  Built at least as early as in 1862, these were in turn refined by Rudolph Koenig, who demonstrated his own setup in 1872.\n For harmonic synthesis, Koenig also built a large apparatus based on his wave siren. It was pneumatic and utilized cut-out tonewheels, and was criticized for low purity of its partial tones. Also tibia pipes of pipe organs have nearly sinusoidal waveforms and can be combined in the manner of additive synthesis.\n\nIn 1938, with significant new supporting evidence,\n it was reported on the pages of Popular Science Monthly that the human vocal cords function like a fire siren to produce a harmonic-rich tone, which is then filtered by the vocal tract to produce different vowel tones.\n By the time, the additive Hammond organ was already on market. Most early electronic organ makers thought it too expensive to manufacture the plurality of oscillators required by additive organs, and began instead to build subtractive ones. In a 1940 Institute of Radio Engineers meeting, the head field engineer of Hammond elaborated on the company's new Novachord as having a âsubtractive systemâ in contrast to the original Hammond organ in which âthe final tones were built up by combining sound wavesâ. Alan Douglas used the qualifiers additive and subtractive to describe different types of electronic organs in a 1948 paper presented to the Royal Musical Association.  The contemporary wording additive synthesis and subtractive synthesis can be found in his 1957 book The electrical production of music, in which he categorically lists three methods of forming of musical tone-colours, in sections titled Additive synthesis, Subtractive synthesis, and Other forms of combinations.\n\nA typical modern additive synthesizer produces its output as an electrical, analog signal, or as digital audio, such as in the case of software synthesizers, which became popular around year 2000.\n\nTimeline \n\nThe following is a timeline of historically and technologically notable analog and digital synthesizers and devices implementing additive synthesis.\n\nDiscrete-time equations\n\nIn digital implementations of additive synthesis, discrete-time equations are used in place of the continuous-time synthesis equations.  A notational convention for discrete-time signals uses brackets i.e. y[n]\\, and the argument n\\, can only be integer values.  If the continuous-time synthesis output y(t)\\, is expected to be sufficiently bandlimited; below half the sampling rate or f_\\mathrm{s}/2\\,, it suffices to directly sample the continuous-time expression to get the discrete synthesis equation. The continuous synthesis output can later be reconstructed from the samples using a digital-to-analog converter. The sampling period is T=1/f_\\mathrm{s}\\,.\n\nBeginning with (),\n\ny(t) \\sum_{k\n1}^{K} r_k(t) \\cos\\left(2 \\pi \\int_0^t f_k(u)\\ du + \\phi_k \\right)\n\nand sampling at discrete times  t nT \n n/f_\\mathrm{s} \\, results in\n\n \\begin{align}\n y[n] & y(nT) \n \\sum_{k=1}^{K} r_k(nT) \\cos\\left(2 \\pi \\int_0^{nT} f_k(u)\\ du + \\phi_k \\right) \\\\\n      & \\sum_{k\n1}^{K} r_k(nT) \\cos\\left(2 \\pi \\sum_{i=1}^{n} \\int_{(i-1)T}^{iT} f_k(u)\\ du + \\phi_k \\right) \\\\\n      & \\sum_{k\n1}^{K} r_k(nT) \\cos\\left(2 \\pi \\sum_{i=1}^{n} (T f_k[i]) + \\phi_k \\right) \\\\\n      & \\sum_{k\n1}^{K} r_k[n] \\cos\\left(\\frac{2 \\pi}{f_\\mathrm{s}} \\sum_{i=1}^{n} f_k[i] + \\phi_k \\right) \\\\\n       \\end{align} \nwhere\n\nr_k[n] = r_k(nT) \\, is the discrete-time varying amplitude envelope\nf_k[n] = \\frac{1}{T} \\int_{(n-1)T}^{nT} f_k(t)\\ dt \\, is the discrete-time backward difference instantaneous frequency.\n\nThis is equivalent to\n\n y[n] \\sum_{k\n1}^{K} r_k[n] \\cos\\left( \\theta_k[n] \\right) \n\nwhere\n\n \\begin{align}\n    \\theta_k[n] &\\frac{2 \\pi}{f_\\mathrm{s}} \\sum_{i\n1}^{n} f_k[i] + \\phi_k \\\\\n                &= \\theta_k[n-1] + \\frac{2 \\pi}{f_\\mathrm{s}} f_k[n] \\\\\n       \\end{align}  for all n>0\\,\nand\n \\theta_k[0] = \\phi_k. \\,",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Additive synthesis" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=2218" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "Additive synthesis is a sound synthesis technique that creates timbre by adding sine waves together.\n\nThe timbre of musical instruments can be considered in the light of Fourier theory to consist of multiple harmonic or inharmonic partials or overtones. Each partial is a sine wave of different frequency and amplitude that swells and decays over time due to modulation from an ADSR envelope or low frequency oscillator.\n\nAdditive synthesis most directly generates sound by adding the output of multiple sine wave generators. Alternative implementations may use pre-computed wavetables or the inverse Fast Fourier transform.\n\nExplanation \n\nThe sounds that are heard in everyday life are not characterized by a single frequency. Instead, they consist of a sum of pure sine frequencies, each one at a different amplitude. When humans hear these frequencies simultaneously, we can recognize the sound. This is true for both \"non-musical\" sounds (e.g. water splashing, leaves rustling, etc.) and for \"musical sounds\" (e.g. a piano note, a bird's tweet, etc.). This set of parameters (frequencies, their relative amplitudes, and how the relative amplitudes change over time) are encapsulated by the timbre of the sound. Fourier analysis is the technique that is used to determine these exact timbre parameters from an overall sound signal; conversely, the resulting set of frequencies and amplitudes is called the Fourier series of the original sound signal.\n\nIn the case of a musical note, the lowest frequency of its timbre is designated as the sound's fundamental frequency. For simplicity, we often say that the note is playing at that fundamental frequency (e.g. \"middle C is 261.6 Hz\"), even though the sound of that note consists of many other frequencies as well. The set of the remaining frequencies is called the overtones (or the harmonics) of the sound. In other words, the fundamental frequency alone is responsible for the pitch of the note, while the overtones define the timbre of the sound. The overtones of a piano playing middle C will be quite different from the overtones of a violin playing the same note; that's what allows us to differentiate the sounds of the two instruments. There are even subtle differences in timbre between different versions of the same instrument (for example, an upright piano vs. a grand piano).\n\nAdditive synthesis aims to exploit this property of sound in order to construct timbre from the ground up. By adding together pure frequencies (sine waves) of varying frequencies and amplitudes, we can precisely define the timbre of the sound that we want to create.\n\nDefinitions\n\nHarmonic additive synthesis is closely related to the concept of a Fourier series which is a way of expressing a periodic function as the sum of sinusoidal functions with frequencies equal to integer multiples of a common fundamental frequency.  These sinusoids are called harmonics, overtones, or generally, partials.  In general, a Fourier series contains an infinite number of sinusoidal components, with no upper limit to the frequency of the sinusoidal functions and includes a DC component (one with frequency of 0 Hz).  Frequencies outside of the human audible range can be omitted in additive synthesis.  As a result, only a finite number of sinusoidal terms with frequencies that lie within the audible range are modeled in additive synthesis.\n\nA waveform or function is said to be periodic if\n\n y(t) = y(t+P) \\ \n\nfor all  t \\, and for some period  P \\,.\n\nThe Fourier series of a periodic function is mathematically expressed as:\n\n \\begin{align}\n  y(t) &\\frac{a_0}{2} + \\sum_{k\n1}^{\\infty} \\left[ a_k \\cos(2 \\pi k f_0 t ) - b_k \\sin(2 \\pi k f_0 t ) \\right] \\\\\n       &\\frac{a_0}{2} + \\sum_{k\n1}^{\\infty} r_k \\cos\\left(2 \\pi k f_0 t + \\phi_k \\right) \\\\\n   \\end{align} \n\nwhere\n\n: f_0 = 1/P\\, is the fundamental frequency of the waveform and is equal to the reciprocal of the period,\n: a_k r_k \\cos(\\phi_k) \n 2 f_0 \\int_{0}^P y(t) \\cos(2 \\pi k f_0 t)\\, dt, \\quad k \\ge 0\\,\n: b_k r_k \\sin(\\phi_k) \n -2 f_0 \\int_{0}^P y(t) \\sin(2 \\pi k f_0 t)\\, dt, \\quad k \\ge 1\\,\n: r_k = \\sqrt{a_k^2 + b_k^2}\\, is the amplitude of the k\\,th harmonic,\n: \\phi_k = \\operatorname{atan2}(b_k, a_k)\\, is the phase offset of the k\\,th harmonic. atan2(Â ) is the four-quadrant arctangent function,\n\nBeing inaudible, the DC component, a_0/2\\,, and all components with frequencies higher than some finite limit, K f_0\\,, are omitted in the following expressions of additive synthesis.\n\nHarmonic form\n\nThe simplest harmonic additive synthesis can be mathematically expressed as:\n\nwhere y(t)\\, is the synthesis output, r_k\\,, k f_0\\,, and \\phi_k\\, are the amplitude, frequency, and the phase offset, respectively, of the k\\,th harmonic partial of a total of K\\, harmonic partials, and f_0\\, is the fundamental frequency of the waveform and the frequency of the musical note.\n\nTime-dependent amplitudes\n\nMore generally, the amplitude of each harmonic can be prescribed as a function of time, r_k(t)\\,, in which case the synthesis output is\n\nEach envelope r_k(t)\\, should vary slowly relative to the frequency spacing between adjacent sinusoids.  The bandwidth of r_k(t)\\, should be significantly less than f_0\\,.\n\nInharmonic form\n\nAdditive synthesis can also produce inharmonic sounds (which are aperiodic waveforms) in which the individual overtones need not have frequencies that are integer multiples of some common fundamental frequency.\n ([https://ccrma.stanford.edu/STANM/stanms/stanm43/stanm43.pdf online reprint])\n  While many conventional musical instruments have harmonic partials (e.g. an oboe), some have inharmonic partials (e.g. bells).  Inharmonic additive synthesis can be described as\n\ny(t) \\sum_{k\n1}^{K} r_k(t) \\cos\\left(2 \\pi f_k t + \\phi_k \\right),\n\nwhere f_k\\, is the constant frequency of k\\,th partial.\n\nTime-dependent frequencies\n\nIn the general case, the instantaneous frequency of a sinusoid is the derivative (with respect to time) of the argument of the sine or cosine function.  If this frequency is represented in hertz, rather than in angular frequency form, then this derivative is divided by 2 \\pi\\,.  This is the case whether the partial is harmonic or inharmonic and whether its frequency is constant or time-varying.\n\nIn the most general form, the frequency of each non-harmonic partial is a non-negative function of time, f_k(t)\\,, yielding\n\nBroader definitions\n\nAdditive synthesis more broadly may mean sound synthesis techniques that sum simple elements to create more complex timbres, even when the elements are not sine waves.\n\n For example, F. Richard Moore listed additive synthesis as one of the \"four basic categories\" of sound synthesis alongside subtractive synthesis, nonlinear synthesis, and physical modeling. In this broad sense, pipe organs, which also have pipes producing non-sinusoidal waveforms, can be considered as a variant form of additive synthesizers. Summation of principal components and Walsh functions have also been classified as additive synthesis.\n\nImplementation methods\n\nModern-day implementations of additive synthesis are mainly digital. (See section Discrete-time equations for the underlying discrete-time theory)\n\nOscillator bank synthesis\n\nAdditive synthesis can be implemented using a bank of sinusoidal oscillators, one for each partial.\n\nWavetable synthesis\n\nIn the case of harmonic, quasi-periodic musical tones, wavetable synthesis can be as general as time-varying additive synthesis, but requires less computation during synthesis.\n\n As a result, an efficient implementation of time-varying additive synthesis of harmonic tones can be accomplished by use of wavetable synthesis.\n\nGroup additive synthesis\n\nGroup additive synthesis\n \n\n is a method to group partials into harmonic groups (having different fundamental frequencies) and synthesize each group separately with wavetable synthesis before mixing the results.\n\nInverse FFT synthesis\n\nAn inverse Fast Fourier transform can be used to efficiently synthesize frequencies that evenly divide the transform period or \"frame\". By careful consideration of the DFT frequency-domain representation it is also possible to efficiently synthesize sinusoids of arbitrary frequencies using a series of overlapping frames and the inverse Fast Fourier transform.\n\nAdditive analysis/resynthesis\n\nIt is possible to analyze the frequency components of a recorded sound giving a \"sum of sinusoids\" representation. This representation can be re-synthesized using additive synthesis. One method of decomposing a sound into time varying sinusoidal partials is short-time Fourier transform (STFT)-based McAulay-Quatieri Analysis.\n\nBy modifying the sum of sinusoids representation, timbral alterations can be made prior to resynthesis. For example, a harmonic sound could be restructured to sound inharmonic, and vice versa. Sound hybridisation or \"morphing\" has been implemented by additive resynthesis.\n\nAdditive analysis/resynthesis has been employed in a number of techniques including Sinusoidal Modelling,\n Spectral Modelling Synthesis (SMS), and the Reassigned Bandwidth-Enhanced Additive Sound Model.\n Software that implements additive analysis/resynthesis includes: SPEAR,[http://www.klingbeil.com/spear/ SPEAR Sinusoidal Partial Editing Analysis and Resynthesis for Mac OS X, MacOS 9 and Windows] LEMUR, LORIS,[http://www.hakenaudio.com/Loris/ Loris Software for Sound Modeling, Morphing, and Manipulation] SMSTools,[http://mtg.upf.edu/technologies/sms SMSTools application for Windows] ARSS.[http://arss.sourceforge.net/ ARSS: The Analysis & Resynthesis Sound Spectrograph]\n\nProducts\n\nNew England Digital Synclavier had a resynthesis feature where samples could be analyzed and converted into âtimbre framesâ which were part of its additive synthesis engine. Technos acxel, launched in 1987, utilized the additive analysis/resynthesis model, in an FFT implementation.\n\nAlso a vocal synthesizer, Vocaloid have been implemented on the basis of additive analysis/resynthesis: its spectral voice model called Excitation plus Resonances (EpR) model\n ([http://mtg.upf.edu/files/publications/icmc2001-celma.pdf PDF])\n ([http://www.tdx.cat/bitstream/handle/10803/7542/talm.pdf?sequence=1 PDF]).\nSee \"Excitation plus resonances voice model\" (p. 51)\n is extended based on Spectral Modeling Synthesis (SMS),\nand its diphone concatenative synthesis is processed using\nspectral peak processing (SPP), \"Spectral peak processing\" technique similar to modified phase-locked vocoder, \"Phase locked vocoder\" (an improved phase vocoder for formant processing).\n  Using these techniques, spectral components (formants) consisting of purely harmonic partials can be appropriately transformed into desired form for sound modeling, and sequence of short samples (diphones or phonemes) constituting desired phrase, can be smoothly connected by interpolating matched partials and formant peaks, respectively, in the inserted transition region between different samples. (See also Dynamic timbres)\n\nApplications\n\nMusical instruments\n\nAdditive synthesis is used in electronic musical instruments. It is the principal sound generation technique used by Eminent organs.\n\nSpeech synthesis\n\nIn linguistics research, harmonic additive synthesis was used in 1950s to play back modified and synthetic speech spectrograms.\n\nLater, in early 1980s, listening tests were carried out on synthetic speech stripped of acoustic cues to assess their significance. Time-varying formant frequencies and amplitudes derived by linear predictive coding were synthesized additively as pure tone whistles. This method is called sinewave synthesis.\n\n Also the composite sinusoidal modeling (CSM)\n\n used on a singing speech synthesis feature on Yamaha CX5M (1984), is known to use a similar approach which was independently developed during 1966â1979.\n\n These methods are characterized by extraction and recomposition of a set of significant spectral peaks corresponding to the several resonance modes occurred in the oral cavity and nasal cavity, in a viewpoint of acoustics. This principle was also utilized on a physical modeling synthesis method, called modal synthesis.\n\n Â (See also [http://www2.ph.ed.ac.uk/~sbilbao/nsstop.html companion page])\n\nHistory\n\nHarmonic analysis was discovered by Joseph Fourier,\n who published an extensive treatise of his research in the context of heat transfer in 1822.\n The theory found an early application in prediction of tides. Around 1876, Lord Kelvin constructed a mechanical tide predictor. It consisted of a harmonic analyzer and a harmonic synthesizer, as they were called already in the 19th century.\n\n The analysis of tide measurements was done using James Thomson's integrating machine. The resulting Fourier coefficients were input into the synthesizer, which then used a system of cords and pulleys to generate and sum harmonic sinusoidal partials for prediction of future tides. In 1910, a similar machine was built for the analysis of periodic waveforms of sound. The synthesizer drew a graph of the combination waveform, which was used chiefly for visual validation of the analysis.\n\nGeorg Ohm applied Fourier's theory to sound in 1843. The line of work was greatly advanced by Hermann von Helmholtz, who published his eight years worth of research in 1863.\n Helmholtz believed that the psychological perception of tone color is subject to learning, while hearing in the sensory sense is purely physiological.\n He supported the idea that perception of sound derives from signals from nerve cells of the basilar membrane and that the elastic appendages of these cells are sympathetically vibrated by pure sinusoidal tones of appropriate frequencies.\n Helmholtz agreed with the finding of Ernst Chladni from 1787 that certain sound sources have inharmonic vibration modes.\n\nIn Helmholtz's time, electronic amplification was unavailable. For synthesis of tones with harmonic partials, Helmholtz built an electrically excited array of tuning forks and acoustic resonance chambers that allowed adjustment of the amplitudes of the partials.  Built at least as early as in 1862, these were in turn refined by Rudolph Koenig, who demonstrated his own setup in 1872.\n For harmonic synthesis, Koenig also built a large apparatus based on his wave siren. It was pneumatic and utilized cut-out tonewheels, and was criticized for low purity of its partial tones. Also tibia pipes of pipe organs have nearly sinusoidal waveforms and can be combined in the manner of additive synthesis.\n\nIn 1938, with significant new supporting evidence,\n it was reported on the pages of Popular Science Monthly that the human vocal cords function like a fire siren to produce a harmonic-rich tone, which is then filtered by the vocal tract to produce different vowel tones.\n By the time, the additive Hammond organ was already on market. Most early electronic organ makers thought it too expensive to manufacture the plurality of oscillators required by additive organs, and began instead to build subtractive ones. In a 1940 Institute of Radio Engineers meeting, the head field engineer of Hammond elaborated on the company's new Novachord as having a âsubtractive systemâ in contrast to the original Hammond organ in which âthe final tones were built up by combining sound wavesâ. Alan Douglas used the qualifiers additive and subtractive to describe different types of electronic organs in a 1948 paper presented to the Royal Musical Association.  The contemporary wording additive synthesis and subtractive synthesis can be found in his 1957 book The electrical production of music, in which he categorically lists three methods of forming of musical tone-colours, in sections titled Additive synthesis, Subtractive synthesis, and Other forms of combinations.\n\nA typical modern additive synthesizer produces its output as an electrical, analog signal, or as digital audio, such as in the case of software synthesizers, which became popular around year 2000.\n\nTimeline \n\nThe following is a timeline of historically and technologically notable analog and digital synthesizers and devices implementing additive synthesis.\n\nDiscrete-time equations\n\nIn digital implementations of additive synthesis, discrete-time equations are used in place of the continuous-time synthesis equations.  A notational convention for discrete-time signals uses brackets i.e. y[n]\\, and the argument n\\, can only be integer values.  If the continuous-time synthesis output y(t)\\, is expected to be sufficiently bandlimited; below half the sampling rate or f_\\mathrm{s}/2\\,, it suffices to directly sample the continuous-time expression to get the discrete synthesis equation. The continuous synthesis output can later be reconstructed from the samples using a digital-to-analog converter. The sampling period is T=1/f_\\mathrm{s}\\,.\n\nBeginning with (),\n\ny(t) \\sum_{k\n1}^{K} r_k(t) \\cos\\left(2 \\pi \\int_0^t f_k(u)\\ du + \\phi_k \\right)\n\nand sampling at discrete times  t nT \n n/f_\\mathrm{s} \\, results in\n\n \\begin{align}\n y[n] & y(nT) \n \\sum_{k=1}^{K} r_k(nT) \\cos\\left(2 \\pi \\int_0^{nT} f_k(u)\\ du + \\phi_k \\right) \\\\\n      & \\sum_{k\n1}^{K} r_k(nT) \\cos\\left(2 \\pi \\sum_{i=1}^{n} \\int_{(i-1)T}^{iT} f_k(u)\\ du + \\phi_k \\right) \\\\\n      & \\sum_{k\n1}^{K} r_k(nT) \\cos\\left(2 \\pi \\sum_{i=1}^{n} (T f_k[i]) + \\phi_k \\right) \\\\\n      & \\sum_{k\n1}^{K} r_k[n] \\cos\\left(\\frac{2 \\pi}{f_\\mathrm{s}} \\sum_{i=1}^{n} f_k[i] + \\phi_k \\right) \\\\\n       \\end{align} \nwhere\n\nr_k[n] = r_k(nT) \\, is the discrete-time varying amplitude envelope\nf_k[n] = \\frac{1}{T} \\int_{(n-1)T}^{nT} f_k(t)\\ dt \\, is the discrete-time backward difference instantaneous frequency.\n\nThis is equivalent to\n\n y[n] \\sum_{k\n1}^{K} r_k[n] \\cos\\left( \\theta_k[n] \\right) \n\nwhere\n\n \\begin{align}\n    \\theta_k[n] &\\frac{2 \\pi}{f_\\mathrm{s}} \\sum_{i\n1}^{n} f_k[i] + \\phi_k \\\\\n                &= \\theta_k[n-1] + \\frac{2 \\pi}{f_\\mathrm{s}} f_k[n] \\\\\n       \\end{align}  for all n>0\\,\nand\n \\theta_k[0] = \\phi_k. \\,. Additive synthesis. http://en.wikipedia.org/?curid=2218."
  }
}
