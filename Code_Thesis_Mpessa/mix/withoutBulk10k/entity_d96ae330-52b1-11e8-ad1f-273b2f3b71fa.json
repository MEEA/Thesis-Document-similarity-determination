{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=6011",
  "eid" : "d96ae330-52b1-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778444515,
  "textBody" : "In the formal languages of computer science and linguistics, the Chomsky hierarchy (occasionally referred to as Chomsky–Schützenberger hierarchy) is a containment hierarchy of classes of formal grammars.\nThis hierarchy of grammars was described by Noam Chomsky in 1956. It is also named after Marcel-Paul Schützenberger, who played a crucial role in the development of the theory of formal languages.\n\nFormal grammars \n\nA formal grammar of this type consists of a finite set of production rules (left-hand side → right-hand side), where each side consists of a finite sequence of the following symbols:\n* a finite set of nonterminal symbols (indicating that some production rule can yet be applied)\n* a finite set of terminal symbols (indicating that no production rule can be applied)\n* a start symbol (a distinguished nonterminal symbol)\n\nA formal grammar provides an axiom schema for (or generates) a formal language, which is a (usually infinite) set of finite-length sequences of symbols  that may be constructed by applying production rules to another sequence of symbols (which initially contains just the start symbol).  A rule may be applied by replacing an occurrence of the symbols on its left-hand side with those that appear on its right-hand side.  A sequence of rule applications is called a derivation.  Such a grammar defines the formal language: all words consisting solely of terminal symbols which can be reached by a derivation from the start symbol.\n\nNonterminals are often represented by uppercase letters, terminals by lowercase letters, and the start symbol by .  For example, the grammar with terminals , nonterminals , production rules\n→ \n→ ε  (where ε is the empty string)\n→ \n→ \nand start symbol , defines the language of all words of the form  a^n b^n  (i.e.  copies of  followed by  copies of ).\n\nThe following is a simpler grammar that defines the same language: \nTerminals , Nonterminals , Start symbol , Production rules\n→ \n→ ε\n\nAs another example, a grammar for a toy subset of English language is given by:\n;terminals: \n;nonterminals: \n;production rules\n→  \n→  \n→ \n→  \n→ \n→ \n→ \n→ \n→ \n→ \n→ \nand start symbol . An example derivation is\n→  →  →  →  →  →  →  →  →  →  →  →  → .\nOther sequences that can be derived from this grammar are: \"ideas hate great linguists\", and \"ideas generate\". While these sentences are nonsensical, they are syntactically correct. A syntactically incorrect sentence ( e.g. \"ideas ideas great hate\") cannot be derived from this grammar. See \"Colorless green ideas sleep furiously\" for a similar example given by Chomsky in 1957; see Phrase structure grammar and Phrase structure rules for more natural language examples and the problems of formal grammar in that area.\n\nThe hierarchy \n\nThe following table summarizes each of Chomsky's four types of grammars, the class of language it generates, the type of automaton that recognizes it, and the form its rules must have.\n\nNote that the set of grammars corresponding to recursive languages is not a member of this hierarchy; these would be properly between Type-0 and Type-1.\n\nEvery regular language is context-free, every context-free language is context-sensitive, every context-sensitive language is recursive and every recursive language is recursively enumerable. These are all proper inclusions, meaning that there exist recursively enumerable languages that are not context-sensitive, context-sensitive languages that are not context-free and context-free languages that are not regular.\n\nType-0 grammars\n\nType-0 grammars include all formal grammars. They generate exactly all languages that can be recognized by a Turing machine. These languages are also known as the recursively enumerable or Turing-recognizable languages.  Note that this is different from the recursive languages, which can be decided by an always-halting Turing machine.\n\nType-1 grammars\n\nType-1 grammars generate the context-sensitive languages.  These grammars have rules of the form \\alpha A\\beta \\rightarrow \\alpha\\gamma\\beta with A a nonterminal and \\alpha, \\beta and \\gamma strings of terminals and/or nonterminals. The strings \\alpha and \\beta may be empty, but \\gamma must be nonempty.  The rule S \\rightarrow \\epsilon is allowed if S does not appear on the right side of any rule.  The languages described by these grammars are exactly all languages that can be recognized by a linear bounded automaton (a nondeterministic Turing machine whose tape is bounded by a constant times the length of the input.)\n\nType-2 grammars\n\nType-2 grammars generate the context-free languages. These are defined by rules of the form A \\rightarrow \\gamma with A being a nonterminal and \\gamma being a string of terminals and/or nonterminals. These languages are exactly all languages that can be recognized by a non-deterministic pushdown automaton. Context-free languages—or rather its subset of deterministic context-free language—are the theoretical basis for the phrase structure of most programming languages, though their syntax also includes context-sensitive name resolution due to declarations and scope. Often a subset of grammars is used to make parsing easier, such as by an LL parser.\n\nType-3 grammars\n\nType-3 grammars generate the regular languages.  Such a grammar restricts its rules to a single nonterminal on the left-hand side and a right-hand side consisting of a single terminal, possibly followed by a single nonterminal (right regular). Alternatively, the right-hand side of the grammar can consist of a single terminal, possibly preceded by a single nonterminal (left regular). These generate the same languages. However, if left-regular rules and right-regular rules are combined, the language need no longer be regular. The rule S \\rightarrow \\epsilon is also allowed here if S does not appear on the right side of any rule.  These languages are exactly all languages that can be decided by a finite state automaton. Additionally, this family of formal languages can be obtained by regular expressions. Regular languages are commonly used to define search patterns and the lexical structure of programming languages.",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Chomsky hierarchy" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=6011" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "In the formal languages of computer science and linguistics, the Chomsky hierarchy (occasionally referred to as Chomsky–Schützenberger hierarchy) is a containment hierarchy of classes of formal grammars.\nThis hierarchy of grammars was described by Noam Chomsky in 1956. It is also named after Marcel-Paul Schützenberger, who played a crucial role in the development of the theory of formal languages.\n\nFormal grammars \n\nA formal grammar of this type consists of a finite set of production rules (left-hand side → right-hand side), where each side consists of a finite sequence of the following symbols:\n* a finite set of nonterminal symbols (indicating that some production rule can yet be applied)\n* a finite set of terminal symbols (indicating that no production rule can be applied)\n* a start symbol (a distinguished nonterminal symbol)\n\nA formal grammar provides an axiom schema for (or generates) a formal language, which is a (usually infinite) set of finite-length sequences of symbols  that may be constructed by applying production rules to another sequence of symbols (which initially contains just the start symbol).  A rule may be applied by replacing an occurrence of the symbols on its left-hand side with those that appear on its right-hand side.  A sequence of rule applications is called a derivation.  Such a grammar defines the formal language: all words consisting solely of terminal symbols which can be reached by a derivation from the start symbol.\n\nNonterminals are often represented by uppercase letters, terminals by lowercase letters, and the start symbol by .  For example, the grammar with terminals , nonterminals , production rules\n→ \n→ ε  (where ε is the empty string)\n→ \n→ \nand start symbol , defines the language of all words of the form  a^n b^n  (i.e.  copies of  followed by  copies of ).\n\nThe following is a simpler grammar that defines the same language: \nTerminals , Nonterminals , Start symbol , Production rules\n→ \n→ ε\n\nAs another example, a grammar for a toy subset of English language is given by:\n;terminals: \n;nonterminals: \n;production rules\n→  \n→  \n→ \n→  \n→ \n→ \n→ \n→ \n→ \n→ \n→ \nand start symbol . An example derivation is\n→  →  →  →  →  →  →  →  →  →  →  →  → .\nOther sequences that can be derived from this grammar are: \"ideas hate great linguists\", and \"ideas generate\". While these sentences are nonsensical, they are syntactically correct. A syntactically incorrect sentence ( e.g. \"ideas ideas great hate\") cannot be derived from this grammar. See \"Colorless green ideas sleep furiously\" for a similar example given by Chomsky in 1957; see Phrase structure grammar and Phrase structure rules for more natural language examples and the problems of formal grammar in that area.\n\nThe hierarchy \n\nThe following table summarizes each of Chomsky's four types of grammars, the class of language it generates, the type of automaton that recognizes it, and the form its rules must have.\n\nNote that the set of grammars corresponding to recursive languages is not a member of this hierarchy; these would be properly between Type-0 and Type-1.\n\nEvery regular language is context-free, every context-free language is context-sensitive, every context-sensitive language is recursive and every recursive language is recursively enumerable. These are all proper inclusions, meaning that there exist recursively enumerable languages that are not context-sensitive, context-sensitive languages that are not context-free and context-free languages that are not regular.\n\nType-0 grammars\n\nType-0 grammars include all formal grammars. They generate exactly all languages that can be recognized by a Turing machine. These languages are also known as the recursively enumerable or Turing-recognizable languages.  Note that this is different from the recursive languages, which can be decided by an always-halting Turing machine.\n\nType-1 grammars\n\nType-1 grammars generate the context-sensitive languages.  These grammars have rules of the form \\alpha A\\beta \\rightarrow \\alpha\\gamma\\beta with A a nonterminal and \\alpha, \\beta and \\gamma strings of terminals and/or nonterminals. The strings \\alpha and \\beta may be empty, but \\gamma must be nonempty.  The rule S \\rightarrow \\epsilon is allowed if S does not appear on the right side of any rule.  The languages described by these grammars are exactly all languages that can be recognized by a linear bounded automaton (a nondeterministic Turing machine whose tape is bounded by a constant times the length of the input.)\n\nType-2 grammars\n\nType-2 grammars generate the context-free languages. These are defined by rules of the form A \\rightarrow \\gamma with A being a nonterminal and \\gamma being a string of terminals and/or nonterminals. These languages are exactly all languages that can be recognized by a non-deterministic pushdown automaton. Context-free languages—or rather its subset of deterministic context-free language—are the theoretical basis for the phrase structure of most programming languages, though their syntax also includes context-sensitive name resolution due to declarations and scope. Often a subset of grammars is used to make parsing easier, such as by an LL parser.\n\nType-3 grammars\n\nType-3 grammars generate the regular languages.  Such a grammar restricts its rules to a single nonterminal on the left-hand side and a right-hand side consisting of a single terminal, possibly followed by a single nonterminal (right regular). Alternatively, the right-hand side of the grammar can consist of a single terminal, possibly preceded by a single nonterminal (left regular). These generate the same languages. However, if left-regular rules and right-regular rules are combined, the language need no longer be regular. The rule S \\rightarrow \\epsilon is also allowed here if S does not appear on the right side of any rule.  These languages are exactly all languages that can be decided by a finite state automaton. Additionally, this family of formal languages can be obtained by regular expressions. Regular languages are commonly used to define search patterns and the lexical structure of programming languages. Chomsky hierarchy. http://en.wikipedia.org/?curid=6011."
  }
}
