{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=14856",
  "eid" : "18222f70-52b2-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778549735,
  "textBody" : "In linear algebra, an inner product space is a vector space with an additional structure called an inner product. This additional structure associates each pair of vectors in the space with a scalar quantity known as the inner product of the vectors. Inner products allow the rigorous introduction of intuitive geometrical notions such as the length of a vector or the angle between two vectors. They also provide the means of defining orthogonality between vectors (zero inner product). Inner product spaces generalize Euclidean spaces (in which the inner product is the dot product, also known as the scalar product) to vector spaces of any (possibly infinite) dimension, and are studied in functional analysis. The first usage of the concept of a vector space with an inner product is due to Peano, in 1898.\n\nAn inner product naturally induces an associated norm, thus an inner product space is also a normed vector space. A complete space with an inner product is called a Hilbert space. An (incomplete) space with an inner product is called a pre-Hilbert space, since its completion with respect to the norm induced by the inner product is a Hilbert space. Inner product spaces over the field of complex numbers are sometimes referred to as unitary spaces.\n\nDefinition \n\nIn this article, the field of scalars denoted  is either the field of real numbers  or the field of complex numbers .\n\nFormally, an inner product space is a vector space  over the field  together with an inner product, i.e., with a map\n \\langle \\cdot, \\cdot \\rangle : V \\times V \\to F \n\nthat satisfies the following three axioms for all vectors  and all scalars :\n\n* Conjugate symmetry:A bar over an expression denotes complex conjugation.\n:\\langle x,y\\rangle =\\overline{\\langle y,x\\rangle}\n\n* Linearity in the first argument:\n:\\begin{align}\n\\langle ax,y\\rangle &= a \\langle x,y\\rangle \\\\\n\\langle x+y,z\\rangle &= \\langle x,z\\rangle + \\langle y,z\\rangle\n\\end{align}\n\n* Positive-definiteness:\n:\\begin{align}\n\\langle x,x\\rangle &\\geq 0 \\\\\n\\langle x,x\\rangle &0 \\Leftrightarrow x \n \\mathbf{0} \\,.\n\\end{align}\n\nAlternative definitions, notations and remarks\n\nSome authors, especially in physics and matrix algebra, prefer to define the inner product and the sesquilinear form with linearity in the second argument rather than the first. Then the first argument becomes conjugate linear, rather than the second. In those disciplines we would write the product  as  (the bra–ket notation of quantum mechanics), respectively  (dot product as a case of the convention of forming the matrix product  as the dot products of rows of  with columns of ). Here the kets and columns are identified with the vectors of  and the bras and rows with the linear functionals (covectors) of the dual space , with conjugacy associated with duality. This reverse order is now occasionally followed in the more abstract literature, taking  to be conjugate linear in  rather than . A few instead find a middle ground by recognizing both  and  as distinct notations differing only in which argument is conjugate linear.\n\nThere are various technical reasons why it is necessary to restrict the basefield to  and  in the definition. Briefly, the basefield has to contain an ordered subfield in order for non-negativity to make sense,. and therefore has to have characteristic equal to 0 (since any ordered field has to have such characteristic). This immediately excludes finite fields. The basefield has to have additional structure, such as a distinguished automorphism. More generally any quadratically closed subfield of  or  will suffice for this purpose, e.g., the algebraic numbers or the constructible numbers. However in these cases when it is a proper subfield (i.e., neither  nor ) even finite-dimensional inner product spaces will fail to be metrically complete. In contrast all finite-dimensional inner product spaces over  or , such as those used in quantum computation, are automatically metrically complete and hence Hilbert spaces.\n\nIn some cases we need to consider non-negative semi-definite sesquilinear forms. This means that  is only required to be non-negative. We show how to treat these below.\n\nElementary properties \n\nWhen , conjugate symmetry reduces to symmetry. That is,  for ; while for ,  is equal to the complex conjugate.\n\nNotice that conjugate symmetry implies that  is real for all , since we have:\n\n\\langle x,x \\rangle = \\overline{\\langle x,x \\rangle} \\,.\n\nMoreover, sesquilinearity (see below) implies that\n\n \\langle -x,x \\rangle-1\\langle x,x\\rangle \n \\overline{-1}\\langle x,x\\rangle = \\langle x,-x\\rangle \\,.\n\nConjugate symmetry and linearity in the first variable gives\n\n\\begin{align}\n\\langle x, a y \\rangle &\\overline{\\langle a y, x \\rangle} \n \\overline{a} \\overline{\\langle y, x \\rangle} = \\overline{a} \\langle x, y \\rangle \\\\\n\\langle x, y + z \\rangle &\\overline{\\langle y + z, x \\rangle} \n \\overline{\\langle y, x \\rangle} + \\overline{\\langle z, x \\rangle} = \\langle x, y \\rangle + \\langle x, z \\rangle \\,,\n\\end{align}\n\nso an inner product is a sesquilinear form. Conjugate symmetry is also called Hermitian symmetry, and a conjugate symmetric sesquilinear form is called a Hermitian form. While the above axioms are more mathematically economical, a compact verbal definition of an inner product is a positive-definite Hermitian form.\n\nIn the case of , conjugate-symmetry reduces to symmetry, and sesquilinear reduces to bilinear. So, an inner product on a real vector space is a positive-definite symmetric bilinear form.\n\nFrom the linearity property it is derived that  implies . while from the positive-definiteness axiom we obtain the converse,  implies . Combining these two, we have the property that  if and only if .\n\nCombining the linearity of the inner product in its first argument and the conjugate symmetry gives the following important generalization of the familiar square expansion:\n\\langle x + y,x + y\\rangle = \\langle x,x\\rangle + \\langle x,y\\rangle + \\langle y,x\\rangle + \\langle y,y\\rangle \\,.\nAssuming the underlying field to be , the inner product becomes symmetric, and we obtain\n\\langle x \\pm y,x \\pm y\\rangle =\\langle x,x\\rangle \\pm 2\\langle x,y\\rangle + \\langle y,y\\rangle \\,,\nThe property of an inner product space  that\n\\begin{align}\n\\langle x+y,z\\rangle&= \\langle x,z\\rangle+ \\langle y,z\\rangle \\,, \\\\\n\\langle x,y+z\\rangle &= \\langle x,y\\rangle + \\langle x,z\\rangle\n\\end{align}\nis also known as additivity.\n\nExamples \n\nReal numbers\n\nA simple example is the real numbers with the standard multiplication as the inner product\n\\langle x,y\\rangle := x y.\n\nEuclidean space\n\nMore generally, the real -space  with the dot product is an inner product space, an example of a Euclidean -space.\n\\left\\langle \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix},\\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_n \\end{bmatrix} \\right\\rangle :x^\\mathsf{T} y \n \\sum_{i1}^n x_i y_i \n x_1 y_1 + \\cdots + x_n y_n,\nwhere  is the transpose of .\n\nComplex coordinate space\n\nThe general form of an inner product on  is known as the Hermitian form and is given by\n\\langle \\mathbf{x},\\mathbf{y}\\rangle :\\mathbf{y}^\\dagger\\mathbf{M}\\mathbf{x} \n \\overline{\\mathbf{x}^\\dagger\\mathbf{M}\\mathbf{y}},\nwhere  is any Hermitian positive-definite matrix and  is the conjugate transpose of . For the real case this corresponds to the dot product of the results of directionally different scaling of the two vectors, with positive scale factors and orthogonal directions of scaling. Up to an orthogonal transformation it is a weighted-sum version of the dot product, with positive weights.\n\nHilbert space\n\nThe article on Hilbert space has several examples of inner product spaces wherein the metric induced by the inner product yields a complete metric space. An example of an inner product which induces an incomplete metric occurs with the space  of continuous complex valued functions on the interval . The inner product is\n \\langle f , g \\rangle := \\int_a^b f(t) \\overline{g(t)} \\, \\mathrm{d}t. \nThis space is not complete; consider for example, for the interval  the sequence of continuous \"step\" functions, , defined by:\n f_k(t) = \\begin{cases} 0 & t \\in [-1,0] \\\\ 1 & t \\in \\left [\\tfrac{1}{k}, 1 \\right ] \\\\ kt & t \\in \\left (0, \\tfrac{1}{k} \\right) \\end{cases}\nThis sequence is a Cauchy sequence for the norm induced by the preceding inner product, which does not converge to a continuous function.\n\nRandom variables\n\nFor real random variables  and , the expected value of their product\n \\langle X, Y \\rangle := \\operatorname{E}(X Y) \nis an inner product. In this case,  if and only if  (i.e.,  almost surely). This definition of expectation as inner product can be extended to random vectors as well.\n\nReal matrices\n\nFor real matrices of the same size,  with transpose as conjugation\n \\left(\\langle A, B \\rangle = \\left\\langle B^\\mathrm{T}, A^\\mathrm{T} \\right\\rangle \\right)\nis an inner product.\n\nNorms on inner product spaces \n\nA linear space with a norm such as:\n\n\\|x\\|_p \\left ( \\sum_{i\n1}^{\\infty} \\left|\\xi_i \\right|^p \\right) ^{\\frac{1}{p}} \\qquad x = \\left \\{\\xi_i \\right \\} \\in l^p, \\quad p \\neq 2,\n\nis a normed space but not an inner product space, because this norm does not satisfy the parallelogram equality required of a norm to have an inner product associated with it.\n\nHowever, inner product spaces have a naturally defined norm based upon the inner product of the space itself that does satisfy the parallelogram equality:\n\n \\|x\\| =\\sqrt{\\langle x, x\\rangle}.\n\nThis is well defined by the nonnegativity axiom of the definition of inner product space. The norm is thought of as the length of the vector . Directly from the axioms, we can prove the following:\n\n*Cauchy–Schwarz inequality: for ,  elements of \n\n: |\\langle x,y\\rangle| \\leq \\|x\\| \\cdot \\|y\\| \n\nwith equality if and only if  and  are linearly dependent. This is one of the most important inequalities in mathematics. It is also known in the Russian mathematical literature as the Cauchy–Bunyakovsky–Schwarz inequality.\n\n*Orthogonality: The geometric interpretation of the inner product in terms of angle and length, motivates much of the geometric terminology we use in regard to these spaces. Indeed, an immediate consequence of the Cauchy–Schwarz inequality is that it justifies defining the angle between two non-zero vectors  and  (denoted ) in the case  by the identity\n\n:\\angle(x,y) = \\arccos \\frac{\\langle x, y \\rangle}{\\|x\\| \\cdot \\|y\\|}.\n\nWe assume the value of the angle is chosen to be in the interval . This is in analogy to the situation in two-dimensional Euclidean space.\n\nIn the case , the angle in the interval  is typically defined by\n\n:\\angle(x,y) = \\arccos \\frac{\\|x\\| \\cdot \\|y\\|}.\n\nCorrespondingly, we will say that non-zero vectors  and  of  are orthogonal if and only if their inner product is zero.\n\n*Homogeneity: for  an element of  and  a scalar\n\n: \\|r \\cdot x\\| = |r| \\cdot \\| x\\|.\n\nThe homogeneity property is completely trivial to prove.\n\n*Triangle inequality: for ,  elements of \n\n: \\|x + y\\| \\leq \\|x \\| + \\|y\\|. \n\nThe last two properties show the function defined is indeed a norm.\n\nBecause of the triangle inequality and because of axiom 2, we see that  is a norm which turns  into a normed vector space and hence also into a metric space. The most important inner product spaces are the ones which are complete with respect to this metric; they are called Hilbert spaces. Every inner product  space is a dense subspace of some Hilbert space. This Hilbert space is essentially uniquely determined by  and is constructed by completing .\n\n*Pythagorean theorem: Whenever ,  are in  and , then\n\n: \\|x\\|^2 + \\|y\\|^2 = \\|x+y\\|^2. \n\nThe proof of the identity requires only expressing the definition of norm in terms of the inner product and multiplying out, using the property of additivity of each component.\n\nThe name Pythagorean theorem arises from the geometric interpretation of this result as an analogue of the theorem in synthetic geometry. Note that the proof of the Pythagorean theorem in synthetic geometry is considerably more elaborate because of the paucity of underlying structure. In this sense, the synthetic Pythagorean theorem, if correctly demonstrated, is deeper than the version given above.\n\nAn induction on the Pythagorean theorem yields:\n\n*If  are orthogonal vectors, that is,  for distinct indices , , then\n\n: \\sum_{i1}^n \\|x_i\\|^2 \n \\left\\|\\sum_{i=1}^n x_i \\right\\|^2. \n\nIn view of the Cauchy-Schwarz inequality, we also note that  is continuous from  to . This allows us to extend Pythagoras' theorem to infinitely many summands:\n\n*Parseval's identity: Suppose  is a complete inner product space. If  are mutually orthogonal vectors in  then\n\n: \\sum_{i1}^\\infty\\|x_i\\|^2 \n \\left\\|\\sum_{i=1}^\\infty x_i\\right\\|^2, \n\nprovided the infinite series on the left is convergent. Completeness of the space is needed to ensure that the sequence of partial sums\n\n: S_k \\sum_{i\n1}^k x_i, \n\nwhich is easily shown to be a Cauchy sequence, is convergent.\n\n*Parallelogram law: for ,  elements of ,\n\n: \\|x + y\\|^2 + \\|x - y\\|^2 = 2\\|x\\|^2 + 2\\|y\\|^2. \n\nThe Parallelogram law is, in fact, a necessary and sufficient condition for the existence of a scalar product corresponding to a given norm. If it holds, the scalar product is defined by the polarization identity:\n\n: \\|x + y\\|^2 = \\|x\\|^2 + \\|y\\|^2 + 2 \\real \\langle x , y \\rangle. \n\nwhich is a form of the law of cosines.\n\nOrthonormal sequences \n\nLet  be a finite dimensional inner product space of dimension . Recall that every basis of  consists of exactly  linearly independent vectors. Using the Gram–Schmidt process we may start with an arbitrary basis and transform it into an orthonormal basis. That is, into a basis in which all the elements are orthogonal and have unit norm. In symbols, a basis  is orthonormal if  for every  and  for each .\n\nThis definition of orthonormal basis generalizes to the case of infinite-dimensional inner product spaces in the following way. Let  be any inner product space. Then a collection\n\nE= \\left \\{e_{\\alpha} \\right \\}_{\\alpha \\in A}\n\nis a basis for  if the subspace of  generated by finite linear combinations of elements of  is dense in  (in the norm induced by the inner product). We say that  is an orthonormal basis for  if it is a basis and\n\n\\left \\langle e_{\\alpha}, e_{\\beta} \\right \\rangle=0\n\nif  and  for all .\n\nUsing an infinite-dimensional analog of the Gram-Schmidt process one may show:\n\nTheorem. Any separable inner product space  has an orthonormal basis.\n\nUsing the Hausdorff maximal principle and the fact that in a complete inner product space orthogonal projection onto linear subspaces is well-defined, one may also show that\n\nTheorem. Any complete inner product space  has an orthonormal basis.\n\nThe two previous theorems raise the question of whether all inner product spaces have an orthonormal basis. The answer, it turns out is negative. This is a non-trivial result, and is proved below. The following proof is taken from Halmos's A Hilbert Space Problem Book (see the references).\n\nParseval's identity leads immediately to the following theorem:\n\nTheorem. Let  be a separable inner product space and  an orthonormal basis of . Then the map\n x \\mapsto \\bigl\\{\\langle e_k, x\\rangle\\bigr\\}_{k \\in \\mathbb{N}} \nis an isometric linear map  with a dense image.\n\nThis theorem can be regarded as an abstract form of Fourier series, in which an arbitrary orthonormal basis plays the role of the sequence of trigonometric polynomials. Note that the underlying index set can be taken to be any countable set (and in fact any set whatsoever, provided  is defined appropriately, as is explained in the article Hilbert space). In particular, we obtain the following result in the theory of Fourier series:\n\nTheorem. Let  be the inner product space . Then the sequence (indexed on set of all integers) of continuous functions\n\ne_k(t) = \\frac{e^{i k t}}{\\sqrt{2 \\pi}}\n\nis an orthonormal basis of the space  with the  inner product. The mapping\n\n f \\mapsto \\frac{1}{\\sqrt{2 \\pi}} \\left\\{\\int_{-\\pi}^\\pi f(t) e^{-i k t} \\, \\mathrm{d}t \\right\\}_{k \\in \\mathbb{Z}} \n\nis an isometric linear map with dense image.\n\nOrthogonality of the sequence  follows immediately from the fact that if , then\n\n \\int_{-\\pi}^\\pi e^{-i (j-k) t} \\, \\mathrm{d}t = 0. \n\nNormality of the sequence is by design, that is, the coefficients are so chosen so that the norm comes out to 1. Finally the fact that the sequence has a dense algebraic span, in the inner product norm, follows from the fact that the sequence has a dense algebraic span, this time in the space of continuous periodic functions on  with the uniform norm. This is the content of the Weierstrass theorem on the uniform density of trigonometric polynomials.\n\nOperators on inner product spaces\n\nSeveral types of linear maps  from an inner product space  to an inner product space  are of relevance:\n* Continuous linear maps, i.e.,  is linear and continuous with respect to the metric defined above, or equivalently,  is linear and the set of non-negative reals",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Inner product space" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=14856" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "In linear algebra, an inner product space is a vector space with an additional structure called an inner product. This additional structure associates each pair of vectors in the space with a scalar quantity known as the inner product of the vectors. Inner products allow the rigorous introduction of intuitive geometrical notions such as the length of a vector or the angle between two vectors. They also provide the means of defining orthogonality between vectors (zero inner product). Inner product spaces generalize Euclidean spaces (in which the inner product is the dot product, also known as the scalar product) to vector spaces of any (possibly infinite) dimension, and are studied in functional analysis. The first usage of the concept of a vector space with an inner product is due to Peano, in 1898.\n\nAn inner product naturally induces an associated norm, thus an inner product space is also a normed vector space. A complete space with an inner product is called a Hilbert space. An (incomplete) space with an inner product is called a pre-Hilbert space, since its completion with respect to the norm induced by the inner product is a Hilbert space. Inner product spaces over the field of complex numbers are sometimes referred to as unitary spaces.\n\nDefinition \n\nIn this article, the field of scalars denoted  is either the field of real numbers  or the field of complex numbers .\n\nFormally, an inner product space is a vector space  over the field  together with an inner product, i.e., with a map\n \\langle \\cdot, \\cdot \\rangle : V \\times V \\to F \n\nthat satisfies the following three axioms for all vectors  and all scalars :\n\n* Conjugate symmetry:A bar over an expression denotes complex conjugation.\n:\\langle x,y\\rangle =\\overline{\\langle y,x\\rangle}\n\n* Linearity in the first argument:\n:\\begin{align}\n\\langle ax,y\\rangle &= a \\langle x,y\\rangle \\\\\n\\langle x+y,z\\rangle &= \\langle x,z\\rangle + \\langle y,z\\rangle\n\\end{align}\n\n* Positive-definiteness:\n:\\begin{align}\n\\langle x,x\\rangle &\\geq 0 \\\\\n\\langle x,x\\rangle &0 \\Leftrightarrow x \n \\mathbf{0} \\,.\n\\end{align}\n\nAlternative definitions, notations and remarks\n\nSome authors, especially in physics and matrix algebra, prefer to define the inner product and the sesquilinear form with linearity in the second argument rather than the first. Then the first argument becomes conjugate linear, rather than the second. In those disciplines we would write the product  as  (the bra–ket notation of quantum mechanics), respectively  (dot product as a case of the convention of forming the matrix product  as the dot products of rows of  with columns of ). Here the kets and columns are identified with the vectors of  and the bras and rows with the linear functionals (covectors) of the dual space , with conjugacy associated with duality. This reverse order is now occasionally followed in the more abstract literature, taking  to be conjugate linear in  rather than . A few instead find a middle ground by recognizing both  and  as distinct notations differing only in which argument is conjugate linear.\n\nThere are various technical reasons why it is necessary to restrict the basefield to  and  in the definition. Briefly, the basefield has to contain an ordered subfield in order for non-negativity to make sense,. and therefore has to have characteristic equal to 0 (since any ordered field has to have such characteristic). This immediately excludes finite fields. The basefield has to have additional structure, such as a distinguished automorphism. More generally any quadratically closed subfield of  or  will suffice for this purpose, e.g., the algebraic numbers or the constructible numbers. However in these cases when it is a proper subfield (i.e., neither  nor ) even finite-dimensional inner product spaces will fail to be metrically complete. In contrast all finite-dimensional inner product spaces over  or , such as those used in quantum computation, are automatically metrically complete and hence Hilbert spaces.\n\nIn some cases we need to consider non-negative semi-definite sesquilinear forms. This means that  is only required to be non-negative. We show how to treat these below.\n\nElementary properties \n\nWhen , conjugate symmetry reduces to symmetry. That is,  for ; while for ,  is equal to the complex conjugate.\n\nNotice that conjugate symmetry implies that  is real for all , since we have:\n\n\\langle x,x \\rangle = \\overline{\\langle x,x \\rangle} \\,.\n\nMoreover, sesquilinearity (see below) implies that\n\n \\langle -x,x \\rangle-1\\langle x,x\\rangle \n \\overline{-1}\\langle x,x\\rangle = \\langle x,-x\\rangle \\,.\n\nConjugate symmetry and linearity in the first variable gives\n\n\\begin{align}\n\\langle x, a y \\rangle &\\overline{\\langle a y, x \\rangle} \n \\overline{a} \\overline{\\langle y, x \\rangle} = \\overline{a} \\langle x, y \\rangle \\\\\n\\langle x, y + z \\rangle &\\overline{\\langle y + z, x \\rangle} \n \\overline{\\langle y, x \\rangle} + \\overline{\\langle z, x \\rangle} = \\langle x, y \\rangle + \\langle x, z \\rangle \\,,\n\\end{align}\n\nso an inner product is a sesquilinear form. Conjugate symmetry is also called Hermitian symmetry, and a conjugate symmetric sesquilinear form is called a Hermitian form. While the above axioms are more mathematically economical, a compact verbal definition of an inner product is a positive-definite Hermitian form.\n\nIn the case of , conjugate-symmetry reduces to symmetry, and sesquilinear reduces to bilinear. So, an inner product on a real vector space is a positive-definite symmetric bilinear form.\n\nFrom the linearity property it is derived that  implies . while from the positive-definiteness axiom we obtain the converse,  implies . Combining these two, we have the property that  if and only if .\n\nCombining the linearity of the inner product in its first argument and the conjugate symmetry gives the following important generalization of the familiar square expansion:\n\\langle x + y,x + y\\rangle = \\langle x,x\\rangle + \\langle x,y\\rangle + \\langle y,x\\rangle + \\langle y,y\\rangle \\,.\nAssuming the underlying field to be , the inner product becomes symmetric, and we obtain\n\\langle x \\pm y,x \\pm y\\rangle =\\langle x,x\\rangle \\pm 2\\langle x,y\\rangle + \\langle y,y\\rangle \\,,\nThe property of an inner product space  that\n\\begin{align}\n\\langle x+y,z\\rangle&= \\langle x,z\\rangle+ \\langle y,z\\rangle \\,, \\\\\n\\langle x,y+z\\rangle &= \\langle x,y\\rangle + \\langle x,z\\rangle\n\\end{align}\nis also known as additivity.\n\nExamples \n\nReal numbers\n\nA simple example is the real numbers with the standard multiplication as the inner product\n\\langle x,y\\rangle := x y.\n\nEuclidean space\n\nMore generally, the real -space  with the dot product is an inner product space, an example of a Euclidean -space.\n\\left\\langle \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix},\\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_n \\end{bmatrix} \\right\\rangle :x^\\mathsf{T} y \n \\sum_{i1}^n x_i y_i \n x_1 y_1 + \\cdots + x_n y_n,\nwhere  is the transpose of .\n\nComplex coordinate space\n\nThe general form of an inner product on  is known as the Hermitian form and is given by\n\\langle \\mathbf{x},\\mathbf{y}\\rangle :\\mathbf{y}^\\dagger\\mathbf{M}\\mathbf{x} \n \\overline{\\mathbf{x}^\\dagger\\mathbf{M}\\mathbf{y}},\nwhere  is any Hermitian positive-definite matrix and  is the conjugate transpose of . For the real case this corresponds to the dot product of the results of directionally different scaling of the two vectors, with positive scale factors and orthogonal directions of scaling. Up to an orthogonal transformation it is a weighted-sum version of the dot product, with positive weights.\n\nHilbert space\n\nThe article on Hilbert space has several examples of inner product spaces wherein the metric induced by the inner product yields a complete metric space. An example of an inner product which induces an incomplete metric occurs with the space  of continuous complex valued functions on the interval . The inner product is\n \\langle f , g \\rangle := \\int_a^b f(t) \\overline{g(t)} \\, \\mathrm{d}t. \nThis space is not complete; consider for example, for the interval  the sequence of continuous \"step\" functions, , defined by:\n f_k(t) = \\begin{cases} 0 & t \\in [-1,0] \\\\ 1 & t \\in \\left [\\tfrac{1}{k}, 1 \\right ] \\\\ kt & t \\in \\left (0, \\tfrac{1}{k} \\right) \\end{cases}\nThis sequence is a Cauchy sequence for the norm induced by the preceding inner product, which does not converge to a continuous function.\n\nRandom variables\n\nFor real random variables  and , the expected value of their product\n \\langle X, Y \\rangle := \\operatorname{E}(X Y) \nis an inner product. In this case,  if and only if  (i.e.,  almost surely). This definition of expectation as inner product can be extended to random vectors as well.\n\nReal matrices\n\nFor real matrices of the same size,  with transpose as conjugation\n \\left(\\langle A, B \\rangle = \\left\\langle B^\\mathrm{T}, A^\\mathrm{T} \\right\\rangle \\right)\nis an inner product.\n\nNorms on inner product spaces \n\nA linear space with a norm such as:\n\n\\|x\\|_p \\left ( \\sum_{i\n1}^{\\infty} \\left|\\xi_i \\right|^p \\right) ^{\\frac{1}{p}} \\qquad x = \\left \\{\\xi_i \\right \\} \\in l^p, \\quad p \\neq 2,\n\nis a normed space but not an inner product space, because this norm does not satisfy the parallelogram equality required of a norm to have an inner product associated with it.\n\nHowever, inner product spaces have a naturally defined norm based upon the inner product of the space itself that does satisfy the parallelogram equality:\n\n \\|x\\| =\\sqrt{\\langle x, x\\rangle}.\n\nThis is well defined by the nonnegativity axiom of the definition of inner product space. The norm is thought of as the length of the vector . Directly from the axioms, we can prove the following:\n\n*Cauchy–Schwarz inequality: for ,  elements of \n\n: |\\langle x,y\\rangle| \\leq \\|x\\| \\cdot \\|y\\| \n\nwith equality if and only if  and  are linearly dependent. This is one of the most important inequalities in mathematics. It is also known in the Russian mathematical literature as the Cauchy–Bunyakovsky–Schwarz inequality.\n\n*Orthogonality: The geometric interpretation of the inner product in terms of angle and length, motivates much of the geometric terminology we use in regard to these spaces. Indeed, an immediate consequence of the Cauchy–Schwarz inequality is that it justifies defining the angle between two non-zero vectors  and  (denoted ) in the case  by the identity\n\n:\\angle(x,y) = \\arccos \\frac{\\langle x, y \\rangle}{\\|x\\| \\cdot \\|y\\|}.\n\nWe assume the value of the angle is chosen to be in the interval . This is in analogy to the situation in two-dimensional Euclidean space.\n\nIn the case , the angle in the interval  is typically defined by\n\n:\\angle(x,y) = \\arccos \\frac{\\|x\\| \\cdot \\|y\\|}.\n\nCorrespondingly, we will say that non-zero vectors  and  of  are orthogonal if and only if their inner product is zero.\n\n*Homogeneity: for  an element of  and  a scalar\n\n: \\|r \\cdot x\\| = |r| \\cdot \\| x\\|.\n\nThe homogeneity property is completely trivial to prove.\n\n*Triangle inequality: for ,  elements of \n\n: \\|x + y\\| \\leq \\|x \\| + \\|y\\|. \n\nThe last two properties show the function defined is indeed a norm.\n\nBecause of the triangle inequality and because of axiom 2, we see that  is a norm which turns  into a normed vector space and hence also into a metric space. The most important inner product spaces are the ones which are complete with respect to this metric; they are called Hilbert spaces. Every inner product  space is a dense subspace of some Hilbert space. This Hilbert space is essentially uniquely determined by  and is constructed by completing .\n\n*Pythagorean theorem: Whenever ,  are in  and , then\n\n: \\|x\\|^2 + \\|y\\|^2 = \\|x+y\\|^2. \n\nThe proof of the identity requires only expressing the definition of norm in terms of the inner product and multiplying out, using the property of additivity of each component.\n\nThe name Pythagorean theorem arises from the geometric interpretation of this result as an analogue of the theorem in synthetic geometry. Note that the proof of the Pythagorean theorem in synthetic geometry is considerably more elaborate because of the paucity of underlying structure. In this sense, the synthetic Pythagorean theorem, if correctly demonstrated, is deeper than the version given above.\n\nAn induction on the Pythagorean theorem yields:\n\n*If  are orthogonal vectors, that is,  for distinct indices , , then\n\n: \\sum_{i1}^n \\|x_i\\|^2 \n \\left\\|\\sum_{i=1}^n x_i \\right\\|^2. \n\nIn view of the Cauchy-Schwarz inequality, we also note that  is continuous from  to . This allows us to extend Pythagoras' theorem to infinitely many summands:\n\n*Parseval's identity: Suppose  is a complete inner product space. If  are mutually orthogonal vectors in  then\n\n: \\sum_{i1}^\\infty\\|x_i\\|^2 \n \\left\\|\\sum_{i=1}^\\infty x_i\\right\\|^2, \n\nprovided the infinite series on the left is convergent. Completeness of the space is needed to ensure that the sequence of partial sums\n\n: S_k \\sum_{i\n1}^k x_i, \n\nwhich is easily shown to be a Cauchy sequence, is convergent.\n\n*Parallelogram law: for ,  elements of ,\n\n: \\|x + y\\|^2 + \\|x - y\\|^2 = 2\\|x\\|^2 + 2\\|y\\|^2. \n\nThe Parallelogram law is, in fact, a necessary and sufficient condition for the existence of a scalar product corresponding to a given norm. If it holds, the scalar product is defined by the polarization identity:\n\n: \\|x + y\\|^2 = \\|x\\|^2 + \\|y\\|^2 + 2 \\real \\langle x , y \\rangle. \n\nwhich is a form of the law of cosines.\n\nOrthonormal sequences \n\nLet  be a finite dimensional inner product space of dimension . Recall that every basis of  consists of exactly  linearly independent vectors. Using the Gram–Schmidt process we may start with an arbitrary basis and transform it into an orthonormal basis. That is, into a basis in which all the elements are orthogonal and have unit norm. In symbols, a basis  is orthonormal if  for every  and  for each .\n\nThis definition of orthonormal basis generalizes to the case of infinite-dimensional inner product spaces in the following way. Let  be any inner product space. Then a collection\n\nE= \\left \\{e_{\\alpha} \\right \\}_{\\alpha \\in A}\n\nis a basis for  if the subspace of  generated by finite linear combinations of elements of  is dense in  (in the norm induced by the inner product). We say that  is an orthonormal basis for  if it is a basis and\n\n\\left \\langle e_{\\alpha}, e_{\\beta} \\right \\rangle=0\n\nif  and  for all .\n\nUsing an infinite-dimensional analog of the Gram-Schmidt process one may show:\n\nTheorem. Any separable inner product space  has an orthonormal basis.\n\nUsing the Hausdorff maximal principle and the fact that in a complete inner product space orthogonal projection onto linear subspaces is well-defined, one may also show that\n\nTheorem. Any complete inner product space  has an orthonormal basis.\n\nThe two previous theorems raise the question of whether all inner product spaces have an orthonormal basis. The answer, it turns out is negative. This is a non-trivial result, and is proved below. The following proof is taken from Halmos's A Hilbert Space Problem Book (see the references).\n\nParseval's identity leads immediately to the following theorem:\n\nTheorem. Let  be a separable inner product space and  an orthonormal basis of . Then the map\n x \\mapsto \\bigl\\{\\langle e_k, x\\rangle\\bigr\\}_{k \\in \\mathbb{N}} \nis an isometric linear map  with a dense image.\n\nThis theorem can be regarded as an abstract form of Fourier series, in which an arbitrary orthonormal basis plays the role of the sequence of trigonometric polynomials. Note that the underlying index set can be taken to be any countable set (and in fact any set whatsoever, provided  is defined appropriately, as is explained in the article Hilbert space). In particular, we obtain the following result in the theory of Fourier series:\n\nTheorem. Let  be the inner product space . Then the sequence (indexed on set of all integers) of continuous functions\n\ne_k(t) = \\frac{e^{i k t}}{\\sqrt{2 \\pi}}\n\nis an orthonormal basis of the space  with the  inner product. The mapping\n\n f \\mapsto \\frac{1}{\\sqrt{2 \\pi}} \\left\\{\\int_{-\\pi}^\\pi f(t) e^{-i k t} \\, \\mathrm{d}t \\right\\}_{k \\in \\mathbb{Z}} \n\nis an isometric linear map with dense image.\n\nOrthogonality of the sequence  follows immediately from the fact that if , then\n\n \\int_{-\\pi}^\\pi e^{-i (j-k) t} \\, \\mathrm{d}t = 0. \n\nNormality of the sequence is by design, that is, the coefficients are so chosen so that the norm comes out to 1. Finally the fact that the sequence has a dense algebraic span, in the inner product norm, follows from the fact that the sequence has a dense algebraic span, this time in the space of continuous periodic functions on  with the uniform norm. This is the content of the Weierstrass theorem on the uniform density of trigonometric polynomials.\n\nOperators on inner product spaces\n\nSeveral types of linear maps  from an inner product space  to an inner product space  are of relevance:\n* Continuous linear maps, i.e.,  is linear and continuous with respect to the metric defined above, or equivalently,  is linear and the set of non-negative reals. Inner product space. http://en.wikipedia.org/?curid=14856."
  }
}
