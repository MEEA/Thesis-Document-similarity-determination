{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=10236",
  "eid" : "f47afcf0-52b1-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778489919,
  "textBody" : "The ELIZA effect, in computer science, is the tendency to unconsciously assume computer behaviors are analogous to human behaviors, that is anthropomorphisation.\n\nOverview\n\nIn its specific form, the ELIZA effect refers only to \"the susceptibility of people to read far more understanding than is warranted into strings of symbols — especially words — strung together by computers\". A trivial example of the specific form of the Eliza effect, given by Douglas Hofstadter, involves an automated teller machine which displays the words \"THANK YOU\" at the end of a transaction. A (very) casual observer might think that the machine is actually expressing gratitude; however, the machine is only printing a preprogrammed string of symbols.\n\nMore generally, the ELIZA effect describes any situation where, based solely on a system's output, users perceive computer systems as having \"intrinsic qualities and abilities which the software controlling the (output) cannot possibly achieve\" or \"assume that [outputs] reflect a greater causality than they actually do.\" In both its specific and general forms, the ELIZA effect is notable for occurring even when users of the system are aware of the determinate nature of output produced by the system. From a psychological standpoint, the ELIZA effect is the result of a subtle cognitive dissonance between the user's awareness of programming limitations and their behavior towards the output of the program. The discovery of the ELIZA effect was an important development in artificial intelligence, demonstrating the principle of using social engineering rather than explicit programming to pass a Turing test.\n\nOrigin\n\nThe effect is named for the 1966 chatterbot ELIZA, developed by MIT computer scientist Joseph Weizenbaum. When executing Weizenbaum's DOCTOR script, ELIZA parodied a Rogerian psychotherapist, largely by rephrasing the \"patient\"'s replies as questions:\n\nHuman: Well, my boyfriend made me come here.\nELIZA: Your boyfriend made you come here?\nHuman: He says I'm depressed much of the time.\nELIZA: I am sorry to hear you are depressed.\nHuman: It's true. I'm unhappy.\nELIZA: Do you think coming here will help you not to be unhappy?\n\nThough designed strictly as a mechanism to support \"natural language conversation\" with a computer, ELIZA's DOCTOR script was found to be surprisingly successful in eliciting emotional responses from users who, in the course of interacting with the program, began to ascribe understanding and motivation to the program's output. As Weizenbaum later wrote, \"I had not realized ... that extremely short exposures to a relatively simple computer program could induce powerful delusional thinking in quite normal people.\" Indeed, ELIZA's code had not been designed to evoke this reaction in the first place. Upon observation, researchers discovered users unconsciously assuming ELIZA's questions implied interest and emotional involvement in the topics discussed, even when they consciously knew that ELIZA did not simulate emotion.",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "ELIZA effect" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=10236" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "The ELIZA effect, in computer science, is the tendency to unconsciously assume computer behaviors are analogous to human behaviors, that is anthropomorphisation.\n\nOverview\n\nIn its specific form, the ELIZA effect refers only to \"the susceptibility of people to read far more understanding than is warranted into strings of symbols — especially words — strung together by computers\". A trivial example of the specific form of the Eliza effect, given by Douglas Hofstadter, involves an automated teller machine which displays the words \"THANK YOU\" at the end of a transaction. A (very) casual observer might think that the machine is actually expressing gratitude; however, the machine is only printing a preprogrammed string of symbols.\n\nMore generally, the ELIZA effect describes any situation where, based solely on a system's output, users perceive computer systems as having \"intrinsic qualities and abilities which the software controlling the (output) cannot possibly achieve\" or \"assume that [outputs] reflect a greater causality than they actually do.\" In both its specific and general forms, the ELIZA effect is notable for occurring even when users of the system are aware of the determinate nature of output produced by the system. From a psychological standpoint, the ELIZA effect is the result of a subtle cognitive dissonance between the user's awareness of programming limitations and their behavior towards the output of the program. The discovery of the ELIZA effect was an important development in artificial intelligence, demonstrating the principle of using social engineering rather than explicit programming to pass a Turing test.\n\nOrigin\n\nThe effect is named for the 1966 chatterbot ELIZA, developed by MIT computer scientist Joseph Weizenbaum. When executing Weizenbaum's DOCTOR script, ELIZA parodied a Rogerian psychotherapist, largely by rephrasing the \"patient\"'s replies as questions:\n\nHuman: Well, my boyfriend made me come here.\nELIZA: Your boyfriend made you come here?\nHuman: He says I'm depressed much of the time.\nELIZA: I am sorry to hear you are depressed.\nHuman: It's true. I'm unhappy.\nELIZA: Do you think coming here will help you not to be unhappy?\n\nThough designed strictly as a mechanism to support \"natural language conversation\" with a computer, ELIZA's DOCTOR script was found to be surprisingly successful in eliciting emotional responses from users who, in the course of interacting with the program, began to ascribe understanding and motivation to the program's output. As Weizenbaum later wrote, \"I had not realized ... that extremely short exposures to a relatively simple computer program could induce powerful delusional thinking in quite normal people.\" Indeed, ELIZA's code had not been designed to evoke this reaction in the first place. Upon observation, researchers discovered users unconsciously assuming ELIZA's questions implied interest and emotional involvement in the topics discussed, even when they consciously knew that ELIZA did not simulate emotion. ELIZA effect. http://en.wikipedia.org/?curid=10236."
  }
}
