{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=11617",
  "eid" : "fcb305c0-52b1-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778503708,
  "textBody" : "In theoretical physics, Feynman diagrams are pictorial representations of the mathematical expressions describing the behavior of subatomic particles. The scheme is named after its inventor, American physicist Richard Feynman, and was first introduced in 1948. The interaction of sub-atomic particles can be complex and difficult to understand intuitively. Feynman diagrams give a simple visualization of what would otherwise be an arcane and abstract formula. As David Kaiser writes, \"since the middle of the 20th century, theoretical physicists have increasingly turned to this tool to help them undertake critical calculations\", and so \"Feynman diagrams have revolutionized nearly every aspect of theoretical physics\". While the diagrams are applied primarily to quantum field theory, they can also be used in other fields, such as solid-state theory.\n\nFeynman used Ernst Stueckelberg's interpretation of the positron as if it were an electron moving backward in time. Thus, antiparticles are represented as moving backward along the time axis in Feynman diagrams.\n\nThe calculation of probability amplitudes in theoretical particle physics requires the use of rather large and complicated integrals over a large number of variables. These integrals do, however, have a regular structure, and may be represented graphically as Feynman diagrams.\n\nA Feynman diagram is a contribution of a particular class of particle paths, which join and split as described by the diagram. More precisely, and technically, a Feynman diagram is a graphical representation of a perturbative contribution to the transition amplitude or correlation function of a quantum mechanical or statistical field theory. Within the canonical formulation of quantum field theory, a Feynman diagram represents a term in the Wick's expansion of the perturbative -matrix. Alternatively, the path integral formulation of quantum field theory represents the transition amplitude as a weighted sum of all possible histories of the system from the initial to the final state, in terms of either particles or fields. The transition amplitude is then given as the matrix element of the -matrix between the initial and the final states of the quantum system.\n\nMotivation and history \n\nWhen calculating scattering cross-sections in particle physics, the interaction between particles can be described by starting from a free field that describes the incoming and outgoing particles, and including an interaction Hamiltonian to describe how the particles deflect one another. The amplitude for scattering is the sum of each possible interaction history over all possible intermediate particle states. The number of times the interaction Hamiltonian acts is the order of the perturbation expansion, and the time-dependent perturbation theory for fields is known as the Dyson series. When the intermediate states at intermediate times are energy eigenstates (collections of particles with a definite momentum) the series is called old-fashioned perturbation theory.\n\nThe Dyson series can be alternatively rewritten as a sum over Feynman diagrams, where at each vertex both the energy and momentum are conserved, but where the length of the energy-momentum four-vector is not necessarily equal to the mass. The Feynman diagrams are much easier to keep track of than old-fashioned terms, because the old-fashioned way treats the particle and antiparticle contributions as separate. Each Feynman diagram is the sum of exponentially many old-fashioned terms, because each internal line can separately represent either a particle or an antiparticle. In a non-relativistic theory, there are no antiparticles and there is no doubling, so each Feynman diagram includes only one term.\n\nFeynman gave a prescription for calculating the amplitude for any given diagram from a field theory Lagrangian—the Feynman rules. Each internal line corresponds to a factor of the virtual particle's propagator; each vertex where lines meet gives a factor derived from an interaction term in the Lagrangian, and incoming and outgoing lines carry an energy, momentum, and spin.\n\nIn addition to their value as a mathematical tool, Feynman diagrams provide deep physical insight into the nature of particle interactions. Particles interact in every way available; in fact, intermediate virtual particles are allowed to propagate faster than light. The probability of each final state is then obtained by summing over all such possibilities. This is closely tied to the functional integral formulation of quantum mechanics, also invented by Feynman–see path integral formulation.\n\nThe naïve application of such calculations often produces diagrams whose amplitudes are infinite, because the short-distance particle interactions require a careful limiting procedure, to include particle self-interactions. The technique of renormalization, suggested by Ernst Stueckelberg and Hans Bethe and implemented by Dyson, Feynman, Schwinger, and Tomonaga compensates for this effect and eliminates the troublesome infinities. After renormalization, calculations using Feynman diagrams match experimental results with very high accuracy.\n\nFeynman diagram and path integral methods are also used in statistical mechanics and can even be applied to classical mechanics.\n\nAlternative names \n\nMurray Gell-Mann always referred to Feynman diagrams as Stueckelberg diagrams, after a Swiss physicist, Ernst Stueckelberg, who devised a similar notation many years earlier. Stueckelberg was motivated by the need for a manifestly covariant formalism for quantum field theory, but did not provide as automated a way to handle symmetry factors and loops, although he was first to find the correct physical interpretation in terms of forward and backward in time particle paths, all without the path-integral. \n\nHistorically, as a book-keeping device of covariant perturbation theory, the graphs were called Feynman–Dyson diagrams or Dyson graphs,Gribbin, John and Mary. Richard Feynman: A Life in Science, Penguin-Putnam, 1997 Ch 5. because when they were introduced, the path integral was unfamiliar, and Freeman Dyson's derivation from old-fashioned perturbation theory was easier to follow for physicists trained in earlier methods.\"It was Dyson's contribution to indicate how Feynman's visual insights could be used [...] He realized that Feynman diagrams [...] can also be viewed as a representation of the logical content of field theories (as stated in their perturbative expansions)\". Schwebber, op.cit (1994) Feynman had to lobby hard for the diagrams, which confused the establishment physicists trained in equations and graphs.Leonard Mlodinow. Feynman's Rainbow. Vintage, 2011. p. 29\n\nRepresentation of physical reality \n\nIn their presentations of fundamental interactions,Gerardus 't Hooft, Martinus Veltman, Diagrammar, CERN Yellow Report 1973, reprinted in G. 't Hooft, Under the Spell of Gauge Principle (World Scientific, Singapore, 1994), Introduction [http://preprints.cern.ch/cgi-bin/setlink?basecernrep&categ\nYellow_Report&id=1973-009 online]Martinus Veltman, Diagrammatica: The Path to Feynman Diagrams, Cambridge Lecture Notes in Physics,  written from the particle physics perspective, Gerard 't Hooft and Martinus Veltman gave good arguments for taking the original, non-regularized Feynman diagrams as the most succinct representation of our present knowledge about the physics of quantum scattering of fundamental particles. Their motivations are consistent with the convictions of James Daniel Bjorken and Sidney Drell:\n\nThe Feynman graphs and rules of calculation summarize quantum field theory in a form in close contact with the experimental numbers one wants to understand. Although the statement of the theory in terms of graphs may imply perturbation theory, use of graphical methods in the many-body problem shows that this formalism is flexible enough to deal with phenomena of nonperturbative characters … Some modification of the Feynman rules of calculation may well outlive the elaborate mathematical structure of local canonical quantum field theory …\n\nSo far there are no opposing opinions. In quantum field theories the Feynman diagrams are obtained from Lagrangian by Feynman rules.\n\nDimensional regularization is a method for regularizing integrals in the evaluation of Feynman diagrams; it assigns values to them that are meromorphic functions of an auxiliary complex parameter , called the dimension.  Dimensional regularization writes a Feynman integral as an integral depending on the spacetime dimension  and spacetime points.\n\nParticle-path interpretation \n\nA Feynman diagram is a representation of quantum field theory processes in terms of particle paths. The particle trajectories are represented by the lines of the diagram, which can be squiggly or straight, with an arrow or without, depending on the type of particle. A point where lines connect to other lines is a vertex, and this is where the particles meet and interact: by emitting or absorbing new particles, deflecting one another, or changing type.\n\nThere are three different types of lines: internal lines connect two vertices, incoming lines extend from \"the past\" to a vertex and represent an initial state, and outgoing lines extend from a vertex to \"the future\" and represent the final state (the latter two are also known as external lines). Sometimes, the bottom of the diagram is the past and the top the future; other times, the past is to the left and the future to the right. When calculating correlation functions instead of scattering amplitudes, there is no past and future and all the lines are internal. The particles then begin and end on little x's, which represent the positions of the operators whose correlation is being calculated.\n\nFeynman diagrams are a pictorial representation of a contribution to the total amplitude for a process that can happen in several different ways. When a group of incoming particles are to scatter off each other, the process can be thought of as one where the particles travel over all possible paths, including paths that go backward in time.\n\nFeynman diagrams are often confused with spacetime diagrams and bubble chamber images because they all describe particle scattering. Feynman diagrams are graphs that represent the trajectories of particles in intermediate stages of a scattering process. Unlike a bubble chamber picture, only the sum of all the Feynman diagrams represent any given particle interaction; particles do not choose a particular diagram each time they interact. The law of summation is in accord with the principle of superposition—every diagram contributes to the total amplitude for the process.\n\nDescription \n\nA Feynman diagram represents a perturbative contribution to the amplitude of a quantum transition from some initial quantum state to some final quantum state.\n\nFor example, in the process of electron-positron annihilation the initial state is one electron and one positron, the final state: two photons.\n\nThe initial state is often assumed to be at the left of the diagram and the final state at the right (although other conventions are also used quite often).\n\nA Feynman diagram consists of points, called vertices, and lines attached to the vertices.\n\nThe particles in the initial state are depicted by lines sticking out in the direction of the initial state (e.g., to the left), the particles in the final state are represented by lines sticking out in the direction of the final state (e.g., to the right).\n\nIn QED there are two types of particles: electrons/positrons (called fermions) and photons (called gauge bosons). They are represented in Feynman diagrams as follows:\n# Electron in the initial state is represented by a solid line with an arrow pointing toward the vertex (→•).\n# Electron in the final state is represented by a line with an arrow pointing away from the vertex: (•→).\n# Positron in the initial state is represented by a solid line with an arrow pointing away from the vertex: (←•).\n# Positron in the final state is represented by a line with an arrow pointing toward the vertex: (•←).\n# Photon in the initial and the final state is represented by a wavy line (~• and •~).\n\nIn QED a vertex always has three lines attached to it: one bosonic line, one fermionic line with arrow toward the vertex, and one fermionic line with arrow away from the vertex.\n\nThe vertices might be connected by a bosonic or fermionic propagator. A bosonic propagator is represented by a wavy line connecting two vertices (•~•). A fermionic propagator is represented by a solid line (with an arrow in one or another direction) connecting two vertices, (•←•).\n\nThe number of vertices gives the order of the term in the perturbation series expansion of the transition amplitude.\n\nElectron–positron annihilation example \n\nThe electron–positron annihilation interaction:\n\ne+ e− → 2γ\n\nhas a contribution from the second order Feynman diagram shown adjacent:\n\nIn the initial state (at the bottom; early time) there is one electron (e−) and one positron (e+) and in the final state (at the top; late time) there are two photons (γ).\n\nCanonical quantization formulation \n\nThe probability amplitude for a transition of a quantum system from the initial state  to the final state  is given by the matrix element\n\nS_{fi}=\\langle f|S|i\\rangle\\;,\n\nwhere  is the -matrix.\n\nIn the canonical quantum field theory the -matrix is represented within the interaction picture by the perturbation series in the powers of the interaction Lagrangian,\n\nS\\sum_{n\n0}^{\\infty}\\frac{i^n}{n!}\\int\\prod_{j1}^n d^4 x_j T\\prod_{j\n1}^n L_v\\left(x_j\\right)\\equiv\\sum_{n=0}^{\\infty}S^{(n)}\\;,\n\nwhere  is the interaction Lagrangian and  signifies the time-ordered product of operators.\n\nA Feynman diagram is a graphical representation of a term in the Wick's expansion of the time-ordered product in the th order term  of the -matrix,\n\nT\\prod_{j1}^nL_v\\left(x_j\\right)\n\\sum_{\\text{all possible} \\atop \\text{contractions}}(\\pm)N\\prod_{j=1}^nL_v\\left(x_j\\right)\\;,\n\nwhere  signifies the normal-product of the operators and (±) takes care of the possible sign change when commuting the fermionic operators to bring them together for a contraction (a propagator).\n\nFeynman rules \n\nThe diagrams are drawn according to the Feynman rules, which depend upon the interaction Lagrangian. For the QED interaction Lagrangian\nL_v=-g\\bar\\psi\\gamma^\\mu\\psi A_\\mu\ndescribing the interaction of a fermionic field  with a bosonic gauge field , the Feynman rules can be formulated in coordinate space as follows:\n\n# Each integration coordinate  is represented by a point (sometimes called a vertex);\n# A bosonic propagator is represented by a wiggly line connecting two points;\n# A fermionic propagator is represented by a solid line connecting two points;\n# A bosonic field A_\\mu(x_i) is represented by a wiggly line attached to the point ;\n# A fermionic field  is represented by a solid line attached to the point  with an arrow toward the point;\n# An anti-fermionic field  is represented by a solid line attached to the point  with an arrow away from the point;\n\nExample: second order processes in QED \n\nThe second order perturbation term in the -matrix is\n\nS^{(2)}=\\frac{(ie)^2}{2!}\\int d^4x\\, d^4x'\\, T\\bar\\psi(x)\\,\\gamma^\\mu\\,\\psi(x)\\,A_\\mu(x)\\,\\bar\\psi(x')\\,\\gamma^\\nu\\,\\psi(x')\\,A_\\nu(x').\\;\n\nScattering of fermions \n\n    \nThe Wick's expansion of the integrand gives (among others) the following term\n\nN\\bar\\psi(x)\\gamma^\\mu\\psi(x)\\bar\\psi(x')\\gamma^\\nu\\psi(x')\\underline{A_\\mu(x)A_\\nu(x')}\\;,\n\nwhere\n\n\\underline{A_\\mu(x)A_\\nu(x')}=\\int\\frac{d^4k}{(2\\pi)^4}\\frac{-ig_{\\mu\\nu}}{k^2+i0}e^{-ik(x-x')}\n\nis the electromagnetic contraction (propagator) in the Feynman gauge. This term is represented by the Feynman diagram at the right. This diagram gives contributions to the following processes:\n# e− e− scattering (initial state at the right, final state at the left of the diagram);\n# e+ e+ scattering (initial state at the left, final state at the right of the diagram);\n# e− e+ scattering (initial state at the bottom/top, final state at the top/bottom of the diagram).\n\nCompton scattering and annihilation/generation of e− e+ pairs \n\nAnother interesting term in the expansion is\n\nN\\bar\\psi(x)\\,\\gamma^\\mu\\,\\underline{\\psi(x)\\,\\bar\\psi(x')}\\,\\gamma^\\nu\\,\\psi(x')\\,A_\\mu(x)\\,A_\\nu(x')\\;,\n\nwhere\n\n\\underline{\\psi(x)\\bar\\psi(x')}=\\int\\frac{d^4p}{(2\\pi)^4}\\frac{i}{\\gamma p-m+i0}e^{-ip(x-x')}\n\nis the fermionic contraction (propagator).\n\nPath integral formulation \n\nIn a path integral, the field Lagrangian, integrated over all possible field histories, defines the probability amplitude to go from one field configuration to another. In order to make sense, the field theory should have a well-defined ground state, and the integral should be performed a little bit rotated into imaginary time, i.e. a Wick rotation.\n\nScalar field Lagrangian \n\nA simple example is the free relativistic scalar field in  dimensions, whose action integral is:\n S = \\int \\tfrac12 \\partial_\\mu \\phi \\partial^\\mu \\phi\\, d^dx \\,.\n\nThe probability amplitude for a process is:\n\n \\int_A^B e^{iS}\\, D\\phi\\,, \n\nwhere  and  are space-like hypersurfaces that define the boundary conditions. The collection of all the  on the starting hypersurface give the initial value of the field, analogous to the starting position for a point particle, and the field values  at each point of the final hypersurface defines the final field value, which is allowed to vary, giving a different amplitude to end up at different values. This is the field-to-field transition amplitude.\n\nThe path integral gives the expectation value of operators between the initial and final state:\n\n \\int_A^B e^{iS} \\phi(x_1) \\cdots \\phi(x_n) \\,D\\phi = \\left\\langle A\\left| \\phi(x_1) \\cdots \\phi(x_n) \\right|B \\right\\rangle\\,,\n\nand in the limit that A and B recede to the infinite past and the infinite future, the only contribution that matters is from the ground state (this is only rigorously true if the path-integral is defined slightly rotated into imaginary time). The path integral can be thought of as analogous to a probability distribution, and it is convenient to define it so that multiplying by a constant doesn't change anything:\n\n \\frac{\\displaystyle\\int e^{iS} \\phi(x_1) \\cdots \\phi(x_n) \\,D\\phi }{ \\displaystyle\\int e^{iS} \\,D\\phi } = \\left\\langle 0 \\left| \\phi(x_1) \\cdots \\phi(x_n) \\right|0\\right\\rangle \\,.\n\nThe normalization factor on the bottom is called the partition function for the field, and it coincides with the statistical mechanical partition function at zero temperature when rotated into imaginary time.\n\nThe initial-to-final amplitudes are ill-defined if one thinks of the continuum limit right from the beginning, because the fluctuations in the field can become unbounded. So the path-integral can be thought of as on a discrete square lattice, with lattice spacing  and the limit  should be taken carefully. If the final results do not depend on the shape of the lattice or the value of , then the continuum limit exists.\n\nOn a lattice \n\nOn a lattice, (i), the field can be expanded in Fourier modes:\n\\phi(x) \\int \\frac{dk}{(2\\pi)^d} \\phi(k) e^{ik\\cdot x} \n \\int_k \\phi(k) e^{ikx}\\,.\n\nHere the integration domain is over  restricted to a cube of side length , so that large values of  are not allowed. It is important to note that the -measure contains the factors of 2 from Fourier transforms, this is the best standard convention for -integrals in QFT. The lattice means that fluctuations at large  are not allowed to contribute right away, they only start to contribute in the limit . Sometimes, instead of a lattice, the field modes are just cut off at high values of  instead.\n\nIt is also convenient from time to time to consider the space-time volume to be finite, so that the  modes are also a lattice. This is not strictly as necessary as the space-lattice limit, because interactions in  are not localized, but it is convenient for keeping track of the factors in front of the -integrals and the momentum-conserving delta functions that will arise.\n\nOn a lattice, (ii), the action needs to be discretized:\n S= \\sum_{\\langle x,y\\rangle} \\tfrac12 \\big(\\phi(x) - \\phi(y) \\big)^2\\,,\n\nwhere  is a pair of nearest lattice neighbors  and . The discretization should be thought of as defining what the derivative  means.\n\nIn terms of the lattice Fourier modes, the action can be written:\nS= \\int_k \\Big( \\big(1-\\cos(k_1)\\big) +\\big(1-\\cos(k_2)\\big) + \\cdots + \\big(1-\\cos(k_d)\\big) \\Big)\\phi^*_k \\phi^k\\,.\nFor  near zero this is:\nS = \\int_k \\tfrac12 k^2 \\left|\\phi(k)\\right|^2\\,.\n\nNow we have the continuum Fourier transform of the original action. In finite volume, the quantity  is not infinitesimal, but becomes the volume of a box made by neighboring Fourier modes, or .\n\nThe field  is real-valued, so the Fourier transform obeys:\n\n \\phi(k)^* = \\phi(-k)\\,.\n\nIn terms of real and imaginary parts, the real part of  is an even function of , while the imaginary part is odd. The Fourier transform avoids double-counting, so that it can be written:\n\n S = \\int_k \\tfrac12 k^2 \\phi(k) \\phi(-k)\n\nover an integration domain that integrates over each pair  exactly once.\n\nFor a complex scalar field with action\n\n S = \\int \\tfrac12 \\partial_\\mu\\phi^* \\partial^\\mu\\phi \\,d^dx\n\nthe Fourier transform is unconstrained:\n\n S = \\int_k \\tfrac12 k^2 \\left|\\phi(k)\\right|^2\n\nand the integral is over all .\n\nIntegrating over all different values of  is equivalent to integrating over all Fourier modes, because taking a Fourier transform is a unitary linear transformation of field coordinates. When you change coordinates in a multidimensional integral by a linear transformation, the value of the new integral is given by the determinant of the transformation matrix. If\n y_i = A_{ij} x_j\\,,\n\nthen\n\\det(A) \\int dx_1\\, dx_2 \\cdots\\, dx_n = \\int dy_1\\, dy_2 \\cdots\\, dy_n\\,.\n\nIf  is a rotation, then\nA^\\mathrm{T} A = I\nso that , and the sign depends on whether the rotation includes a reflection or not.\n\nThe matrix that changes coordinates from  to  can be read off from the definition of a Fourier transform.\n\n A_{kx} = e^{ikx} \\,\n\nand the Fourier inversion theorem tells you the inverse:\n\n A^{-1}_{kx} = e^{-ikx} \\,\n\nwhich is the complex conjugate-transpose, up to factors of 2. On a finite volume lattice, the determinant is nonzero and independent of the field values.\n \\det A = 1 \\,\n\nand the path integral is a separate factor at each value of .\n\n \\int \\exp \\left(\\frac{i}{2} \\sum_k k^2 \\phi^*(k) \\phi(k) \\right)\\, D\\phi = \\prod_k \\int_{\\phi_k} e^{\\frac{i}{2} k^2 \\left|\\phi_k \\right|^2\\, d^dk} \\,\n\nThe factor  is the infinitesimal volume of a discrete cell in -space, in a square lattice box\nd^dk = \\left(\\frac{1}{L}\\right)^d\\,,\nwhere  is the side-length of the box. Each separate factor is an oscillatory Gaussian, and the width of the Gaussian diverges as the volume goes to infinity.\n\nIn imaginary time, the Euclidean action becomes positive definite, and can be interpreted as a probability distribution. The probability of a field having values  is\n e^{\\int_k - \\tfrac12 k^2 \\phi^*_k \\phi_k} = \\prod_k e^{- k^2 \\left|\\phi_k\\right|^2\\, d^dk}\\,. \n\nThe expectation value of the field is the statistical expectation value of the field when chosen according to the probability distribution:\n\n\\left\\langle \\phi(x_1) \\cdots \\phi(x_n) \\right\\rangle = \\frac{ \\displaystyle\\int e^{-S} \\phi(x_1) \\cdots \\phi(x_n)\\, D\\phi} {\\displaystyle\\int e^{-S}\\, D\\phi}\n\nSince the probability of  is a product, the value of  at each separate value of  is independently Gaussian distributed. The variance of the Gaussian is , which is formally infinite, but that just means that the fluctuations are unbounded in infinite volume. In any finite volume, the integral is replaced by a discrete sum, and the variance of the integral is .\n\nMonte Carlo \n\nThe path integral defines a probabilistic algorithm to generate a Euclidean scalar field configuration. Randomly pick the real and imaginary parts of each Fourier mode at wavenumber  to be a Gaussian random variable with variance . This generates a configuration  at random, and the Fourier transform gives . For real scalar fields, the algorithm must generate only one of each pair , and make the second the complex conjugate of the first.\n\nTo find any correlation function, generate a field again and again by this procedure, and find the statistical average:\n\n \\left\\langle \\phi(x_1) \\cdots \\phi(x_n) \\right\\rangle = \\lim_",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Feynman diagram" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=11617" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "In theoretical physics, Feynman diagrams are pictorial representations of the mathematical expressions describing the behavior of subatomic particles. The scheme is named after its inventor, American physicist Richard Feynman, and was first introduced in 1948. The interaction of sub-atomic particles can be complex and difficult to understand intuitively. Feynman diagrams give a simple visualization of what would otherwise be an arcane and abstract formula. As David Kaiser writes, \"since the middle of the 20th century, theoretical physicists have increasingly turned to this tool to help them undertake critical calculations\", and so \"Feynman diagrams have revolutionized nearly every aspect of theoretical physics\". While the diagrams are applied primarily to quantum field theory, they can also be used in other fields, such as solid-state theory.\n\nFeynman used Ernst Stueckelberg's interpretation of the positron as if it were an electron moving backward in time. Thus, antiparticles are represented as moving backward along the time axis in Feynman diagrams.\n\nThe calculation of probability amplitudes in theoretical particle physics requires the use of rather large and complicated integrals over a large number of variables. These integrals do, however, have a regular structure, and may be represented graphically as Feynman diagrams.\n\nA Feynman diagram is a contribution of a particular class of particle paths, which join and split as described by the diagram. More precisely, and technically, a Feynman diagram is a graphical representation of a perturbative contribution to the transition amplitude or correlation function of a quantum mechanical or statistical field theory. Within the canonical formulation of quantum field theory, a Feynman diagram represents a term in the Wick's expansion of the perturbative -matrix. Alternatively, the path integral formulation of quantum field theory represents the transition amplitude as a weighted sum of all possible histories of the system from the initial to the final state, in terms of either particles or fields. The transition amplitude is then given as the matrix element of the -matrix between the initial and the final states of the quantum system.\n\nMotivation and history \n\nWhen calculating scattering cross-sections in particle physics, the interaction between particles can be described by starting from a free field that describes the incoming and outgoing particles, and including an interaction Hamiltonian to describe how the particles deflect one another. The amplitude for scattering is the sum of each possible interaction history over all possible intermediate particle states. The number of times the interaction Hamiltonian acts is the order of the perturbation expansion, and the time-dependent perturbation theory for fields is known as the Dyson series. When the intermediate states at intermediate times are energy eigenstates (collections of particles with a definite momentum) the series is called old-fashioned perturbation theory.\n\nThe Dyson series can be alternatively rewritten as a sum over Feynman diagrams, where at each vertex both the energy and momentum are conserved, but where the length of the energy-momentum four-vector is not necessarily equal to the mass. The Feynman diagrams are much easier to keep track of than old-fashioned terms, because the old-fashioned way treats the particle and antiparticle contributions as separate. Each Feynman diagram is the sum of exponentially many old-fashioned terms, because each internal line can separately represent either a particle or an antiparticle. In a non-relativistic theory, there are no antiparticles and there is no doubling, so each Feynman diagram includes only one term.\n\nFeynman gave a prescription for calculating the amplitude for any given diagram from a field theory Lagrangian—the Feynman rules. Each internal line corresponds to a factor of the virtual particle's propagator; each vertex where lines meet gives a factor derived from an interaction term in the Lagrangian, and incoming and outgoing lines carry an energy, momentum, and spin.\n\nIn addition to their value as a mathematical tool, Feynman diagrams provide deep physical insight into the nature of particle interactions. Particles interact in every way available; in fact, intermediate virtual particles are allowed to propagate faster than light. The probability of each final state is then obtained by summing over all such possibilities. This is closely tied to the functional integral formulation of quantum mechanics, also invented by Feynman–see path integral formulation.\n\nThe naïve application of such calculations often produces diagrams whose amplitudes are infinite, because the short-distance particle interactions require a careful limiting procedure, to include particle self-interactions. The technique of renormalization, suggested by Ernst Stueckelberg and Hans Bethe and implemented by Dyson, Feynman, Schwinger, and Tomonaga compensates for this effect and eliminates the troublesome infinities. After renormalization, calculations using Feynman diagrams match experimental results with very high accuracy.\n\nFeynman diagram and path integral methods are also used in statistical mechanics and can even be applied to classical mechanics.\n\nAlternative names \n\nMurray Gell-Mann always referred to Feynman diagrams as Stueckelberg diagrams, after a Swiss physicist, Ernst Stueckelberg, who devised a similar notation many years earlier. Stueckelberg was motivated by the need for a manifestly covariant formalism for quantum field theory, but did not provide as automated a way to handle symmetry factors and loops, although he was first to find the correct physical interpretation in terms of forward and backward in time particle paths, all without the path-integral. \n\nHistorically, as a book-keeping device of covariant perturbation theory, the graphs were called Feynman–Dyson diagrams or Dyson graphs,Gribbin, John and Mary. Richard Feynman: A Life in Science, Penguin-Putnam, 1997 Ch 5. because when they were introduced, the path integral was unfamiliar, and Freeman Dyson's derivation from old-fashioned perturbation theory was easier to follow for physicists trained in earlier methods.\"It was Dyson's contribution to indicate how Feynman's visual insights could be used [...] He realized that Feynman diagrams [...] can also be viewed as a representation of the logical content of field theories (as stated in their perturbative expansions)\". Schwebber, op.cit (1994) Feynman had to lobby hard for the diagrams, which confused the establishment physicists trained in equations and graphs.Leonard Mlodinow. Feynman's Rainbow. Vintage, 2011. p. 29\n\nRepresentation of physical reality \n\nIn their presentations of fundamental interactions,Gerardus 't Hooft, Martinus Veltman, Diagrammar, CERN Yellow Report 1973, reprinted in G. 't Hooft, Under the Spell of Gauge Principle (World Scientific, Singapore, 1994), Introduction [http://preprints.cern.ch/cgi-bin/setlink?basecernrep&categ\nYellow_Report&id=1973-009 online]Martinus Veltman, Diagrammatica: The Path to Feynman Diagrams, Cambridge Lecture Notes in Physics,  written from the particle physics perspective, Gerard 't Hooft and Martinus Veltman gave good arguments for taking the original, non-regularized Feynman diagrams as the most succinct representation of our present knowledge about the physics of quantum scattering of fundamental particles. Their motivations are consistent with the convictions of James Daniel Bjorken and Sidney Drell:\n\nThe Feynman graphs and rules of calculation summarize quantum field theory in a form in close contact with the experimental numbers one wants to understand. Although the statement of the theory in terms of graphs may imply perturbation theory, use of graphical methods in the many-body problem shows that this formalism is flexible enough to deal with phenomena of nonperturbative characters … Some modification of the Feynman rules of calculation may well outlive the elaborate mathematical structure of local canonical quantum field theory …\n\nSo far there are no opposing opinions. In quantum field theories the Feynman diagrams are obtained from Lagrangian by Feynman rules.\n\nDimensional regularization is a method for regularizing integrals in the evaluation of Feynman diagrams; it assigns values to them that are meromorphic functions of an auxiliary complex parameter , called the dimension.  Dimensional regularization writes a Feynman integral as an integral depending on the spacetime dimension  and spacetime points.\n\nParticle-path interpretation \n\nA Feynman diagram is a representation of quantum field theory processes in terms of particle paths. The particle trajectories are represented by the lines of the diagram, which can be squiggly or straight, with an arrow or without, depending on the type of particle. A point where lines connect to other lines is a vertex, and this is where the particles meet and interact: by emitting or absorbing new particles, deflecting one another, or changing type.\n\nThere are three different types of lines: internal lines connect two vertices, incoming lines extend from \"the past\" to a vertex and represent an initial state, and outgoing lines extend from a vertex to \"the future\" and represent the final state (the latter two are also known as external lines). Sometimes, the bottom of the diagram is the past and the top the future; other times, the past is to the left and the future to the right. When calculating correlation functions instead of scattering amplitudes, there is no past and future and all the lines are internal. The particles then begin and end on little x's, which represent the positions of the operators whose correlation is being calculated.\n\nFeynman diagrams are a pictorial representation of a contribution to the total amplitude for a process that can happen in several different ways. When a group of incoming particles are to scatter off each other, the process can be thought of as one where the particles travel over all possible paths, including paths that go backward in time.\n\nFeynman diagrams are often confused with spacetime diagrams and bubble chamber images because they all describe particle scattering. Feynman diagrams are graphs that represent the trajectories of particles in intermediate stages of a scattering process. Unlike a bubble chamber picture, only the sum of all the Feynman diagrams represent any given particle interaction; particles do not choose a particular diagram each time they interact. The law of summation is in accord with the principle of superposition—every diagram contributes to the total amplitude for the process.\n\nDescription \n\nA Feynman diagram represents a perturbative contribution to the amplitude of a quantum transition from some initial quantum state to some final quantum state.\n\nFor example, in the process of electron-positron annihilation the initial state is one electron and one positron, the final state: two photons.\n\nThe initial state is often assumed to be at the left of the diagram and the final state at the right (although other conventions are also used quite often).\n\nA Feynman diagram consists of points, called vertices, and lines attached to the vertices.\n\nThe particles in the initial state are depicted by lines sticking out in the direction of the initial state (e.g., to the left), the particles in the final state are represented by lines sticking out in the direction of the final state (e.g., to the right).\n\nIn QED there are two types of particles: electrons/positrons (called fermions) and photons (called gauge bosons). They are represented in Feynman diagrams as follows:\n# Electron in the initial state is represented by a solid line with an arrow pointing toward the vertex (→•).\n# Electron in the final state is represented by a line with an arrow pointing away from the vertex: (•→).\n# Positron in the initial state is represented by a solid line with an arrow pointing away from the vertex: (←•).\n# Positron in the final state is represented by a line with an arrow pointing toward the vertex: (•←).\n# Photon in the initial and the final state is represented by a wavy line (~• and •~).\n\nIn QED a vertex always has three lines attached to it: one bosonic line, one fermionic line with arrow toward the vertex, and one fermionic line with arrow away from the vertex.\n\nThe vertices might be connected by a bosonic or fermionic propagator. A bosonic propagator is represented by a wavy line connecting two vertices (•~•). A fermionic propagator is represented by a solid line (with an arrow in one or another direction) connecting two vertices, (•←•).\n\nThe number of vertices gives the order of the term in the perturbation series expansion of the transition amplitude.\n\nElectron–positron annihilation example \n\nThe electron–positron annihilation interaction:\n\ne+ e− → 2γ\n\nhas a contribution from the second order Feynman diagram shown adjacent:\n\nIn the initial state (at the bottom; early time) there is one electron (e−) and one positron (e+) and in the final state (at the top; late time) there are two photons (γ).\n\nCanonical quantization formulation \n\nThe probability amplitude for a transition of a quantum system from the initial state  to the final state  is given by the matrix element\n\nS_{fi}=\\langle f|S|i\\rangle\\;,\n\nwhere  is the -matrix.\n\nIn the canonical quantum field theory the -matrix is represented within the interaction picture by the perturbation series in the powers of the interaction Lagrangian,\n\nS\\sum_{n\n0}^{\\infty}\\frac{i^n}{n!}\\int\\prod_{j1}^n d^4 x_j T\\prod_{j\n1}^n L_v\\left(x_j\\right)\\equiv\\sum_{n=0}^{\\infty}S^{(n)}\\;,\n\nwhere  is the interaction Lagrangian and  signifies the time-ordered product of operators.\n\nA Feynman diagram is a graphical representation of a term in the Wick's expansion of the time-ordered product in the th order term  of the -matrix,\n\nT\\prod_{j1}^nL_v\\left(x_j\\right)\n\\sum_{\\text{all possible} \\atop \\text{contractions}}(\\pm)N\\prod_{j=1}^nL_v\\left(x_j\\right)\\;,\n\nwhere  signifies the normal-product of the operators and (±) takes care of the possible sign change when commuting the fermionic operators to bring them together for a contraction (a propagator).\n\nFeynman rules \n\nThe diagrams are drawn according to the Feynman rules, which depend upon the interaction Lagrangian. For the QED interaction Lagrangian\nL_v=-g\\bar\\psi\\gamma^\\mu\\psi A_\\mu\ndescribing the interaction of a fermionic field  with a bosonic gauge field , the Feynman rules can be formulated in coordinate space as follows:\n\n# Each integration coordinate  is represented by a point (sometimes called a vertex);\n# A bosonic propagator is represented by a wiggly line connecting two points;\n# A fermionic propagator is represented by a solid line connecting two points;\n# A bosonic field A_\\mu(x_i) is represented by a wiggly line attached to the point ;\n# A fermionic field  is represented by a solid line attached to the point  with an arrow toward the point;\n# An anti-fermionic field  is represented by a solid line attached to the point  with an arrow away from the point;\n\nExample: second order processes in QED \n\nThe second order perturbation term in the -matrix is\n\nS^{(2)}=\\frac{(ie)^2}{2!}\\int d^4x\\, d^4x'\\, T\\bar\\psi(x)\\,\\gamma^\\mu\\,\\psi(x)\\,A_\\mu(x)\\,\\bar\\psi(x')\\,\\gamma^\\nu\\,\\psi(x')\\,A_\\nu(x').\\;\n\nScattering of fermions \n\n    \nThe Wick's expansion of the integrand gives (among others) the following term\n\nN\\bar\\psi(x)\\gamma^\\mu\\psi(x)\\bar\\psi(x')\\gamma^\\nu\\psi(x')\\underline{A_\\mu(x)A_\\nu(x')}\\;,\n\nwhere\n\n\\underline{A_\\mu(x)A_\\nu(x')}=\\int\\frac{d^4k}{(2\\pi)^4}\\frac{-ig_{\\mu\\nu}}{k^2+i0}e^{-ik(x-x')}\n\nis the electromagnetic contraction (propagator) in the Feynman gauge. This term is represented by the Feynman diagram at the right. This diagram gives contributions to the following processes:\n# e− e− scattering (initial state at the right, final state at the left of the diagram);\n# e+ e+ scattering (initial state at the left, final state at the right of the diagram);\n# e− e+ scattering (initial state at the bottom/top, final state at the top/bottom of the diagram).\n\nCompton scattering and annihilation/generation of e− e+ pairs \n\nAnother interesting term in the expansion is\n\nN\\bar\\psi(x)\\,\\gamma^\\mu\\,\\underline{\\psi(x)\\,\\bar\\psi(x')}\\,\\gamma^\\nu\\,\\psi(x')\\,A_\\mu(x)\\,A_\\nu(x')\\;,\n\nwhere\n\n\\underline{\\psi(x)\\bar\\psi(x')}=\\int\\frac{d^4p}{(2\\pi)^4}\\frac{i}{\\gamma p-m+i0}e^{-ip(x-x')}\n\nis the fermionic contraction (propagator).\n\nPath integral formulation \n\nIn a path integral, the field Lagrangian, integrated over all possible field histories, defines the probability amplitude to go from one field configuration to another. In order to make sense, the field theory should have a well-defined ground state, and the integral should be performed a little bit rotated into imaginary time, i.e. a Wick rotation.\n\nScalar field Lagrangian \n\nA simple example is the free relativistic scalar field in  dimensions, whose action integral is:\n S = \\int \\tfrac12 \\partial_\\mu \\phi \\partial^\\mu \\phi\\, d^dx \\,.\n\nThe probability amplitude for a process is:\n\n \\int_A^B e^{iS}\\, D\\phi\\,, \n\nwhere  and  are space-like hypersurfaces that define the boundary conditions. The collection of all the  on the starting hypersurface give the initial value of the field, analogous to the starting position for a point particle, and the field values  at each point of the final hypersurface defines the final field value, which is allowed to vary, giving a different amplitude to end up at different values. This is the field-to-field transition amplitude.\n\nThe path integral gives the expectation value of operators between the initial and final state:\n\n \\int_A^B e^{iS} \\phi(x_1) \\cdots \\phi(x_n) \\,D\\phi = \\left\\langle A\\left| \\phi(x_1) \\cdots \\phi(x_n) \\right|B \\right\\rangle\\,,\n\nand in the limit that A and B recede to the infinite past and the infinite future, the only contribution that matters is from the ground state (this is only rigorously true if the path-integral is defined slightly rotated into imaginary time). The path integral can be thought of as analogous to a probability distribution, and it is convenient to define it so that multiplying by a constant doesn't change anything:\n\n \\frac{\\displaystyle\\int e^{iS} \\phi(x_1) \\cdots \\phi(x_n) \\,D\\phi }{ \\displaystyle\\int e^{iS} \\,D\\phi } = \\left\\langle 0 \\left| \\phi(x_1) \\cdots \\phi(x_n) \\right|0\\right\\rangle \\,.\n\nThe normalization factor on the bottom is called the partition function for the field, and it coincides with the statistical mechanical partition function at zero temperature when rotated into imaginary time.\n\nThe initial-to-final amplitudes are ill-defined if one thinks of the continuum limit right from the beginning, because the fluctuations in the field can become unbounded. So the path-integral can be thought of as on a discrete square lattice, with lattice spacing  and the limit  should be taken carefully. If the final results do not depend on the shape of the lattice or the value of , then the continuum limit exists.\n\nOn a lattice \n\nOn a lattice, (i), the field can be expanded in Fourier modes:\n\\phi(x) \\int \\frac{dk}{(2\\pi)^d} \\phi(k) e^{ik\\cdot x} \n \\int_k \\phi(k) e^{ikx}\\,.\n\nHere the integration domain is over  restricted to a cube of side length , so that large values of  are not allowed. It is important to note that the -measure contains the factors of 2 from Fourier transforms, this is the best standard convention for -integrals in QFT. The lattice means that fluctuations at large  are not allowed to contribute right away, they only start to contribute in the limit . Sometimes, instead of a lattice, the field modes are just cut off at high values of  instead.\n\nIt is also convenient from time to time to consider the space-time volume to be finite, so that the  modes are also a lattice. This is not strictly as necessary as the space-lattice limit, because interactions in  are not localized, but it is convenient for keeping track of the factors in front of the -integrals and the momentum-conserving delta functions that will arise.\n\nOn a lattice, (ii), the action needs to be discretized:\n S= \\sum_{\\langle x,y\\rangle} \\tfrac12 \\big(\\phi(x) - \\phi(y) \\big)^2\\,,\n\nwhere  is a pair of nearest lattice neighbors  and . The discretization should be thought of as defining what the derivative  means.\n\nIn terms of the lattice Fourier modes, the action can be written:\nS= \\int_k \\Big( \\big(1-\\cos(k_1)\\big) +\\big(1-\\cos(k_2)\\big) + \\cdots + \\big(1-\\cos(k_d)\\big) \\Big)\\phi^*_k \\phi^k\\,.\nFor  near zero this is:\nS = \\int_k \\tfrac12 k^2 \\left|\\phi(k)\\right|^2\\,.\n\nNow we have the continuum Fourier transform of the original action. In finite volume, the quantity  is not infinitesimal, but becomes the volume of a box made by neighboring Fourier modes, or .\n\nThe field  is real-valued, so the Fourier transform obeys:\n\n \\phi(k)^* = \\phi(-k)\\,.\n\nIn terms of real and imaginary parts, the real part of  is an even function of , while the imaginary part is odd. The Fourier transform avoids double-counting, so that it can be written:\n\n S = \\int_k \\tfrac12 k^2 \\phi(k) \\phi(-k)\n\nover an integration domain that integrates over each pair  exactly once.\n\nFor a complex scalar field with action\n\n S = \\int \\tfrac12 \\partial_\\mu\\phi^* \\partial^\\mu\\phi \\,d^dx\n\nthe Fourier transform is unconstrained:\n\n S = \\int_k \\tfrac12 k^2 \\left|\\phi(k)\\right|^2\n\nand the integral is over all .\n\nIntegrating over all different values of  is equivalent to integrating over all Fourier modes, because taking a Fourier transform is a unitary linear transformation of field coordinates. When you change coordinates in a multidimensional integral by a linear transformation, the value of the new integral is given by the determinant of the transformation matrix. If\n y_i = A_{ij} x_j\\,,\n\nthen\n\\det(A) \\int dx_1\\, dx_2 \\cdots\\, dx_n = \\int dy_1\\, dy_2 \\cdots\\, dy_n\\,.\n\nIf  is a rotation, then\nA^\\mathrm{T} A = I\nso that , and the sign depends on whether the rotation includes a reflection or not.\n\nThe matrix that changes coordinates from  to  can be read off from the definition of a Fourier transform.\n\n A_{kx} = e^{ikx} \\,\n\nand the Fourier inversion theorem tells you the inverse:\n\n A^{-1}_{kx} = e^{-ikx} \\,\n\nwhich is the complex conjugate-transpose, up to factors of 2. On a finite volume lattice, the determinant is nonzero and independent of the field values.\n \\det A = 1 \\,\n\nand the path integral is a separate factor at each value of .\n\n \\int \\exp \\left(\\frac{i}{2} \\sum_k k^2 \\phi^*(k) \\phi(k) \\right)\\, D\\phi = \\prod_k \\int_{\\phi_k} e^{\\frac{i}{2} k^2 \\left|\\phi_k \\right|^2\\, d^dk} \\,\n\nThe factor  is the infinitesimal volume of a discrete cell in -space, in a square lattice box\nd^dk = \\left(\\frac{1}{L}\\right)^d\\,,\nwhere  is the side-length of the box. Each separate factor is an oscillatory Gaussian, and the width of the Gaussian diverges as the volume goes to infinity.\n\nIn imaginary time, the Euclidean action becomes positive definite, and can be interpreted as a probability distribution. The probability of a field having values  is\n e^{\\int_k - \\tfrac12 k^2 \\phi^*_k \\phi_k} = \\prod_k e^{- k^2 \\left|\\phi_k\\right|^2\\, d^dk}\\,. \n\nThe expectation value of the field is the statistical expectation value of the field when chosen according to the probability distribution:\n\n\\left\\langle \\phi(x_1) \\cdots \\phi(x_n) \\right\\rangle = \\frac{ \\displaystyle\\int e^{-S} \\phi(x_1) \\cdots \\phi(x_n)\\, D\\phi} {\\displaystyle\\int e^{-S}\\, D\\phi}\n\nSince the probability of  is a product, the value of  at each separate value of  is independently Gaussian distributed. The variance of the Gaussian is , which is formally infinite, but that just means that the fluctuations are unbounded in infinite volume. In any finite volume, the integral is replaced by a discrete sum, and the variance of the integral is .\n\nMonte Carlo \n\nThe path integral defines a probabilistic algorithm to generate a Euclidean scalar field configuration. Randomly pick the real and imaginary parts of each Fourier mode at wavenumber  to be a Gaussian random variable with variance . This generates a configuration  at random, and the Fourier transform gives . For real scalar fields, the algorithm must generate only one of each pair , and make the second the complex conjugate of the first.\n\nTo find any correlation function, generate a field again and again by this procedure, and find the statistical average:\n\n \\left\\langle \\phi(x_1) \\cdots \\phi(x_n) \\right\\rangle = \\lim_. Feynman diagram. http://en.wikipedia.org/?curid=11617."
  }
}
