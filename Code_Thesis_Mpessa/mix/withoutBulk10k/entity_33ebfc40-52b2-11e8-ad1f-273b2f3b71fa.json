{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=18610",
  "eid" : "33ebfc40-52b2-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778596356,
  "textBody" : "In mathematics, the Laplace transform is an integral transform named after its discoverer Pierre-Simon Laplace.  It takes a function of a real variable  (often time) to a function of a complex variable  (frequency).\n\nThe Laplace transform is very similar to the Fourier transform.  While the Fourier transform of a function is a complex function of a real variable (frequency), the Laplace transform of a function is a complex function of a complex variable.  Laplace transforms are usually restricted to functions of  with .  A consequence of this restriction is that the Laplace transform of a function is a holomorphic function of the variable .  Unlike the Fourier transform, the Laplace transform of a distribution is generally a well-behaved function.  Also techniques of complex variables can be used directly to study Laplace transforms.  As a holomorphic function, the Laplace transform has a power series representation.  This power series expresses a function as a linear superposition of moments of the function.  This perspective has applications in probability theory.\n\nThe Laplace transform is invertible on a large class of functions.  The inverse Laplace transform takes a function of a complex variable s (often frequency) and yields a function of a real variable t (time).  Given a simple mathematical or functional description of an input or output to a system, the Laplace transform provides an alternative functional description that often simplifies the process of analyzing the behavior of the system, or in synthesizing a new system based on a set of specifications.  So, for example, Laplace transformation from the time domain to the frequency domain transforms differential equations into algebraic equations and convolution into multiplication.  It has many applications in the sciences and technology.\n\nHistory \n\nThe Laplace transform is named after mathematician and astronomer Pierre-Simon Laplace, who used a similar transform in his work on probability theory. Laplace's use of generating functions was similar to what is now known as the z-transform and he gave little attention to the continuous variable case which was discussed by Abel. [https://books.google.com/books?id6FtDAQAAMAAJ&pg\nRA2-PA67&lpg=RA2-PA67 1881 edition] The theory was further developed in the 19th and early 20th centuries by Lerch, Heaviside, and Bromwich. The current widespread use of the transform (mainly in engineering) came about during and soon after World War IIAn influential book was:  replacing the earlier Heaviside operational calculus. The advantages of the Laplace transform had been emphasized by Doetsch translation 1943 to whom is apparently due the name Laplace Transform.  \n\nThe early history of methods having some similarity to Laplace transform is as follows. From 1744, Leonhard Euler investigated integrals of the form\n z \\int X(x) e^{ax}\\, dx \\quad\\text{ and }\\quad z \n \\int X(x) x^A \\, dx\nas solutions of differential equations but did not pursue the matter very far., , \n\nJoseph Louis Lagrange was an admirer of Euler and, in his work on integrating probability density functions, investigated expressions of the form\n \\int X(x) e^{- a x } a^x\\, dx,\nwhich some modern historians have interpreted within modern Laplace transform theory.\n\nThese types of integrals seem first to have attracted Laplace's attention in 1782 where he was following in the spirit of Euler in using the integrals themselves as solutions of equations. However, in 1785, Laplace took the critical step forward when, rather than just looking for a solution in the form of an integral, he started to apply the transforms in the sense that was later to become popular. He used an integral of the form\n \\int x^s \\varphi (x)\\, dx,\nakin to a Mellin transform, to transform the whole of a difference equation, in order to look for solutions of the transformed equation. He then went on to apply the Laplace transform in the same way and started to derive some of its properties, beginning to appreciate its potential power.\n\nLaplace also recognised that Joseph Fourier's method of Fourier series for solving the diffusion equation could only apply to a limited region of space because those solutions were periodic. In 1809, Laplace applied his transform to find solutions that diffused indefinitely in space.\n\nFormal definition \n\nThe Laplace transform is a frequency-domain approach for continuous time signals irrespective of whether the system is stable or unstable. The Laplace transform of a function , defined for all real numbers , is the function , which is a unilateral transform defined by\nF(s) =\\int_0^\\infty f(t)e^{-st} \\, dt\nwhere s is a complex number frequency parameter\ns = \\sigma + i \\omega, with real numbers  and .\n\nAn alternate notation for the Laplace transform is \\mathcal{L}\\{f\\} instead of .\n\nThe meaning of the integral depends on types of functions of interest.  A necessary condition for existence of the integral is that  must be locally integrable on .  For locally integrable functions that decay at infinity or are of exponential type, the integral can be understood to be a (proper) Lebesgue integral. However, for many applications it is necessary to regard it to be a conditionally convergent improper integral at .  Still more generally, the integral can be understood in a weak sense, and this is dealt with below.\n\nOne can define the Laplace transform of a finite Borel measure  by the Lebesgue integral\n\\mathcal{L}\\{\\mu\\}(s) = \\int_{[0,\\infty)} e^{-st}\\, d\\mu(t).\n\nAn important special case is where  is a probability measure, for example, the Dirac delta function. In operational calculus, the Laplace transform of a measure is often treated as though the measure came from a probability density function .  In that case, to avoid potential confusion, one often writes\n\\mathcal{L}\\{f\\}(s) = \\int_{0^-}^\\infty f(t)e^{-st} \\, dt,\nwhere the lower limit of  is shorthand notation for\n\\lim_{\\varepsilon\\rightarrow 0}\\int_{-\\varepsilon}^\\infty.\n\nThis limit emphasizes that any point mass located at  is entirely captured by the Laplace transform.  Although with the Lebesgue integral, it is not necessary to take such a limit, it does appear more naturally in connection with the Laplace–Stieltjes transform.\n\nProbability theory \n\nIn pure and applied probability, the Laplace transform is defined as an expected value. If  is a random variable with probability density function , then the Laplace transform of  is given by the expectation\n\\mathcal{L}\\{f\\}(s) = E\\! \\left[e^{-sX} \\right]\\! .\n\nBy convention, this is referred to as the Laplace transform of the random variable  itself. Replacing  by  gives the moment generating function of . The Laplace transform has applications throughout probability theory, including first passage times of stochastic processes such as Markov chains, and renewal theory.\n\nOf particular use is the ability to recover the cumulative distribution function of a continuous random variable  by means of the Laplace transform as followsThe cumulative distribution function is the integral of the probability density function.\nF_X(x) \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s}E\\left[e^{-sX}\\right]\\right\\}\\! (x) \n \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s}\\mathcal{L}\\{f\\}(s)\\right\\}\\! (x).\n\nBilateral Laplace transform \n\nWhen one says \"the Laplace transform\" without qualification, the unilateral or one-sided transform is normally intended. The Laplace transform can be alternatively defined as the bilateral Laplace transform or two-sided Laplace transform by extending the limits of integration to be the entire real axis.  If that is done the common unilateral transform simply becomes a special case of the bilateral transform where the definition of the function being transformed is multiplied by the Heaviside step function.\n\nThe bilateral Laplace transform is defined as follows,\n\\mathcal{B}\\{f\\}(s) = \\int_{-\\infty}^\\infty e^{-st} f(t)\\, dt.\n\nInverse Laplace transform \n\nTwo integrable functions have the same Laplace transform only if they differ on a set of Lebesgue measure zero. This means that, on the range of the transform, there is an inverse transform. In fact, besides integrable functions, the Laplace transform is a one-to-one mapping from one function space into another in many other function spaces as well, although there is usually no easy characterization of the range. Typical function spaces in which this is true include the spaces of bounded continuous functions, the space Lp space|, or more generally tempered functions (that is, functions of at worst polynomial growth) on .  The Laplace transform is also defined and injective for suitable spaces of tempered distributions.\n\nIn these cases, the image of the Laplace transform lives in a space of analytic functions in the region of convergence.  The inverse Laplace transform is given by the following complex integral, which is known by various names (the Bromwich integral, the Fourier–Mellin integral, and Mellin's inverse formula):\nf(t) \\mathcal{L}^{-1}\\{F\\}(t) \n \\frac{1}{2 \\pi i} \\lim_{T\\to\\infty}\\int_{\\gamma - i T}^{\\gamma + i T} e^{st} F(s)\\, ds,\nwhere  is a real number so that the contour path of integration is in the region of convergence of . An alternative formula for the inverse Laplace transform is given by Post's inversion formula. The limit here is interpreted in the weak-* topology.\n\nIn practice, it is typically more convenient to decompose a Laplace transform into known transforms of functions obtained from a table, and construct the inverse by inspection.\n\nRegion of convergence \n\nIf  is a locally integrable function (or more generally a Borel measure locally of bounded variation), then the Laplace transform  of  converges provided that the limit\n\\lim_{R\\to\\infty}\\int_0^R f(t)e^{-st}\\,dt\nexists.\n\nThe Laplace transform converges absolutely if the integral\n\\int_0^\\infty \\left|f(t)e^{-st}\\right|\\,dt\nexists (as a proper Lebesgue integral).  The Laplace transform is usually understood as conditionally convergent, meaning that it converges in the former instead of the latter sense.\n\nThe set of values for which  converges absolutely is either of the form  or else , where  is an extended real constant, .  (This follows from the dominated convergence theorem.) The constant  is known as the abscissa of absolute convergence, and depends on the growth behavior of . Analogously, the two-sided transform converges absolutely in a strip of the form  , and possibly including the lines  or .  The subset of values of  for which the Laplace transform converges absolutely is called the region of absolute convergence or the domain of absolute convergence.  In the two-sided case, it is sometimes called the strip of absolute convergence. The Laplace transform is analytic in the region of absolute convergence: this is a consequence of Fubini's theorem and Morera's theorem. \n\nSimilarly, the set of values for which  converges (conditionally or absolutely) is known as the region of conditional convergence, or simply the region of convergence (ROC).  If the Laplace transform converges (conditionally) at , then it automatically converges for all  with .  Therefore, the region of convergence is a half-plane of the form , possibly including some points of the boundary line .\n\nIn the region of convergence , the Laplace transform of  can be expressed by integrating by parts as the integral\nF(s) (s-s_0)\\int_0^\\infty e^{-(s-s_0)t}\\beta(t)\\,dt,\\quad \\beta(u) \n \\int_0^u e^{-s_0t}f(t)\\,dt.\n\nThat is, in the region of convergence  can effectively be expressed as the absolutely convergent Laplace transform of some other function.  In particular, it is analytic.\n\nThere are several Paley–Wiener theorems concerning the relationship between the decay properties of  and the properties of the Laplace transform within the region of convergence.\n\nIn engineering applications, a function corresponding to a linear time-invariant (LTI) system is stable if every bounded input produces a bounded output.  This is equivalent to the absolute convergence of the Laplace transform of the impulse response function in the region .  As a result, LTI systems are stable provided the poles of the Laplace transform of the impulse response function have negative real part.\n\nThis ROC is used in knowing about the causality and stability of a system.\n\nProperties and theorems \n\nThe Laplace transform has a number of properties that make it useful for analyzing linear dynamical systems. The most significant advantage is that differentiation and integration become multiplication and division, respectively, by   (similarly to logarithms changing multiplication of numbers to addition of their logarithms).\n\nBecause of this property, the Laplace variable  is also known as operator variable in the  domain: either derivative operator or (for  integration operator. The transform turns integral equations and differential equations to polynomial equations, which are much easier to solve.  Once solved, use of the inverse Laplace transform reverts to the time domain.\n\nGiven the functions  and , and their respective Laplace transforms  and ,\n\\begin{align}\nf(t) &= \\mathcal{L}^{-1}\\{F(s)\\},\\\\\ng(t) &= \\mathcal{L}^{-1}\\{G(s)\\},\n\\end{align}\n\nThe following table is a list of properties of unilateral Laplace transform:\n\n* Initial value theorem:\nf(0^+)=\\lim_{s\\to \\infty}{sF(s)}.\n* Final value theorem:\nf(\\infty)=\\lim_{s\\to 0}{sF(s)}, if all poles of sF(s) are in the left half-plane.\nThe final value theorem is useful because it gives the long-term behaviour without having to perform partial fraction decompositions or other difficult algebra. If  has a pole in the right-hand plane or poles on the imaginary axis (e.g., if f(t) e^t or f(t) \n \\sin(t)), the behaviour of this formula is undefined.\n\nRelation to power series \n\nThe Laplace transform can be viewed as a continuous analogue of a power series. If   is a discrete function of a positive integer , then the power series associated to   is the series\n\\sum_{n=0}^{\\infty} a(n) x^n\nwhere   is a real variable (see Z transform). Replacing summation over  with integration over  , a continuous version of the power series becomes\n\\int_{0}^{\\infty} f(t) x^t\\, dt\nwhere the discrete function  is replaced by the continuous one . \n\nChanging the base of the power from  to  gives\n\\int_{0}^{\\infty} f(t) \\left(e^{\\ln{x}}\\right)^t\\, dt\n\nFor this to converge for, say, all bounded functions , it is necessary to require that . Making the substitution  gives just the Laplace transform:\n\\int_{0}^{\\infty} f(t) e^{-st}\\, dt\n\nIn other words, the Laplace transform is a continuous analog of a power series in which the discrete parameter  is replaced by the continuous parameter , and  is replaced by .\n\nRelation to moments \n\nThe quantities\n\\mu_n = \\int_0^\\infty t^nf(t)\\, dt\n\nare the moments of the function .  If the first  moments of  converge absolutely, then by repeated differentiation under the integral, \n(-1)^n(\\mathcal L f)^{(n)}(0) = \\mu_n .\nThis is of special significance in probability theory, where the moments of a random variable  are given by the expectation values \\mu_n=E[X^n].  Then, the relation holds\n\\mu_n = (-1)^n\\frac{d^n}{ds^n}E\\left[e^{-sX}\\right](0).\n\nProof of the Laplace transform of a function's derivative \n\nIt is often convenient to use the differentiation property of the Laplace transform to find the transform of a function's derivative.  This can be derived from the basic expression for a Laplace transform as follows:\n\n\\begin{align}\n  \\mathcal{L} \\left\\{f(t)\\right\\} &= \\int_{0^-}^\\infty e^{-st} f(t)\\, dt \\\\[6pt]\n                                  &= \\left[\\frac{f(t)e^{-st}}{-s} \\right]_{0^-}^\\infty -\n                                       \\int_{0^-}^\\infty \\frac{e^{-st}}{-s} f'(t) \\, dt\\quad \\text{(by parts)} \\\\[6pt]\n                                  &= \\left[-\\frac{f(0^-)}{-s}\\right] + \\frac 1 s \\mathcal{L} \\left\\{f'(t)\\right\\},\n\\end{align}\n\nyielding\n\n\\mathcal{L} \\{ f'(t) \\} = s\\cdot\\mathcal{L} \\{ f(t) \\}-f(0^-), \n\nand in the bilateral case,\n\n \\mathcal{L} \\{ f'(t) \\} s \\int_{-\\infty}^\\infty e^{-st} f(t)\\,dt  \n s \\cdot \\mathcal{L} \\{ f(t) \\}. \n\nThe general result\n\n\\mathcal{L} \\left\\{ f^{(n)}(t) \\right\\} = s^n \\cdot \\mathcal{L} \\{ f(t) \\} - s^{n - 1} f(0^-) - \\cdots - f^{(n - 1)}(0^-),\n\nwhere  denotes the th derivative of , can then be established with an inductive argument.\n\nEvaluating integrals over the positive real axis \n\nA useful property of the Laplace transform is the following:\n\n\\int_0^\\infty f(x)g(x)\\,dx = \\int_0^\\infty(\\mathcal{L} f)(s)\\cdot(\\mathcal{L}^{-1}g)(s)\\,ds \n\nunder suitable assumptions on the behaviour of f,g in a right neighbourhood of 0 and on the decay rate of f,g in a left neighbourhood of \\infty. The above formula is a variation of integration by parts, with the operators \n\\frac{d}{dx} and \\int \\,dx being replaced by \\mathcal{L} and \\mathcal{L}^{-1}. Let us prove the equivalent formulation:\n\n\\int_0^\\infty(\\mathcal{L} f)(x)g(x)\\,dx = \\int_0^\\infty f(s)(\\mathcal{L}g)(s)\\,ds. \n\nBy plugging in (\\mathcal{L}f)(x)=\\int_0^\\infty f(s)e^{-sx}\\,ds the left-hand side turns into:\n\n\\int_0^\\infty\\int_0^\\infty f(s)g(x) e^{-sx}\\,ds\\,dx, \n\nbut assuming Fubini's theorem holds, by reversing the order of integration we get the wanted right-hand side.\n\nEvaluating improper integrals \n\nLet \\mathcal{L}\\left\\{f(t)\\right\\} = F(s), then (see the table above)\n\n\\mathcal{L} \\left\\{\\frac{f(t)} t \\right\\} = \\int_s^\\infty F(p)\\, dp,\n\nor\n\n\\int_0^\\infty \\frac{f(t)}{t}e^{-st}\\, dt = \\int_s^\\infty F(p)\\, dp.\n\nLetting , gives one the identity\n\n\\int_0^\\infty \\frac{f(t)} t \\, dt = \\int_0^\\infty F(p)\\, dp.\n\nprovided that the interchange of limits can be justified. Even when the interchange cannot be justified the calculation can be suggestive. For example, proceeding formally one has\n\n\\begin{align}\n& \\int_0^\\infty \\frac 1 t ( \\cos(at) - \\cos(bt) )\\, dt =\n  \\int_0^\\infty \\left(\\frac p {p^2 + a^2} - \\frac{p}{p^2 + b^2}\\right)\\, dp \\\\[6pt]\n{} & \\frac 1 2 \\left. \\ln\\frac{p^2 + a^2}{p^2 + b^2} \\right|_{p\\,:\n\\,0}^\\infty = \\ln b - \\ln a.\n\\end{align}\n\nThe validity of this identity can be proved by other means. It is an example of a Frullani integral.\n\nAnother example is Dirichlet integral.\n\nRelationship to other transforms \n\nLaplace–Stieltjes transform \n\nThe (unilateral) Laplace–Stieltjes transform of a function  is defined by the Lebesgue–Stieltjes integral\n\n\\{\\mathcal{L}^*g\\}(s) = \\int_0^\\infty e^{-st} \\, dg(t).\n\nThe function  is assumed to be of bounded variation.  If  is the antiderivative of :\n\ng(x) = \\int_0^x f(t)\\,dt\n\nthen the Laplace–Stieltjes transform of  and the Laplace transform of  coincide.  In general, the Laplace–Stieltjes transform is the Laplace transform of the Stieltjes measure associated to .  So in practice, the only distinction between the two transforms is that the Laplace transform is thought of as operating on the density function of the measure, whereas the Laplace–Stieltjes transform is thought of as operating on its cumulative distribution function.\n\nFourier transform \n\nThe continuous Fourier transform is equivalent to evaluating the bilateral Laplace transform with imaginary argument  or ,\n\\begin{align}\n  \\hat{f}(\\omega) &= \\mathcal{F}\\{f(t)\\} \\\\[4pt]\n                  &\\mathcal{L}\\{f(t)\\}|_{s \n i\\omega}   F(s)|_{s \n i \\omega} \\\\[4pt]\n                  &= \\int_{-\\infty}^\\infty e^{-i \\omega t} f(t)\\,dt~.\n\\end{align}\n\nThis definition of the Fourier transform requires a prefactor of 1/2  on the reverse Fourier transform. This relationship between the Laplace and Fourier transforms is often used to determine the frequency spectrum of a signal or dynamical system.\n\nThe above relation is valid as stated if and only if the region of convergence (ROC) of   contains the imaginary axis,  .\n\nFor example, the function  has a Laplace transform   whose ROC is . As  is a pole of  , substituting   in  does not yield the Fourier transform of  , which is proportional to the Dirac delta-function .\n\nHowever, a relation of the form\n\\lim_{\\sigma\\to 0^+} F(\\sigma+i\\omega) = \\hat{f}(\\omega)\nholds under much weaker conditions.  For instance, this holds for the above example provided that the limit is understood as a weak limit of measures (see vague topology).  General conditions relating the limit of the Laplace transform of a function on the boundary to the Fourier transform take the form of Paley–Wiener theorems.\n\nMellin transform \n\nThe Mellin transform and its inverse are related to the two-sided Laplace transform by a simple change of variables.\n\nIf in the Mellin transform\nG(s) \\mathcal{M}\\{g(\\theta)\\} \n \\int_0^\\infty \\theta^s g(\\theta) \\, \\frac{d\\theta} \\theta \nwe set  we get a two-sided Laplace transform.\n\nZ-transform \n\nThe unilateral or one-sided Z-transform is simply the Laplace transform of an ideally sampled signal with the substitution of\n z \\stackrel{\\mathrm{def}} e^{sT} ,\nwhere  is the sampling period (in units of time e.g., seconds) and   is the sampling rate (in samples per second or hertz).\n\nLet\n \\Delta_T(t) \\ \\stackrel{\\mathrm{def}}{}\\  \\sum_{n\n0}^{\\infty}  \\delta(t - n T) \nbe a sampling impulse train (also called a Dirac comb) and\n\\begin{align}\n  x_q(t) \\  &\\stackrel{\\mathrm{def}}{}\\  x(t) \\Delta_T(t) \n x(t) \\sum_{n=0}^{\\infty}  \\delta(t - n T) \\\\\n            &\\sum_{n\n0}^{\\infty} x(n T) \\delta(t - n T) \\sum_{n\n0}^{\\infty} x[n] \\delta(t - n T)\n\\end{align}\nbe the sampled representation of the continuous-time \n x[n] \\stackrel{\\mathrm{def}}  x(nT) ~.\n\nThe Laplace transform of the sampled signal  is\n\\begin{align}\n  X_q(s) &= \\int_{0^-}^\\infty x_q(t) e^{-s t} \\,dt \\\\\n         &\\int_{0^-}^\\infty \\sum_{n\n0}^\\infty x[n] \\delta(t - n T) e^{-s t} \\, dt \\\\\n         &\\sum_{n\n0}^\\infty x[n] \\int_{0^-}^\\infty \\delta(t - n T) e^{-s t} \\, dt \\\\\n         &\\sum_{n\n0}^\\infty x[n] e^{-n s T}~.\n\\end{align}\n\nThis is the precise definition of the unilateral Z-transform of the discrete function \n\n X(z) \\sum_{n\n0}^{\\infty} x[n] z^{-n} \nwith the substitution of .\n\nComparing the last two equations, we find the relationship between the unilateral Z-transform and the Laplace transform of the sampled signal,\nX_q(s)  X(z) \\Big|_{z\ne^{sT}}.\n\nThe similarity between the  and Laplace transforms is expanded upon in the theory of time scale calculus.\n\nBorel transform \n\nThe integral form of the Borel transform\n\nF(s) = \\int_0^\\infty f(z)e^{-sz}\\, dz\n\nis a special case of the Laplace transform for  an entire function of exponential type, meaning that\n\n|f(z)|\\le Ae^{B|z|}\n\nfor some constants  and .  The generalized Borel transform allows a different weighting function to be used, rather than the exponential function, to transform functions not of exponential type. Nachbin's theorem gives necessary and sufficient conditions for the Borel transform to be well defined.\n\nFundamental relationships \n\nSince an ordinary Laplace transform can be written as a special case of a two-sided transform, and since the two-sided transform can be written as the sum of two one-sided transforms, the theory of the Laplace-, Fourier-, Mellin-, and Z-transforms are at bottom the same subject. However, a different point of view and different characteristic problems are associated with each of these four major integral transforms.\n\nTable of selected Laplace transforms \n\nThe following table provides Laplace transforms for many common functions of a single variable. For definitions and explanations, see the Explanatory Notes at the end of the table.\n\nBecause the Laplace transform is a linear operator,\n\n* The Laplace transform of a sum is the sum of Laplace transforms of each term.\n\n: \\mathcal{L}\\{f(t) + g(t)\\}  = \\mathcal{L}\\{f(t)\\} + \\mathcal{L}\\{ g(t)\\}  \n\n* The Laplace transform of a multiple of a function is that multiple times the Laplace transformation of that function.\n\n: \\mathcal{L}\\{a f(t)\\}  = a \\mathcal{L}\\{ f(t)\\}\n\nUsing this linearity, and various trigonometric, hyperbolic, and complex number (etc.) properties and/or identities, some Laplace transforms can be obtained from others quicker than by using the definition directly.\n\nThe unilateral Laplace transform takes as input a function whose time domain is the non-negative reals, which is why all of the time domain functions in the table below are multiples of the Heaviside step function, .\n\nThe entries of the table that involve a time delay  are required to be causal (meaning that ).  A causal system is a system where the impulse response  is zero for all time  prior to . In general, the region of convergence for causal systems is not the same as that of anticausal systems.\n\n  \\  \n||  { 2\\alpha \\over \\alpha^2 - s^2 }  \n||  \n|| Frequency shift ofunit step\n\n|- style=\"text-align:center;\"\n| exponential approach \n|| ( 1-e^{-\\alpha t})  \\cdot u(t)  \\  \n|| \\frac{\\alpha}{s(s+\\alpha)}  \n|| \n|| Unit step minusexponential decay\n\n|- style=\"text-align:center;\"\n| sine \n||  \\sin(\\omega t) \\cdot u(t) \\  \n||  { \\omega \\over s^2 + \\omega^2  }  \n|| \n|| \n\n|- style=\"text-align:center;\"\n| cosine \n||  \\cos(\\omega t) \\cdot u(t) \\  \n||  { s \\over s^2 + \\omega^2  }  \n|| \n|| \n\n|- style=\"text-align:center;\"\n| hyperbolic sine \n||  \\sinh(\\alpha t) \\cdot u(t) \\  \n||  { \\alpha \\over s^2 - \\alpha^2 }  \n||  \n|| \n\n|- style=\"text-align:center;\"\n| hyperbolic cosine \n||  \\cosh(\\alpha t) \\cdot u(t) \\  \n||  { s \\over s^2 - \\alpha^2  }  \n|| \n|| \n\n|- style=\"text-align:center;\"\n| exponentially decaying  sine wave \n|| e^{-\\alpha t}  \\sin(\\omega t) \\cdot u(t) \\  \n||  { \\omega \\over (s+\\alpha )^2 + \\omega^2  }  \n||  \n|| \n\n|- style=\"text-align:center;\"\n| exponentially decaying  cosine wave \n|| e^{-\\alpha t}  \\cos(\\omega t) \\cdot u(t) \\  \n||  { s+\\alpha \\over (s+\\alpha )^2 + \\omega^2  }  \n|| \n|| \n\n|- style=\"text-align:center;\"\n| natural logarithm \n||  \\ln (t) \\cdot u(t)  \n||  - { 1 \\over s}\\, \\left[ \\ln(s)+\\gamma \\right]  \n||  \n|| \n\n|- style=\"text-align:center;\"\n| Bessel function  of the first kind,  of order n \n||  J_n( \\omega t) \\cdot u(t) \n|| \\frac{ \\left(\\sqrt{s^2+ \\omega^2}-s\\right)^n}{\\omega^n \\sqrt{s^2 + \\omega^2}} \n||     () \n|| \n\n|- style=\"text-align:center;\"\n| Error function \n||  \\operatorname{erf}(t) \\cdot u(t)  \n||  \\frac 1 s e^{(1/4)s^2} \\left(1 - \\operatorname{erf} \\frac s 2 \\right) \n|| \n|| \n\n|-\n| colspan=5|Explanatory notes:\n\n*  represents the Heaviside step function.\n*   represents the Dirac delta function.\n*  represents the Gamma function.\n*  is the Euler–Mascheroni constant.\n\n*  , a real number, typically represents time, although it can represent any independent dimension.\n*   is the complex frequency domain parameter, and   is its real part.\n*   are real numbers.\n*   is an integer.\n\n|}\n\ns-domain equivalent circuits and impedances \n\nThe Laplace transform is often used in circuit analysis, and simple conversions to the -domain of circuit elements can be made. Circuit elements can be transformed into impedances, very similar to phasor impedances.\n\nHere is a summary of equivalents:\n\nNote that the resistor is exactly the same in the time domain and the -domain. The sources are put in if there are initial conditions on the circuit elements. For example, if a capacitor has an initial voltage across it, or if the inductor has an initial current through it, the sources inserted in the -domain account for that.\n\nThe equivalents for current and voltage sources are simply derived from the transformations in the table above.\n\nExamples and applications \n\nThe Laplace transform is used frequently in engineering and physics; the output of a linear time-invariant system can be calculated by convolving its unit impulse response with the input signal. Performing this calculation in Laplace space turns the convolution into a multiplication; the latter being easier to solve because of its algebraic form. For more information, see control theory.\n\nThe Laplace transform can also be used to solve differential equations and is used extensively in mechanical engineering and electrical engineering.  The Laplace transform reduces a linear differential equation to an algebraic equation, which can then be solved by the formal rules of algebra.  The original differential equation can then be solved by applying the inverse Laplace transform.  The English electrical engineer Oliver Heaviside first proposed a similar scheme, although without using the Laplace transform; and the resulting operational calculus is credited as the Heaviside calculus.\n\nNuclear physics \n\nIn nuclear physics, the following fundamental relationship governs radioactive decay: the number of radioactive atoms  in a sample of a radioactive isotope decays at a rate proportional to .  This leads to the first order linear differential equation\n\n\\frac{dN}{dt} = -\\lambda N,\n\nwhere  is the decay constant. The Laplace transform can be used to solve this equation.\n\nRearranging the equation to one side, we have\n\n\\frac{dN}{dt} + \\lambda N = 0.\n\nNext, we take the Laplace transform of both sides of the equation:\n\n\\left( s \\tilde{N}(s) - N_0 \\right) + \\lambda \\tilde{N}(s) = 0,\n\nwhere\n\n\\tilde{N}(s) = \\mathcal{L}\\{N(t)\\}\n\nand\n\nN_0 = N(0).\n\nSolving, we find\n\n\\tilde{N}(s) = \\frac{N_0}{s + \\lambda}.\n\nFinally, we take the inverse Laplace transform to find the general solution\n\n\\begin{align}\n  N(t) &\\mathcal{L}^{-1} \\{\\tilde{N}(s)\\} \n \\mathcal{L}^{-1}\\! \\left\\{ \\frac{N_0}{s + \\lambda} \\right\\}\\\\\n       &= \\ N_0 e^{-\\lambda t},\n\\end{align}\n\nwhich is indeed the correct form for radioactive decay.\n\nComplex impedance of a capacitor \n\nIn the theory of electrical circuits, the current flow in a capacitor is proportional to the capacitance and rate of change in the electrical potential (in SI units). Symbolically, this is expressed by the differential equation\n\ni = C { dv \\over dt} ,\n\nwhere  is the capacitance (in farads) of the capacitor,  is the electric current (in amperes) through the capacitor as a function of time, and  is the voltage (in volts) across the terminals of the capacitor, also as a function of time.\n\nTaking the Laplace transform of this equation, we obtain\n\nI(s) = C(s V(s) - V_0),\n\nwhere\n\n\\begin{align}\n  I(s) &= \\mathcal{L} \\{ i(t) \\},\\\\\n  V(s) &= \\mathcal{L} \\{ v(t) \\},\n\\end{align}\n\nand\n\nV_0 v(t)\\Big|_{t\n0}. \\, \n\nSolving for  we have\n\nV(s) = { I(s) \\over sC } + { V_0 \\over s }.\n\nThe definition of the complex impedance  (in ohms) is the ratio of the complex voltage  divided by the complex current  while holding the initial state  at zero:\n\nZ(s) \\left. { V(s) \\over I(s) } \\right|_{V_0 \n 0}.\n\nUsing this definition and the previous equation, we find:\n\nZ(s) = \\frac{1}{sC}, \n\nwhich is the correct expression for the complex impedance of a capacitor.\n\nPartial fraction expansion \n\nConsider a linear time-invariant system with transfer function\nH(s) = \\frac{1}{(s + \\alpha)(s + \\beta)}.\n\nThe impulse response is simply the inverse Laplace transform of this transfer function:\nh(t) = \\mathcal{L}^{-1}\\{H(s)\\}.\n\nTo evaluate this inverse transform, we begin by expanding  using the method of partial fraction expansion,\n\\frac{1}{(s + \\alpha)(s + \\beta)} = { P \\over s + \\alpha } + { R \\over s+\\beta }.\n\nThe unknown constants  and  are the residues located at the corresponding poles of the transfer function. Each residue represents the relative contribution of that singularity to the transfer function's overall shape.\n\nBy the residue theorem, the inverse Laplace transform depends only upon the poles and their residues. To find the residue , we multiply both sides of the equation by  to get\n\\frac{1}{s + \\beta} = P  + { R (s + \\alpha) \\over s + \\beta }.\n\nThen by letting , the contribution from  vanishes and all that is left is\nP \\left.{1 \\over s+\\beta}\\right|_{s\n-\\alpha} = {1 \\over \\beta - \\alpha}.\n\nSimilarly, the residue  is given by\nR \\left.{1 \\over s + \\alpha}\\right|_{s\n-\\beta} = {1 \\over \\alpha - \\beta}.\n\nNote that\nR {-1 \\over \\beta - \\alpha} \n - P\nand so the substitution of  and  into the expanded expression for  gives\nH(s)  = \\left( \\frac{1}{\\beta - \\alpha} \\right) \\cdot \\left(  { 1 \\over s + \\alpha } - { 1  \\over s + \\beta }  \\right).\n\nFinally, using the linearity property and the known transform for exponential decay (see Item #3 in the Table of Laplace Transforms, above), we can take the inverse Laplace transform of  to obtain\nh(t) \\mathcal{L}^{-1}\\{H(s)\\} \n \\frac{1}{\\beta - \\alpha}\\left(e^{-\\alpha t} - e^{-\\beta t}\\right),\nwhich is the impulse response of the system.\n\n;Convolution\nThe same result can be achieved using the convolution property as if the system is a series of filters with transfer functions of  and . That is, the inverse of\n\nH(s) \\frac{1}{(s + a)(s + b)} \n \\frac{1}{s+a} \\cdot \\frac{1}{s + b}\n\nis\n\n \\mathcal{L}^{-1}\\! \\left\\{ \\frac{1}{s + a} \\right\\} * \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s + b} \\right\\} e^{-at} * e^{-bt} \n \\int_0^t e^{-ax}e^{-b(t - x)}\\, dx = \\frac{e^{-a t}-e^{-b t}}{b - a}.\n\nPhase delay \n\nStarting with the Laplace transform,\n\nX(s) = \\frac{s\\sin(\\varphi) + \\omega \\cos(\\varphi)}{s^2 + \\omega^2}\n\nwe find the inverse by first rearranging terms in the fraction:\n\n\\begin{align}\n  X(s) &= \\frac{s \\sin(\\varphi)}{s^2 + \\omega^2} + \\frac{\\omega \\cos(\\varphi)}{s^2 + \\omega^2} \\\\\n       &= \\sin(\\varphi) \\left(\\frac{s}{s^2 + \\omega^2} \\right) + \\cos(\\varphi) \\left(\\frac{\\omega}{s^2 + \\omega^2} \\right).\n\\end{align}\n\nWe are now able to take the inverse Laplace transform of our terms:\n\n\\begin{align}\n  x(t) &= \\sin(\\varphi) \\mathcal{L}^{-1}\\left\\{\\frac{s}{s^2 + \\omega^2} \\right\\} + \\cos(\\varphi) \\mathcal{L}^{-1}\\left\\{\\frac{\\omega}{s^2 + \\omega^2} \\right\\} \\\\\n       &= \\sin(\\varphi)\\cos(\\omega t) + \\sin(\\omega t)\\cos(\\varphi).\n\\end{align}\n\nThis is just the sine of the sum of the arguments, yielding:\n\nx(t) = \\sin (\\omega t + \\varphi).\n\nWe can apply similar logic to find that\n\n\\mathcal{L}^{-1} \\left\\{ \\frac{s\\cos\\varphi - \\omega \\sin\\varphi}{s^2 + \\omega^2} \\right\\} = \\cos{(\\omega t + \\varphi)}.\n\nDetermining structure of astronomical object from spectrum \n\nThe wide and general applicability of the Laplace transform and its inverse is illustrated by an application in astronomy which provides some information on the spatial distribution of matter of an astronomical source of radio-frequency thermal radiation too distant to resolve as more than a point, given its flux density spectrum, rather than relating the time domain with the spectrum (frequency domain).\n\nAssuming certain properties of the object, e.g. spherical shape and constant temperature, calculations based on carrying out an inverse Laplace transformation on the spectrum of the object can produce the only possible model of the distribution of matter in it (density as a function of distance from the center) consistent with the spectrum., and When independent information on the structure of an object is available, the inverse Laplace transform method has been found to be in good agreement.\n\nStatistical mechanics \n\nIn statistical mechanics, the Laplace transform of the energy distribution defines the partition function.",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Laplace transform" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=18610" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "In mathematics, the Laplace transform is an integral transform named after its discoverer Pierre-Simon Laplace.  It takes a function of a real variable  (often time) to a function of a complex variable  (frequency).\n\nThe Laplace transform is very similar to the Fourier transform.  While the Fourier transform of a function is a complex function of a real variable (frequency), the Laplace transform of a function is a complex function of a complex variable.  Laplace transforms are usually restricted to functions of  with .  A consequence of this restriction is that the Laplace transform of a function is a holomorphic function of the variable .  Unlike the Fourier transform, the Laplace transform of a distribution is generally a well-behaved function.  Also techniques of complex variables can be used directly to study Laplace transforms.  As a holomorphic function, the Laplace transform has a power series representation.  This power series expresses a function as a linear superposition of moments of the function.  This perspective has applications in probability theory.\n\nThe Laplace transform is invertible on a large class of functions.  The inverse Laplace transform takes a function of a complex variable s (often frequency) and yields a function of a real variable t (time).  Given a simple mathematical or functional description of an input or output to a system, the Laplace transform provides an alternative functional description that often simplifies the process of analyzing the behavior of the system, or in synthesizing a new system based on a set of specifications.  So, for example, Laplace transformation from the time domain to the frequency domain transforms differential equations into algebraic equations and convolution into multiplication.  It has many applications in the sciences and technology.\n\nHistory \n\nThe Laplace transform is named after mathematician and astronomer Pierre-Simon Laplace, who used a similar transform in his work on probability theory. Laplace's use of generating functions was similar to what is now known as the z-transform and he gave little attention to the continuous variable case which was discussed by Abel. [https://books.google.com/books?id6FtDAQAAMAAJ&pg\nRA2-PA67&lpg=RA2-PA67 1881 edition] The theory was further developed in the 19th and early 20th centuries by Lerch, Heaviside, and Bromwich. The current widespread use of the transform (mainly in engineering) came about during and soon after World War IIAn influential book was:  replacing the earlier Heaviside operational calculus. The advantages of the Laplace transform had been emphasized by Doetsch translation 1943 to whom is apparently due the name Laplace Transform.  \n\nThe early history of methods having some similarity to Laplace transform is as follows. From 1744, Leonhard Euler investigated integrals of the form\n z \\int X(x) e^{ax}\\, dx \\quad\\text{ and }\\quad z \n \\int X(x) x^A \\, dx\nas solutions of differential equations but did not pursue the matter very far., , \n\nJoseph Louis Lagrange was an admirer of Euler and, in his work on integrating probability density functions, investigated expressions of the form\n \\int X(x) e^{- a x } a^x\\, dx,\nwhich some modern historians have interpreted within modern Laplace transform theory.\n\nThese types of integrals seem first to have attracted Laplace's attention in 1782 where he was following in the spirit of Euler in using the integrals themselves as solutions of equations. However, in 1785, Laplace took the critical step forward when, rather than just looking for a solution in the form of an integral, he started to apply the transforms in the sense that was later to become popular. He used an integral of the form\n \\int x^s \\varphi (x)\\, dx,\nakin to a Mellin transform, to transform the whole of a difference equation, in order to look for solutions of the transformed equation. He then went on to apply the Laplace transform in the same way and started to derive some of its properties, beginning to appreciate its potential power.\n\nLaplace also recognised that Joseph Fourier's method of Fourier series for solving the diffusion equation could only apply to a limited region of space because those solutions were periodic. In 1809, Laplace applied his transform to find solutions that diffused indefinitely in space.\n\nFormal definition \n\nThe Laplace transform is a frequency-domain approach for continuous time signals irrespective of whether the system is stable or unstable. The Laplace transform of a function , defined for all real numbers , is the function , which is a unilateral transform defined by\nF(s) =\\int_0^\\infty f(t)e^{-st} \\, dt\nwhere s is a complex number frequency parameter\ns = \\sigma + i \\omega, with real numbers  and .\n\nAn alternate notation for the Laplace transform is \\mathcal{L}\\{f\\} instead of .\n\nThe meaning of the integral depends on types of functions of interest.  A necessary condition for existence of the integral is that  must be locally integrable on .  For locally integrable functions that decay at infinity or are of exponential type, the integral can be understood to be a (proper) Lebesgue integral. However, for many applications it is necessary to regard it to be a conditionally convergent improper integral at .  Still more generally, the integral can be understood in a weak sense, and this is dealt with below.\n\nOne can define the Laplace transform of a finite Borel measure  by the Lebesgue integral\n\\mathcal{L}\\{\\mu\\}(s) = \\int_{[0,\\infty)} e^{-st}\\, d\\mu(t).\n\nAn important special case is where  is a probability measure, for example, the Dirac delta function. In operational calculus, the Laplace transform of a measure is often treated as though the measure came from a probability density function .  In that case, to avoid potential confusion, one often writes\n\\mathcal{L}\\{f\\}(s) = \\int_{0^-}^\\infty f(t)e^{-st} \\, dt,\nwhere the lower limit of  is shorthand notation for\n\\lim_{\\varepsilon\\rightarrow 0}\\int_{-\\varepsilon}^\\infty.\n\nThis limit emphasizes that any point mass located at  is entirely captured by the Laplace transform.  Although with the Lebesgue integral, it is not necessary to take such a limit, it does appear more naturally in connection with the Laplace–Stieltjes transform.\n\nProbability theory \n\nIn pure and applied probability, the Laplace transform is defined as an expected value. If  is a random variable with probability density function , then the Laplace transform of  is given by the expectation\n\\mathcal{L}\\{f\\}(s) = E\\! \\left[e^{-sX} \\right]\\! .\n\nBy convention, this is referred to as the Laplace transform of the random variable  itself. Replacing  by  gives the moment generating function of . The Laplace transform has applications throughout probability theory, including first passage times of stochastic processes such as Markov chains, and renewal theory.\n\nOf particular use is the ability to recover the cumulative distribution function of a continuous random variable  by means of the Laplace transform as followsThe cumulative distribution function is the integral of the probability density function.\nF_X(x) \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s}E\\left[e^{-sX}\\right]\\right\\}\\! (x) \n \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s}\\mathcal{L}\\{f\\}(s)\\right\\}\\! (x).\n\nBilateral Laplace transform \n\nWhen one says \"the Laplace transform\" without qualification, the unilateral or one-sided transform is normally intended. The Laplace transform can be alternatively defined as the bilateral Laplace transform or two-sided Laplace transform by extending the limits of integration to be the entire real axis.  If that is done the common unilateral transform simply becomes a special case of the bilateral transform where the definition of the function being transformed is multiplied by the Heaviside step function.\n\nThe bilateral Laplace transform is defined as follows,\n\\mathcal{B}\\{f\\}(s) = \\int_{-\\infty}^\\infty e^{-st} f(t)\\, dt.\n\nInverse Laplace transform \n\nTwo integrable functions have the same Laplace transform only if they differ on a set of Lebesgue measure zero. This means that, on the range of the transform, there is an inverse transform. In fact, besides integrable functions, the Laplace transform is a one-to-one mapping from one function space into another in many other function spaces as well, although there is usually no easy characterization of the range. Typical function spaces in which this is true include the spaces of bounded continuous functions, the space Lp space|, or more generally tempered functions (that is, functions of at worst polynomial growth) on .  The Laplace transform is also defined and injective for suitable spaces of tempered distributions.\n\nIn these cases, the image of the Laplace transform lives in a space of analytic functions in the region of convergence.  The inverse Laplace transform is given by the following complex integral, which is known by various names (the Bromwich integral, the Fourier–Mellin integral, and Mellin's inverse formula):\nf(t) \\mathcal{L}^{-1}\\{F\\}(t) \n \\frac{1}{2 \\pi i} \\lim_{T\\to\\infty}\\int_{\\gamma - i T}^{\\gamma + i T} e^{st} F(s)\\, ds,\nwhere  is a real number so that the contour path of integration is in the region of convergence of . An alternative formula for the inverse Laplace transform is given by Post's inversion formula. The limit here is interpreted in the weak-* topology.\n\nIn practice, it is typically more convenient to decompose a Laplace transform into known transforms of functions obtained from a table, and construct the inverse by inspection.\n\nRegion of convergence \n\nIf  is a locally integrable function (or more generally a Borel measure locally of bounded variation), then the Laplace transform  of  converges provided that the limit\n\\lim_{R\\to\\infty}\\int_0^R f(t)e^{-st}\\,dt\nexists.\n\nThe Laplace transform converges absolutely if the integral\n\\int_0^\\infty \\left|f(t)e^{-st}\\right|\\,dt\nexists (as a proper Lebesgue integral).  The Laplace transform is usually understood as conditionally convergent, meaning that it converges in the former instead of the latter sense.\n\nThe set of values for which  converges absolutely is either of the form  or else , where  is an extended real constant, .  (This follows from the dominated convergence theorem.) The constant  is known as the abscissa of absolute convergence, and depends on the growth behavior of . Analogously, the two-sided transform converges absolutely in a strip of the form  , and possibly including the lines  or .  The subset of values of  for which the Laplace transform converges absolutely is called the region of absolute convergence or the domain of absolute convergence.  In the two-sided case, it is sometimes called the strip of absolute convergence. The Laplace transform is analytic in the region of absolute convergence: this is a consequence of Fubini's theorem and Morera's theorem. \n\nSimilarly, the set of values for which  converges (conditionally or absolutely) is known as the region of conditional convergence, or simply the region of convergence (ROC).  If the Laplace transform converges (conditionally) at , then it automatically converges for all  with .  Therefore, the region of convergence is a half-plane of the form , possibly including some points of the boundary line .\n\nIn the region of convergence , the Laplace transform of  can be expressed by integrating by parts as the integral\nF(s) (s-s_0)\\int_0^\\infty e^{-(s-s_0)t}\\beta(t)\\,dt,\\quad \\beta(u) \n \\int_0^u e^{-s_0t}f(t)\\,dt.\n\nThat is, in the region of convergence  can effectively be expressed as the absolutely convergent Laplace transform of some other function.  In particular, it is analytic.\n\nThere are several Paley–Wiener theorems concerning the relationship between the decay properties of  and the properties of the Laplace transform within the region of convergence.\n\nIn engineering applications, a function corresponding to a linear time-invariant (LTI) system is stable if every bounded input produces a bounded output.  This is equivalent to the absolute convergence of the Laplace transform of the impulse response function in the region .  As a result, LTI systems are stable provided the poles of the Laplace transform of the impulse response function have negative real part.\n\nThis ROC is used in knowing about the causality and stability of a system.\n\nProperties and theorems \n\nThe Laplace transform has a number of properties that make it useful for analyzing linear dynamical systems. The most significant advantage is that differentiation and integration become multiplication and division, respectively, by   (similarly to logarithms changing multiplication of numbers to addition of their logarithms).\n\nBecause of this property, the Laplace variable  is also known as operator variable in the  domain: either derivative operator or (for  integration operator. The transform turns integral equations and differential equations to polynomial equations, which are much easier to solve.  Once solved, use of the inverse Laplace transform reverts to the time domain.\n\nGiven the functions  and , and their respective Laplace transforms  and ,\n\\begin{align}\nf(t) &= \\mathcal{L}^{-1}\\{F(s)\\},\\\\\ng(t) &= \\mathcal{L}^{-1}\\{G(s)\\},\n\\end{align}\n\nThe following table is a list of properties of unilateral Laplace transform:\n\n* Initial value theorem:\nf(0^+)=\\lim_{s\\to \\infty}{sF(s)}.\n* Final value theorem:\nf(\\infty)=\\lim_{s\\to 0}{sF(s)}, if all poles of sF(s) are in the left half-plane.\nThe final value theorem is useful because it gives the long-term behaviour without having to perform partial fraction decompositions or other difficult algebra. If  has a pole in the right-hand plane or poles on the imaginary axis (e.g., if f(t) e^t or f(t) \n \\sin(t)), the behaviour of this formula is undefined.\n\nRelation to power series \n\nThe Laplace transform can be viewed as a continuous analogue of a power series. If   is a discrete function of a positive integer , then the power series associated to   is the series\n\\sum_{n=0}^{\\infty} a(n) x^n\nwhere   is a real variable (see Z transform). Replacing summation over  with integration over  , a continuous version of the power series becomes\n\\int_{0}^{\\infty} f(t) x^t\\, dt\nwhere the discrete function  is replaced by the continuous one . \n\nChanging the base of the power from  to  gives\n\\int_{0}^{\\infty} f(t) \\left(e^{\\ln{x}}\\right)^t\\, dt\n\nFor this to converge for, say, all bounded functions , it is necessary to require that . Making the substitution  gives just the Laplace transform:\n\\int_{0}^{\\infty} f(t) e^{-st}\\, dt\n\nIn other words, the Laplace transform is a continuous analog of a power series in which the discrete parameter  is replaced by the continuous parameter , and  is replaced by .\n\nRelation to moments \n\nThe quantities\n\\mu_n = \\int_0^\\infty t^nf(t)\\, dt\n\nare the moments of the function .  If the first  moments of  converge absolutely, then by repeated differentiation under the integral, \n(-1)^n(\\mathcal L f)^{(n)}(0) = \\mu_n .\nThis is of special significance in probability theory, where the moments of a random variable  are given by the expectation values \\mu_n=E[X^n].  Then, the relation holds\n\\mu_n = (-1)^n\\frac{d^n}{ds^n}E\\left[e^{-sX}\\right](0).\n\nProof of the Laplace transform of a function's derivative \n\nIt is often convenient to use the differentiation property of the Laplace transform to find the transform of a function's derivative.  This can be derived from the basic expression for a Laplace transform as follows:\n\n\\begin{align}\n  \\mathcal{L} \\left\\{f(t)\\right\\} &= \\int_{0^-}^\\infty e^{-st} f(t)\\, dt \\\\[6pt]\n                                  &= \\left[\\frac{f(t)e^{-st}}{-s} \\right]_{0^-}^\\infty -\n                                       \\int_{0^-}^\\infty \\frac{e^{-st}}{-s} f'(t) \\, dt\\quad \\text{(by parts)} \\\\[6pt]\n                                  &= \\left[-\\frac{f(0^-)}{-s}\\right] + \\frac 1 s \\mathcal{L} \\left\\{f'(t)\\right\\},\n\\end{align}\n\nyielding\n\n\\mathcal{L} \\{ f'(t) \\} = s\\cdot\\mathcal{L} \\{ f(t) \\}-f(0^-), \n\nand in the bilateral case,\n\n \\mathcal{L} \\{ f'(t) \\} s \\int_{-\\infty}^\\infty e^{-st} f(t)\\,dt  \n s \\cdot \\mathcal{L} \\{ f(t) \\}. \n\nThe general result\n\n\\mathcal{L} \\left\\{ f^{(n)}(t) \\right\\} = s^n \\cdot \\mathcal{L} \\{ f(t) \\} - s^{n - 1} f(0^-) - \\cdots - f^{(n - 1)}(0^-),\n\nwhere  denotes the th derivative of , can then be established with an inductive argument.\n\nEvaluating integrals over the positive real axis \n\nA useful property of the Laplace transform is the following:\n\n\\int_0^\\infty f(x)g(x)\\,dx = \\int_0^\\infty(\\mathcal{L} f)(s)\\cdot(\\mathcal{L}^{-1}g)(s)\\,ds \n\nunder suitable assumptions on the behaviour of f,g in a right neighbourhood of 0 and on the decay rate of f,g in a left neighbourhood of \\infty. The above formula is a variation of integration by parts, with the operators \n\\frac{d}{dx} and \\int \\,dx being replaced by \\mathcal{L} and \\mathcal{L}^{-1}. Let us prove the equivalent formulation:\n\n\\int_0^\\infty(\\mathcal{L} f)(x)g(x)\\,dx = \\int_0^\\infty f(s)(\\mathcal{L}g)(s)\\,ds. \n\nBy plugging in (\\mathcal{L}f)(x)=\\int_0^\\infty f(s)e^{-sx}\\,ds the left-hand side turns into:\n\n\\int_0^\\infty\\int_0^\\infty f(s)g(x) e^{-sx}\\,ds\\,dx, \n\nbut assuming Fubini's theorem holds, by reversing the order of integration we get the wanted right-hand side.\n\nEvaluating improper integrals \n\nLet \\mathcal{L}\\left\\{f(t)\\right\\} = F(s), then (see the table above)\n\n\\mathcal{L} \\left\\{\\frac{f(t)} t \\right\\} = \\int_s^\\infty F(p)\\, dp,\n\nor\n\n\\int_0^\\infty \\frac{f(t)}{t}e^{-st}\\, dt = \\int_s^\\infty F(p)\\, dp.\n\nLetting , gives one the identity\n\n\\int_0^\\infty \\frac{f(t)} t \\, dt = \\int_0^\\infty F(p)\\, dp.\n\nprovided that the interchange of limits can be justified. Even when the interchange cannot be justified the calculation can be suggestive. For example, proceeding formally one has\n\n\\begin{align}\n& \\int_0^\\infty \\frac 1 t ( \\cos(at) - \\cos(bt) )\\, dt =\n  \\int_0^\\infty \\left(\\frac p {p^2 + a^2} - \\frac{p}{p^2 + b^2}\\right)\\, dp \\\\[6pt]\n{} & \\frac 1 2 \\left. \\ln\\frac{p^2 + a^2}{p^2 + b^2} \\right|_{p\\,:\n\\,0}^\\infty = \\ln b - \\ln a.\n\\end{align}\n\nThe validity of this identity can be proved by other means. It is an example of a Frullani integral.\n\nAnother example is Dirichlet integral.\n\nRelationship to other transforms \n\nLaplace–Stieltjes transform \n\nThe (unilateral) Laplace–Stieltjes transform of a function  is defined by the Lebesgue–Stieltjes integral\n\n\\{\\mathcal{L}^*g\\}(s) = \\int_0^\\infty e^{-st} \\, dg(t).\n\nThe function  is assumed to be of bounded variation.  If  is the antiderivative of :\n\ng(x) = \\int_0^x f(t)\\,dt\n\nthen the Laplace–Stieltjes transform of  and the Laplace transform of  coincide.  In general, the Laplace–Stieltjes transform is the Laplace transform of the Stieltjes measure associated to .  So in practice, the only distinction between the two transforms is that the Laplace transform is thought of as operating on the density function of the measure, whereas the Laplace–Stieltjes transform is thought of as operating on its cumulative distribution function.\n\nFourier transform \n\nThe continuous Fourier transform is equivalent to evaluating the bilateral Laplace transform with imaginary argument  or ,\n\\begin{align}\n  \\hat{f}(\\omega) &= \\mathcal{F}\\{f(t)\\} \\\\[4pt]\n                  &\\mathcal{L}\\{f(t)\\}|_{s \n i\\omega}   F(s)|_{s \n i \\omega} \\\\[4pt]\n                  &= \\int_{-\\infty}^\\infty e^{-i \\omega t} f(t)\\,dt~.\n\\end{align}\n\nThis definition of the Fourier transform requires a prefactor of 1/2  on the reverse Fourier transform. This relationship between the Laplace and Fourier transforms is often used to determine the frequency spectrum of a signal or dynamical system.\n\nThe above relation is valid as stated if and only if the region of convergence (ROC) of   contains the imaginary axis,  .\n\nFor example, the function  has a Laplace transform   whose ROC is . As  is a pole of  , substituting   in  does not yield the Fourier transform of  , which is proportional to the Dirac delta-function .\n\nHowever, a relation of the form\n\\lim_{\\sigma\\to 0^+} F(\\sigma+i\\omega) = \\hat{f}(\\omega)\nholds under much weaker conditions.  For instance, this holds for the above example provided that the limit is understood as a weak limit of measures (see vague topology).  General conditions relating the limit of the Laplace transform of a function on the boundary to the Fourier transform take the form of Paley–Wiener theorems.\n\nMellin transform \n\nThe Mellin transform and its inverse are related to the two-sided Laplace transform by a simple change of variables.\n\nIf in the Mellin transform\nG(s) \\mathcal{M}\\{g(\\theta)\\} \n \\int_0^\\infty \\theta^s g(\\theta) \\, \\frac{d\\theta} \\theta \nwe set  we get a two-sided Laplace transform.\n\nZ-transform \n\nThe unilateral or one-sided Z-transform is simply the Laplace transform of an ideally sampled signal with the substitution of\n z \\stackrel{\\mathrm{def}} e^{sT} ,\nwhere  is the sampling period (in units of time e.g., seconds) and   is the sampling rate (in samples per second or hertz).\n\nLet\n \\Delta_T(t) \\ \\stackrel{\\mathrm{def}}{}\\  \\sum_{n\n0}^{\\infty}  \\delta(t - n T) \nbe a sampling impulse train (also called a Dirac comb) and\n\\begin{align}\n  x_q(t) \\  &\\stackrel{\\mathrm{def}}{}\\  x(t) \\Delta_T(t) \n x(t) \\sum_{n=0}^{\\infty}  \\delta(t - n T) \\\\\n            &\\sum_{n\n0}^{\\infty} x(n T) \\delta(t - n T) \\sum_{n\n0}^{\\infty} x[n] \\delta(t - n T)\n\\end{align}\nbe the sampled representation of the continuous-time \n x[n] \\stackrel{\\mathrm{def}}  x(nT) ~.\n\nThe Laplace transform of the sampled signal  is\n\\begin{align}\n  X_q(s) &= \\int_{0^-}^\\infty x_q(t) e^{-s t} \\,dt \\\\\n         &\\int_{0^-}^\\infty \\sum_{n\n0}^\\infty x[n] \\delta(t - n T) e^{-s t} \\, dt \\\\\n         &\\sum_{n\n0}^\\infty x[n] \\int_{0^-}^\\infty \\delta(t - n T) e^{-s t} \\, dt \\\\\n         &\\sum_{n\n0}^\\infty x[n] e^{-n s T}~.\n\\end{align}\n\nThis is the precise definition of the unilateral Z-transform of the discrete function \n\n X(z) \\sum_{n\n0}^{\\infty} x[n] z^{-n} \nwith the substitution of .\n\nComparing the last two equations, we find the relationship between the unilateral Z-transform and the Laplace transform of the sampled signal,\nX_q(s)  X(z) \\Big|_{z\ne^{sT}}.\n\nThe similarity between the  and Laplace transforms is expanded upon in the theory of time scale calculus.\n\nBorel transform \n\nThe integral form of the Borel transform\n\nF(s) = \\int_0^\\infty f(z)e^{-sz}\\, dz\n\nis a special case of the Laplace transform for  an entire function of exponential type, meaning that\n\n|f(z)|\\le Ae^{B|z|}\n\nfor some constants  and .  The generalized Borel transform allows a different weighting function to be used, rather than the exponential function, to transform functions not of exponential type. Nachbin's theorem gives necessary and sufficient conditions for the Borel transform to be well defined.\n\nFundamental relationships \n\nSince an ordinary Laplace transform can be written as a special case of a two-sided transform, and since the two-sided transform can be written as the sum of two one-sided transforms, the theory of the Laplace-, Fourier-, Mellin-, and Z-transforms are at bottom the same subject. However, a different point of view and different characteristic problems are associated with each of these four major integral transforms.\n\nTable of selected Laplace transforms \n\nThe following table provides Laplace transforms for many common functions of a single variable. For definitions and explanations, see the Explanatory Notes at the end of the table.\n\nBecause the Laplace transform is a linear operator,\n\n* The Laplace transform of a sum is the sum of Laplace transforms of each term.\n\n: \\mathcal{L}\\{f(t) + g(t)\\}  = \\mathcal{L}\\{f(t)\\} + \\mathcal{L}\\{ g(t)\\}  \n\n* The Laplace transform of a multiple of a function is that multiple times the Laplace transformation of that function.\n\n: \\mathcal{L}\\{a f(t)\\}  = a \\mathcal{L}\\{ f(t)\\}\n\nUsing this linearity, and various trigonometric, hyperbolic, and complex number (etc.) properties and/or identities, some Laplace transforms can be obtained from others quicker than by using the definition directly.\n\nThe unilateral Laplace transform takes as input a function whose time domain is the non-negative reals, which is why all of the time domain functions in the table below are multiples of the Heaviside step function, .\n\nThe entries of the table that involve a time delay  are required to be causal (meaning that ).  A causal system is a system where the impulse response  is zero for all time  prior to . In general, the region of convergence for causal systems is not the same as that of anticausal systems.\n\n  \\  \n||  { 2\\alpha \\over \\alpha^2 - s^2 }  \n||  \n|| Frequency shift ofunit step\n\n|- style=\"text-align:center;\"\n| exponential approach \n|| ( 1-e^{-\\alpha t})  \\cdot u(t)  \\  \n|| \\frac{\\alpha}{s(s+\\alpha)}  \n|| \n|| Unit step minusexponential decay\n\n|- style=\"text-align:center;\"\n| sine \n||  \\sin(\\omega t) \\cdot u(t) \\  \n||  { \\omega \\over s^2 + \\omega^2  }  \n|| \n|| \n\n|- style=\"text-align:center;\"\n| cosine \n||  \\cos(\\omega t) \\cdot u(t) \\  \n||  { s \\over s^2 + \\omega^2  }  \n|| \n|| \n\n|- style=\"text-align:center;\"\n| hyperbolic sine \n||  \\sinh(\\alpha t) \\cdot u(t) \\  \n||  { \\alpha \\over s^2 - \\alpha^2 }  \n||  \n|| \n\n|- style=\"text-align:center;\"\n| hyperbolic cosine \n||  \\cosh(\\alpha t) \\cdot u(t) \\  \n||  { s \\over s^2 - \\alpha^2  }  \n|| \n|| \n\n|- style=\"text-align:center;\"\n| exponentially decaying  sine wave \n|| e^{-\\alpha t}  \\sin(\\omega t) \\cdot u(t) \\  \n||  { \\omega \\over (s+\\alpha )^2 + \\omega^2  }  \n||  \n|| \n\n|- style=\"text-align:center;\"\n| exponentially decaying  cosine wave \n|| e^{-\\alpha t}  \\cos(\\omega t) \\cdot u(t) \\  \n||  { s+\\alpha \\over (s+\\alpha )^2 + \\omega^2  }  \n|| \n|| \n\n|- style=\"text-align:center;\"\n| natural logarithm \n||  \\ln (t) \\cdot u(t)  \n||  - { 1 \\over s}\\, \\left[ \\ln(s)+\\gamma \\right]  \n||  \n|| \n\n|- style=\"text-align:center;\"\n| Bessel function  of the first kind,  of order n \n||  J_n( \\omega t) \\cdot u(t) \n|| \\frac{ \\left(\\sqrt{s^2+ \\omega^2}-s\\right)^n}{\\omega^n \\sqrt{s^2 + \\omega^2}} \n||     () \n|| \n\n|- style=\"text-align:center;\"\n| Error function \n||  \\operatorname{erf}(t) \\cdot u(t)  \n||  \\frac 1 s e^{(1/4)s^2} \\left(1 - \\operatorname{erf} \\frac s 2 \\right) \n|| \n|| \n\n|-\n| colspan=5|Explanatory notes:\n\n*  represents the Heaviside step function.\n*   represents the Dirac delta function.\n*  represents the Gamma function.\n*  is the Euler–Mascheroni constant.\n\n*  , a real number, typically represents time, although it can represent any independent dimension.\n*   is the complex frequency domain parameter, and   is its real part.\n*   are real numbers.\n*   is an integer.\n\n|}\n\ns-domain equivalent circuits and impedances \n\nThe Laplace transform is often used in circuit analysis, and simple conversions to the -domain of circuit elements can be made. Circuit elements can be transformed into impedances, very similar to phasor impedances.\n\nHere is a summary of equivalents:\n\nNote that the resistor is exactly the same in the time domain and the -domain. The sources are put in if there are initial conditions on the circuit elements. For example, if a capacitor has an initial voltage across it, or if the inductor has an initial current through it, the sources inserted in the -domain account for that.\n\nThe equivalents for current and voltage sources are simply derived from the transformations in the table above.\n\nExamples and applications \n\nThe Laplace transform is used frequently in engineering and physics; the output of a linear time-invariant system can be calculated by convolving its unit impulse response with the input signal. Performing this calculation in Laplace space turns the convolution into a multiplication; the latter being easier to solve because of its algebraic form. For more information, see control theory.\n\nThe Laplace transform can also be used to solve differential equations and is used extensively in mechanical engineering and electrical engineering.  The Laplace transform reduces a linear differential equation to an algebraic equation, which can then be solved by the formal rules of algebra.  The original differential equation can then be solved by applying the inverse Laplace transform.  The English electrical engineer Oliver Heaviside first proposed a similar scheme, although without using the Laplace transform; and the resulting operational calculus is credited as the Heaviside calculus.\n\nNuclear physics \n\nIn nuclear physics, the following fundamental relationship governs radioactive decay: the number of radioactive atoms  in a sample of a radioactive isotope decays at a rate proportional to .  This leads to the first order linear differential equation\n\n\\frac{dN}{dt} = -\\lambda N,\n\nwhere  is the decay constant. The Laplace transform can be used to solve this equation.\n\nRearranging the equation to one side, we have\n\n\\frac{dN}{dt} + \\lambda N = 0.\n\nNext, we take the Laplace transform of both sides of the equation:\n\n\\left( s \\tilde{N}(s) - N_0 \\right) + \\lambda \\tilde{N}(s) = 0,\n\nwhere\n\n\\tilde{N}(s) = \\mathcal{L}\\{N(t)\\}\n\nand\n\nN_0 = N(0).\n\nSolving, we find\n\n\\tilde{N}(s) = \\frac{N_0}{s + \\lambda}.\n\nFinally, we take the inverse Laplace transform to find the general solution\n\n\\begin{align}\n  N(t) &\\mathcal{L}^{-1} \\{\\tilde{N}(s)\\} \n \\mathcal{L}^{-1}\\! \\left\\{ \\frac{N_0}{s + \\lambda} \\right\\}\\\\\n       &= \\ N_0 e^{-\\lambda t},\n\\end{align}\n\nwhich is indeed the correct form for radioactive decay.\n\nComplex impedance of a capacitor \n\nIn the theory of electrical circuits, the current flow in a capacitor is proportional to the capacitance and rate of change in the electrical potential (in SI units). Symbolically, this is expressed by the differential equation\n\ni = C { dv \\over dt} ,\n\nwhere  is the capacitance (in farads) of the capacitor,  is the electric current (in amperes) through the capacitor as a function of time, and  is the voltage (in volts) across the terminals of the capacitor, also as a function of time.\n\nTaking the Laplace transform of this equation, we obtain\n\nI(s) = C(s V(s) - V_0),\n\nwhere\n\n\\begin{align}\n  I(s) &= \\mathcal{L} \\{ i(t) \\},\\\\\n  V(s) &= \\mathcal{L} \\{ v(t) \\},\n\\end{align}\n\nand\n\nV_0 v(t)\\Big|_{t\n0}. \\, \n\nSolving for  we have\n\nV(s) = { I(s) \\over sC } + { V_0 \\over s }.\n\nThe definition of the complex impedance  (in ohms) is the ratio of the complex voltage  divided by the complex current  while holding the initial state  at zero:\n\nZ(s) \\left. { V(s) \\over I(s) } \\right|_{V_0 \n 0}.\n\nUsing this definition and the previous equation, we find:\n\nZ(s) = \\frac{1}{sC}, \n\nwhich is the correct expression for the complex impedance of a capacitor.\n\nPartial fraction expansion \n\nConsider a linear time-invariant system with transfer function\nH(s) = \\frac{1}{(s + \\alpha)(s + \\beta)}.\n\nThe impulse response is simply the inverse Laplace transform of this transfer function:\nh(t) = \\mathcal{L}^{-1}\\{H(s)\\}.\n\nTo evaluate this inverse transform, we begin by expanding  using the method of partial fraction expansion,\n\\frac{1}{(s + \\alpha)(s + \\beta)} = { P \\over s + \\alpha } + { R \\over s+\\beta }.\n\nThe unknown constants  and  are the residues located at the corresponding poles of the transfer function. Each residue represents the relative contribution of that singularity to the transfer function's overall shape.\n\nBy the residue theorem, the inverse Laplace transform depends only upon the poles and their residues. To find the residue , we multiply both sides of the equation by  to get\n\\frac{1}{s + \\beta} = P  + { R (s + \\alpha) \\over s + \\beta }.\n\nThen by letting , the contribution from  vanishes and all that is left is\nP \\left.{1 \\over s+\\beta}\\right|_{s\n-\\alpha} = {1 \\over \\beta - \\alpha}.\n\nSimilarly, the residue  is given by\nR \\left.{1 \\over s + \\alpha}\\right|_{s\n-\\beta} = {1 \\over \\alpha - \\beta}.\n\nNote that\nR {-1 \\over \\beta - \\alpha} \n - P\nand so the substitution of  and  into the expanded expression for  gives\nH(s)  = \\left( \\frac{1}{\\beta - \\alpha} \\right) \\cdot \\left(  { 1 \\over s + \\alpha } - { 1  \\over s + \\beta }  \\right).\n\nFinally, using the linearity property and the known transform for exponential decay (see Item #3 in the Table of Laplace Transforms, above), we can take the inverse Laplace transform of  to obtain\nh(t) \\mathcal{L}^{-1}\\{H(s)\\} \n \\frac{1}{\\beta - \\alpha}\\left(e^{-\\alpha t} - e^{-\\beta t}\\right),\nwhich is the impulse response of the system.\n\n;Convolution\nThe same result can be achieved using the convolution property as if the system is a series of filters with transfer functions of  and . That is, the inverse of\n\nH(s) \\frac{1}{(s + a)(s + b)} \n \\frac{1}{s+a} \\cdot \\frac{1}{s + b}\n\nis\n\n \\mathcal{L}^{-1}\\! \\left\\{ \\frac{1}{s + a} \\right\\} * \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s + b} \\right\\} e^{-at} * e^{-bt} \n \\int_0^t e^{-ax}e^{-b(t - x)}\\, dx = \\frac{e^{-a t}-e^{-b t}}{b - a}.\n\nPhase delay \n\nStarting with the Laplace transform,\n\nX(s) = \\frac{s\\sin(\\varphi) + \\omega \\cos(\\varphi)}{s^2 + \\omega^2}\n\nwe find the inverse by first rearranging terms in the fraction:\n\n\\begin{align}\n  X(s) &= \\frac{s \\sin(\\varphi)}{s^2 + \\omega^2} + \\frac{\\omega \\cos(\\varphi)}{s^2 + \\omega^2} \\\\\n       &= \\sin(\\varphi) \\left(\\frac{s}{s^2 + \\omega^2} \\right) + \\cos(\\varphi) \\left(\\frac{\\omega}{s^2 + \\omega^2} \\right).\n\\end{align}\n\nWe are now able to take the inverse Laplace transform of our terms:\n\n\\begin{align}\n  x(t) &= \\sin(\\varphi) \\mathcal{L}^{-1}\\left\\{\\frac{s}{s^2 + \\omega^2} \\right\\} + \\cos(\\varphi) \\mathcal{L}^{-1}\\left\\{\\frac{\\omega}{s^2 + \\omega^2} \\right\\} \\\\\n       &= \\sin(\\varphi)\\cos(\\omega t) + \\sin(\\omega t)\\cos(\\varphi).\n\\end{align}\n\nThis is just the sine of the sum of the arguments, yielding:\n\nx(t) = \\sin (\\omega t + \\varphi).\n\nWe can apply similar logic to find that\n\n\\mathcal{L}^{-1} \\left\\{ \\frac{s\\cos\\varphi - \\omega \\sin\\varphi}{s^2 + \\omega^2} \\right\\} = \\cos{(\\omega t + \\varphi)}.\n\nDetermining structure of astronomical object from spectrum \n\nThe wide and general applicability of the Laplace transform and its inverse is illustrated by an application in astronomy which provides some information on the spatial distribution of matter of an astronomical source of radio-frequency thermal radiation too distant to resolve as more than a point, given its flux density spectrum, rather than relating the time domain with the spectrum (frequency domain).\n\nAssuming certain properties of the object, e.g. spherical shape and constant temperature, calculations based on carrying out an inverse Laplace transformation on the spectrum of the object can produce the only possible model of the distribution of matter in it (density as a function of distance from the center) consistent with the spectrum., and When independent information on the structure of an object is available, the inverse Laplace transform method has been found to be in good agreement.\n\nStatistical mechanics \n\nIn statistical mechanics, the Laplace transform of the energy distribution defines the partition function. Laplace transform. http://en.wikipedia.org/?curid=18610."
  }
}
