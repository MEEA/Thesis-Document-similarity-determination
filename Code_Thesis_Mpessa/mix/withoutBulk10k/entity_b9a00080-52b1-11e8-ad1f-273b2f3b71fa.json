{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=1368",
  "eid" : "b9a00080-52b1-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778391176,
  "textBody" : "An assembly (or assembler) language,[http://www-01.ibm.com/support/knowledgecenter/SSLTBW_2.1.0/com.ibm.zos.v2r1.asma400/asmr102112.htm Assembler language], IBM Knowledge center often abbreviated asm, is a low-level programming language for a computer, or other programmable device, in which there is a very strong (but often not one-to-one) correspondence between the language and the architecture's machine code instructions.  Each assembly language is specific to a particular computer architecture. In contrast, most high-level programming languages are generally portable across multiple architectures but require interpreting or compiling. Assembly language may also be called symbolic machine code.\n\nAssembly language is converted into executable machine code by a utility program referred to as an assembler. The conversion process is referred to as assembly, or assembling the source code. Assembly time is the computational step where an assembler is run.\n\nAssembly language uses a mnemonic to represent each low-level machine instruction or opcode, typically also each architectural register, flag, etc. Many operations require one or more operands in order to form a complete instruction and most assemblers can take expressions of numbers and named constants as well as registers and labels as operands, freeing the programmer from tedious repetitive calculations. Depending on the architecture, these elements may also be combined for specific instructions or addressing modes using offsets or other data as well as fixed addresses. Many assemblers offer additional mechanisms to facilitate program development, to control the assembly process, and to aid debugging.\n\nTerminology\n\n* A macro assembler includes a macroinstruction facility so that (parameterized) assembly language text can be represented by a name, and that name can be used to insert the expanded text into other code.\n* A cross assembler (see also cross compiler) is an assembler that is run on a computer or operating system (the host system) of a different type from the system on which the resulting code is to run (the target system). Cross-assembling facilitates the development of programs for systems that do not have the resources to support software development, such as an embedded system. In such a case, the resulting object code must be transferred to the target system, either via read-only memory (ROM, EPROM, etc.) or a data link using an exact bit-by-bit copy of the object code or a text-based representation of that code, such as Motorola S-record or Intel HEX.\n* A high-level assembler is a program that provides language abstractions more often associated with high-level languages, such as advanced control structures (IF/THEN/ELSE, DO CASE, etc.) and high-level abstract data types, including structures/records, unions, classes, and sets.\n* A microassembler is a program that helps prepare a microprogram, called firmware, to control the low level operation of a computer.\n* A meta-assembler is a term used in some circles for \"a program that accepts the syntactic and semantic description of an assembly language, and generates an assembler for that language.\"[http://www.encyclopedia.com/doc/1O11-metaassembler.html (John Daintith, ed.) A Dictionary of Computing: \"meta-assembler\"]\n\nKey concepts\n\nAssembler\n\nAn assembler program creates object code by translating combinations of mnemonics and syntax for operations and addressing modes into their numerical equivalents. This representation typically includes an operation code (\"opcode\") as well as other control bits and data. The assembler also calculates constant expressions and resolves symbolic names for memory locations and other entities.David Salomon (1993). [http://www.davidsalomon.name/assem.advertis/asl.pdf Assemblers and Loaders] The use of symbolic references is a key feature of assemblers, saving tedious calculations and manual address updates after program modifications. Most assemblers also include macro facilities for performing textual substitution – e.g., to generate common short sequences of instructions as inline, instead of called subroutines.\n\nSome assemblers may also be able to perform some simple types of instruction set-specific optimizations. One concrete example of this may be the ubiquitous x86 assemblers from various vendors. Most of them are able to perform jump-instruction replacements (long jumps replaced by short or relative jumps) in any number of passes, on request. Others may even do simple rearrangement or insertion of instructions, such as some assemblers for RISC architectures that can help optimize a sensible instruction scheduling to exploit the CPU pipeline as efficiently as possible.\n\nLike early programming languages such as Fortran, Algol, Cobol and Lisp, assemblers have been available since the 1950s and the first generations of text based computer interfaces. However, assemblers came first as they are far simpler to write than compilers for high-level languages. This is because each mnemonic along with the addressing modes and operands of an instruction translates rather directly into the numeric representations of that particular instruction, without much context or analysis. There have also been several classes of translators and semi automatic code generators with properties similar to both assembly and high level languages, with speedcode as perhaps one of the better known examples.\n\nThere may be several assemblers with different syntax for a particular CPU or instruction set architecture. For instance, an instruction to add memory data to a register in a x86-family processor might be add eax,[ebx], in original Intel syntax, whereas this would be written addl (%ebx),%eax in the AT&T syntax used by the GNU Assembler. Despite different appearances, different syntactic forms generally generate the same numeric machine code, see further below. A single assembler may also have different modes in order to support variations in syntactic forms as well as their exact semantic interpretations (such as FASM-syntax, TASM-syntax, ideal mode etc., in the special case of x86 assembly programming).\n\nNumber of passes\n\nThere are two types of assemblers based on how many passes through the source are needed  (how many times the assembler reads the source) to produce the object file.\n* One-pass assemblers go through the source code once. Any symbol used before it is defined will require \"errata\" at the end of the object code (or, at least, no earlier than the point where the symbol is defined) telling the linker or the loader to \"go back\" and overwrite a placeholder which had been left where the as yet undefined symbol was used.\n* Multi-pass assemblers create a table with all symbols and their values in the first passes, then use the table in later passes to generate code.\nIn both cases, the assembler must be able to determine the size of each instruction on the initial passes in order to calculate the addresses of subsequent symbols. This means that if the size of an operation referring to an operand defined later depends on the type or distance of the operand, the assembler will make a pessimistic estimate when first encountering the operation, and if necessary pad it with one or more \"no-operation\" instructions in a later pass or the errata. In an assembler with peephole optimization, addresses may be recalculated between passes to allow replacing pessimistic code with code tailored to the exact distance from the target.\n\nThe original reason for the use of one-pass assemblers was speed of assembly – often a second pass would require rewinding and rereading the program source on tape or rereading a deck of cards or punched paper tape. Later computers with much larger memories (especially disc storage), had the space to perform all necessary processing without such re-reading. The advantage of the multi-pass assembler is that the absence of errata makes the linking process (or the program load if the assembler directly produces executable code) faster.\n\nExample: in the following code snippet a one-pass assembler would be able to determine the address of the backward reference BKWD when assembling statement S2, but would not be able to determine the address of the forward reference FWD when assembling the branch statement S1; indeed FWD may be undefined. A two-pass assembler would determine both addresses in pass 1, so they would be known when generating code in pass 2,\n    B    \n   ...\n    EQU *\n   ...\n   EQU *\n   ...\n     B   \n\nHigh-level assemblers\n\nMore sophisticated high-level assemblers provide language abstractions such as:\n* High-level procedure/function declarations and invocations\n* Advanced control structures\n* High-level abstract data types, including structures/records, unions, classes, and sets\n* Sophisticated macro processing (although available on ordinary assemblers since the late 1950s for IBM 700 series and since the 1960s for IBM/360, amongst other machines)\n* Object-oriented programming features such as classes, objects, abstraction, polymorphism, and inheritanceHyde, Randall. \"Chapter 12 – Classes and Objects\". The Art of Assembly Language, 2nd Edition. No Starch Press. © 2010.\nSee Language design below for more details.\n\nAssembly language\n\nA program written in assembly language consists of a series of mnemonic processor instructions and meta-statements (known variously as directives, pseudo-instructions and pseudo-ops), comments and data. Assembly language instructions usually consist of an opcode mnemonic followed by a list of data, arguments or parameters. These are translated by an assembler into machine language instructions that can be loaded into memory and executed.\n\nFor example, the instruction below tells an x86/IA-32 processor to move an immediate 8-bit value into a register. The binary code for this instruction is 10110 followed by a 3-bit identifier for which register to use. The identifier for the AL register is 000, so the following machine code loads the AL register with the data 01100001.\n 10110000 01100001\nThis binary computer code can be made more human-readable by expressing it in hexadecimal as follows.\n B0 61\nHere, B0 means 'Move a copy of the following value into AL, and 61 is a hexadecimal representation of the value 01100001, which is 97 in decimal. Assembly language for the 8086 family provides the mnemonic MOV (an abbreviation of move) for instructions such as this, so the machine code above can be written as follows in assembly language, complete with an explanatory comment if required, after the semicolon. This is much easier to read and to remember.\nMOV AL, 61h       ; Load AL with 97 decimal (61 hex)\n\nIn some assembly languages the same mnemonic such as MOV may be used for a family of related instructions for loading, copying and moving data, whether these are immediate values, values in registers, or memory locations pointed to by values in registers.  Other assemblers may use separate opcode mnemonics such as L for \"move memory to register\", ST for \"move register to memory\", LR for \"move register to register\", MVI for \"move immediate operand to memory\", etc.\n\nThe x86 opcode 10110000 (B0) copies an 8-bit value into the AL register, while 10110001 (B1) moves it into CL and 10110010 (B2) does so into DL. Assembly language examples for these follow.\n\nMOV AL, 1h        ; Load AL with immediate value 1\nMOV CL, 2h        ; Load CL with immediate value 2\nMOV DL, 3h        ; Load DL with immediate value 3\n\nThe syntax of MOV can also be more complex as the following examples show.\n\nMOV EAX, [EBX]\t  ; Move the 4 bytes in memory at the address contained in EBX into EAX\nMOV [ESI+EAX], CL ; Move the contents of CL into the byte at address ESI+EAX\n\nIn each case, the MOV mnemonic is translated directly into an opcode in the ranges 88-8E, A0-A3, B0-B8, C6 or C7 by an assembler, and the programmer does not have to know or remember which.\n\nTransforming assembly language into machine code is the job of an assembler, and the reverse can at least partially be achieved by a disassembler. Unlike high-level languages, there is a one-to-one correspondence between many simple assembly statements and machine language instructions. However, in some cases, an assembler may provide pseudoinstructions (essentially macros) which expand into several machine language instructions to provide commonly needed functionality. For example, for a machine that lacks a \"branch if greater or equal\" instruction, an assembler may provide a pseudoinstruction that expands to the machine's \"set if less than\" and \"branch if zero (on the result of the set instruction)\". Most full-featured assemblers also provide a rich macro language (discussed below) which is used by vendors and programmers to generate more complex code and data sequences.\n\nEach computer architecture has its own machine language.  Computers differ in the number and type of operations they support, in the different sizes and numbers of registers, and in the representations of data in storage. While most general-purpose computers are able to carry out essentially the same functionality, the ways they do so differ; the corresponding assembly languages reflect these differences.\n\nMultiple sets of mnemonics or assembly-language syntax may exist for a single instruction set, typically instantiated in different assembler programs. In these cases, the most popular one is usually that supplied by the manufacturer and used in its documentation.\n\nLanguage design\n\nBasic elements\n\nThere is a large degree of diversity in the way the authors of assemblers categorize statements and in the nomenclature that they use. In particular, some describe anything other than a machine mnemonic or extended mnemonic as a pseudo-operation (pseudo-op). A typical assembly language consists of 3 types of instruction statements that are used to define program operations:\n*Opcode mnemonics\n*Data definitions\n*Assembly directives\n\nOpcode mnemonics and extended mnemonics\n\nInstructions (statements) in assembly language are generally very simple, unlike those in high-level languages. Generally, a mnemonic is a symbolic name for a single executable machine language instruction (an opcode), and there is at least one opcode mnemonic defined for each machine language instruction. Each instruction typically consists of an operation or opcode plus zero or more operands. Most instructions refer to a single value, or a pair of values.  Operands can be immediate (value coded in the instruction itself), registers specified in the instruction or implied, or the addresses of data located elsewhere in storage. This is determined by the underlying processor architecture: the assembler merely reflects how this architecture works. Extended mnemonics are often used to specify a combination of an opcode with a specific operand, e.g., the System/360 assemblers use  as an extended mnemonic for  with a mask of 15 and  (\"NO OPeration\" – do nothing for one step) for  with a mask of 0.\n\nExtended mnemonics are often used to support specialized uses of instructions, often for purposes not obvious from the instruction name. For example, many CPU's do not have an explicit NOP instruction, but do have instructions that can be used for the purpose. In 8086 CPUs the instruction  is used for , with  being a pseudo-opcode to encode the instruction . Some disassemblers recognize this and will decode the  instruction as . Similarly, IBM assemblers for System/360 and System/370 use the extended mnemonics  and  for  and  with zero masks.  For the SPARC architecture, these are known as synthetic instructions.\n\nSome assemblers also support simple built-in macro-instructions that generate two or more machine instructions. For instance, with some Z80 assemblers the instruction  is recognized to generate  followed by .[http://www.z80.de/z80/z80code.htm Z80 Op Codes for ZINT]. Z80.de. Retrieved on 2013-07-21. These are sometimes known as pseudo-opcodes.\n\nMnemonics are arbitrary symbols; in 1985 the IEEE published Standard 694 for a uniform set of mnemonics to be used by all assemblers. The standard has since been withdrawn.\n\nData directives\n\nThere are instructions used to define data elements to hold data and variables.  They define the type of data, the length and the alignment of data. These instructions can also define whether the data is available to outside programs (programs assembled separately) or only to the program in which the data section is defined. Some assemblers classify these as pseudo-ops.\n\nAssembly directives\n\nAssembly directives, also called pseudo-opcodes, pseudo-operations or pseudo-ops, are commands given to an assembler \"directing it to perform operations other than assembling instructions.\". Directives affect how the assembler operates and \"may affect the object code, the symbol table, the listing file, and the values of internal assembler parameters.\"  Sometimes the term pseudo-opcode is reserved for directives that generate object code, such as those that generate data.\n\nThe names of pseudo-ops often start with a dot to distinguish them from machine instructions.  Pseudo-ops can make the assembly of the program dependent on parameters input by a programmer, so that one program can be assembled different ways, perhaps for different applications. Or, a pseudo-op can be used to manipulate presentation of a program to make it easier to read and maintain. Another common use of pseudo-ops is to reserve storage areas for run-time data and optionally initialize their contents to known values.\n\nSymbolic assemblers let programmers associate arbitrary names (labels or symbols) with memory locations and various constants. Usually, every constant and variable is given a name so instructions can reference those locations by name, thus promoting self-documenting code. In executable code, the name of each subroutine is associated with its entry point, so any calls to a subroutine can use its name. Inside subroutines, GOTO destinations are given labels. Some assemblers support local symbols which are lexically distinct from normal symbols (e.g., the use of \"10$\" as a GOTO destination).\n\nSome assemblers, such as NASM, provide flexible symbol management, letting programmers manage different namespaces, automatically calculate offsets within data structures, and assign labels that refer to literal values or the result of simple computations performed by the assembler. Labels can also be used to initialize constants and variables with relocatable addresses.\n\nAssembly languages, like most other computer languages, allow comments to be added to program source code that will be ignored during assembly. Judicious commenting is essential in assembly language programs, as the meaning and purpose of a sequence of binary machine instructions can be difficult to determine. The \"raw\" (uncommented) assembly language generated by compilers or disassemblers is quite difficult to read when changes must be made.\n\nMacros\n\nMany assemblers support predefined macros, and others support programmer-defined (and repeatedly re-definable) macros involving sequences of text lines in which variables and constants are embedded. This sequence of text lines may include opcodes or directives. Once a macro has been defined its name may be used in place of a mnemonic. When the assembler processes such a statement, it replaces the statement with the text lines associated with that macro, then processes them as if they existed in the source code file (including, in some assemblers, expansion of any macros existing in the replacement text). Macros in this sense date to IBM autocoders of the 1950s.\n\"The following minor restriction or limitation is in effect with regard to the use of 1401 Autocoder when coding macro nstructions ...\"\n\nIn assembly language, the term \"macro\" represents a more comprehensive concept than it does in some other contexts, such as in the C programming language, where its #define directive typically is used to create short single line macros. Assembler macro instructions, like macros in PL/I and some other languages, can be lengthy \"programs\" by themselves, executed by interpretation by the assembler during assembly.\n\nSince macros can have 'short' names but expand to several or indeed many lines of code, they can be used to make assembly language programs appear to be far shorter, requiring fewer lines of source code, as with higher level languages. They can also be used to add higher levels of structure to assembly programs, optionally introduce embedded debugging code via parameters and other similar features.\n\nMacro assemblers often allow macros to take parameters. Some assemblers include quite sophisticated macro languages, incorporating such high-level language elements as optional parameters, symbolic variables, conditionals, string manipulation, and arithmetic operations, all usable during the execution of a given macro, and allowing macros to save context or exchange information. Thus a macro might generate numerous assembly language instructions or data definitions, based on the macro arguments. This could be used to generate record-style data structures or \"unrolled\" loops, for example, or could generate entire algorithms based on complex parameters. For instance, a \"sort\" macro could accept the specification of a complex sort key and generate code crafted for that specific key, not needing the run-time tests that would be required  for a general procedure interpreting the specification. An organization using assembly language that has been heavily extended using such a macro suite can be considered to be working in a higher-level language, since such programmers are not working with a computer's lowest-level conceptual elements. Underlining this point, macros were used to implement an early virtual machine in SNOBOL4 (1967), which was written in the SNOBOL Implementation Language (SIL), an assembly language for a virtual machine, which was then targeted to physical machines by transpiled to a native assembler via a macro assembler.Griswold, Ralph E.  The Macro Implementation of SNOBOL4.  San Francisco, CA: W. H. Freeman and Company, 1972 (), Chapter 1. This allowed a high degree of portability for the time.\n\nMacros were used to customize large scale software systems for specific customers in the mainframe era and were also used by customer personnel to satisfy their employers' needs by making specific versions of manufacturer operating systems. This was done, for example, by systems programmers working with IBM's Conversational Monitor System / Virtual Machine (VM/CMS) and with IBM's \"real time transaction processing\" add-ons, Customer Information Control System CICS, and ACP/TPF, the airline/financial system that began in the 1970s and still runs many large computer reservation systems (CRS) and credit card systems today.\n\nIt is also possible to use solely the macro processing abilities of an assembler to generate code written in completely different languages, for example, to generate a version of a program in COBOL using a pure macro assembler program containing lines of COBOL code inside assembly time operators instructing the assembler to generate arbitrary code. IBM OS/360 uses macros to perform system generation. The user specifies options by coding a series of assembler macros.  Assembling these macros generates a job stream to build the system, including job control language and utility control statements.\n\nThis is because, as was realized in the 1960s, the concept of \"macro processing\" is independent of the concept of \"assembly\", the former being in modern terms more word processing, text processing, than generating object code. The concept of macro processing appeared, and appears, in the C programming language, which supports \"preprocessor instructions\" to set variables, and make conditional tests on their values. Note that unlike certain previous macro processors inside assemblers, the C preprocessor is not Turing-complete because it lacks the ability to either loop or \"go to\", the latter allowing programs to loop.\n\nDespite the power of macro processing, it fell into disuse in many high level languages (major exceptions being C, C++ and PL/I) while remaining a perennial for assemblers.\n\nMacro parameter substitution is strictly by name: at macro processing time, the value of a parameter is textually substituted for its name. The most famous class of bugs resulting was the use of a parameter that itself was an expression and not a simple name when the macro writer expected a name. In the macro:\n\n foo: macro a\n load a*b\n\nthe intention was that the caller would provide the name of a variable, and the \"global\" variable or constant b would be used to multiply \"a\". If foo is called with the parameter a-c, the macro expansion of load a-c*b occurs.  To avoid any possible ambiguity, users of macro processors can parenthesize formal parameters inside macro definitions, or callers can parenthesize the input parameters.\n\nSupport for structured programming\n\nSome assemblers have incorporated structured programming elements to encode execution flow. The earliest example of this approach was in the Concept-14 macro set, originally proposed by Dr. Harlan Mills (March 1970), and implemented by Marvin Kessler at IBM's Federal Systems Division, which extended the S/360 macro assembler with IF/ELSE/ENDIF and similar control flow blocks. This was a way to reduce or eliminate the use of GOTO operations in assembly code, one of the main factors causing spaghetti code in assembly language. This approach was widely accepted in the early '80s (the latter days of large-scale assembly language use).\n\nA curious design was A-natural, a \"stream-oriented\" assembler for 8080/Z80 processors from Whitesmiths Ltd. (developers of the Unix-like Idris operating system, and what was reported to be the first commercial C compiler). The language was classified as an assembler, because it worked with raw machine elements such as opcodes, registers, and memory references; but it incorporated an expression syntax to indicate execution order. Parentheses and other special symbols, along with block-oriented structured programming constructs, controlled the sequence of the generated instructions. A-natural was built as the object language of a C compiler, rather than for hand-coding, but its logical syntax won some fans.\n\nThere has been little apparent demand for more sophisticated assemblers since the decline of large-scale assembly language development. In spite of that, they are still being developed and applied in cases where resource constraints or peculiarities in the target system's architecture prevent the effective use of higher-level languages.\n\nAssemblers with a strong macro engine allow structured programming via macros, such as the switch macro provided with the Masm32 package (note this code is a complete program):\n\ninclude \\masm32\\include\\masm32rt.inc\t; use the Masm32 library\n\n.code\ndemomain:\n  REPEAT 20\n\tswitch rv(nrandom, 9)\t; generate a number between 0 and 8\n\tmov ecx, 7\n\tcase 0\n\t\tprint \"case 0\"\n\tcase ecx\t\t\t\t; in contrast to most other programming languages,\n\t\tprint \"case 7\"\t\t; the Masm32 switch allows \"variable cases\"\n\tcase 1 .. 3\n\t\t.if eax\n1\n\t\t\tprint \"case 1\"\n\t\t.elseif eax\n2\n\t\t\tprint \"case 2\"\n\t\t.else\n\t\t\tprint \"cases 1 to 3: other\"\n\t\t.endif\n\tcase 4, 6, 8\n\t\tprint \"cases 4, 6 or 8\"\n\tdefault\n\t\tmov ebx, 19\t\t     ; print 20 stars\n\t\t.Repeat\n\t\t\tprint \"*\"\n\t\t\tdec ebx\n\t\t.Until Sign?\t\t ; loop until the sign flag is set\n\tendsw\n\tprint chr$(13, 10)\n  ENDM\n  exit\nend demomain\n\nUse of assembly language\n\nHistorical perspective\n\nAssembly languages, and the use of the word assembly,  date to the introduction of the stored-program computer. The first assembly language was developed in 1947 by Kathleen Booth for the ARC2 at Birkbeck, University of London following work with John von Neumann and Herman Goldstine at the Institute for Advanced Study. The Electronic Delay Storage Automatic Calculator (EDSAC) had an assembler called initial orders featuring one-letter mnemonics in 1949. SOAP (Symbolic Optimal Assembly Program) was an assembly language for the IBM 650 computer written by Stan Poley in 1955.\n\nAssembly languages eliminate much of the error-prone, tedious, and time-consuming first-generation programming needed with the earliest computers, freeing programmers from tedium such as remembering numeric codes and calculating addresses. They were once widely used for all sorts of programming. However, by the 1980s (1990s on microcomputers), their use had largely been supplanted by higher-level languages, in the search for improved programming productivity. Today assembly language is still used for direct hardware manipulation, access to specialized processor instructions, or to address critical performance issues. Typical uses are device drivers, low-level embedded systems, and real-time systems.\n\nHistorically, numerous programs have been written entirely in assembly language. The Burroughs MCP (1961) was the first computer for which an operating system was not developed entirely in assembly language; it was written in Executive Systems Problem Oriented Language (ESPOL), an Algol dialect. Many commercial applications were written in assembly language as well, including a large amount of the IBM mainframe software written by large corporations. COBOL, FORTRAN and some PL/I eventually displaced much of this work, although a number of large organizations retained assembly-language application infrastructures well into the 1990s.\n\nMost early microcomputers relied on hand-coded assembly language, including most operating systems and large applications. This was because these systems had severe resource constraints, imposed idiosyncratic memory and display architectures, and provided limited, buggy system services. Perhaps more important was the lack of first-class high-level language compilers suitable for microcomputer use. A psychological factor may have also played a role: the first generation of microcomputer programmers retained a hobbyist, \"wires and pliers\" attitude.\n\nIn a more commercial context, the biggest reasons for using assembly language were minimal bloat (size), minimal overhead, greater speed, and reliability.\n\nTypical examples of large assembly language programs from this time are IBM PC DOS operating systems, the Turbo Pascal compiler and early applications such as the spreadsheet program Lotus 1-2-3. According to some industry insiders, the assembly language was the best computer language to use to get the best performance out of the Sega Saturn, a console that was notoriously challenging to develop and program games for.[http://www.eidolons-inn.net/tiki-index.php?page=SegaBase+Saturn Eidolon's Inn: SegaBase Saturn] The 1993 arcade game NBA Jam is another example.\n\nAssembly language has long been the primary development language for many popular home computers of the 1980s and 1990s (such as the MSX,  Sinclair ZX Spectrum, Commodore 64, Commodore Amiga, and Atari ST). This was in large part because interpreted BASIC dialects on these systems offered insufficient execution speed, as well as insufficient facilities to take full advantage of the available hardware on these systems. Some systems even have an integrated development environment (IDE) with highly advanced debugging and macro facilities. Some compilers available for the Radio Shack TRS-80 and its successors had the capability to combine inline assembly source with high-level program statements. Upon compilation a built-in assembler produced inline machine code.\n\nCurrent usage\n\nThere have always been debates over the usefulness and performance of assembly language relative to high-level languages. Assembly language has specific niche uses where it is important; see below. , the TIOBE index of programming language popularity ranks assembly language at 11, ahead of Visual Basic, for example. Assembler can be used to optimize for speed or optimize for size. In the case of speed optimization, modern optimizing compilers are claimed  to render high-level languages into code that can run as fast as hand-written assembly, despite the counter-examples that can be found. The complexity of modern processors and memory sub-systems makes effective optimization increasingly difficult for compilers, as well as assembly programmers. Moreover, increasing processor performance has meant that most CPUs sit idle most of the time, with delays caused by predictable bottlenecks such as cache misses, I/O operations and paging. This has made raw code execution speed a non-issue for many programmers.\n\nThere are some situations in which developers might choose to use assembly language:\n* A stand-alone executable of compact size is required that must execute without recourse to the run-time components or libraries associated with a high-level language; this is perhaps the most common situation. For example, firmware for telephones, automobile fuel and ignition systems, air-conditioning control systems, security systems, and sensors.\n* Code that must interact directly with the hardware, for example in device drivers and interrupt handlers.\n* In an embedded processor or DSP, high-repetition interrupts require the shortest number of cycles per interrupt, such as an interrupt that occurs 1000 or 10000 times a second.\n* Programs that need to use processor-specific instructions not implemented in a compiler. A common example is the bitwise rotation instruction at the core of many encryption algorithms, as well as querying the parity of a byte or the 4-bit carry of an addition.\n* Programs that create vectorized functions for programs in higher-level languages such as C.  In the higher-level language this is sometimes aided by compiler intrinsic functions which map directly to SIMD mnemonics, but nevertheless result in a one-to-one assembly conversion specific for the given vector processor.\n* Programs requiring extreme optimization, for example an inner loop in a processor-intensive algorithm. Game programmers take advantage of the abilities of hardware features in systems, enabling games to run faster. Also large scientific simulations require highly optimized algorithms, e.g. linear algebra with BLAS or discrete cosine transformation (e.g. SIMD assembly version from x264)\n* Situations where no high-level language exists, on a new or specialized processor, for example.\n* Programs that need precise timing such as\n** real-time programs such as simulations, flight navigation systems, and medical equipment. For example, in a fly-by-wire system, telemetry must be interpreted and acted upon within strict time constraints. Such systems must eliminate sources of unpredictable delays, which may be created by (some) interpreted languages, automatic garbage collection, paging operations, or preemptive multitasking. However, some higher-level languages incorporate run-time components and operating system interfaces that can introduce such delays. Choosing assembly or lower-level languages for such systems gives programmers greater visibility and control over processing details.\n** cryptographic algorithms that must always take strictly the same time to execute, preventing timing attacks.\n* Modify and extend legacy code written for IBM mainframe computers.\n* Situations where complete control over the environment is required, in extremely high security situations where nothing can be taken for granted.\n* Computer viruses, bootloaders, certain device drivers, or other items very close to the hardware or low-level operating system.\n*  Instruction set simulators for monitoring, tracing and debugging where additional overhead is kept to a minimum\n* Reverse-engineering and modifying program files such as\n**existing binaries that may or may not have originally been written in a high-level language, for example when trying to recreate programs for which source code is not available or has been lost, or cracking copy protection of proprietary software.\n** Video games (also termed ROM hacking), which is possible via several methods. The most widely employed method is altering program code at the assembly language level.\n* Self-modifying code, to which assembly language lends itself well.\n* Games and other software for graphing calculators.\n\nAssembly language is still taught in most computer science and electronic engineering programs. Although few programmers today regularly work with assembly language as a tool, the underlying concepts remain very important. Such fundamental topics as binary arithmetic, memory allocation, stack processing, character set encoding, interrupt processing, and compiler design would be hard to study in detail without a grasp of how a computer operates at the hardware level. Since a computer's behavior is fundamentally defined by its instruction set, the logical way to learn such concepts is to study an assembly language. Most modern computers have similar instruction sets. Therefore, studying a single assembly language is sufficient to learn: I) the basic concepts; II) to recognize situations where the use of assembly language might be appropriate; and III) to see how efficient executable code can be created from high-level languages. This is analogous to children needing to learn the basic arithmetic operations (e.g., long division), although calculators are widely used for all except the most trivial calculations.\n\nTypical applications\n\n*Assembly language is typically used in a system's boot code, the low-level code that initializes and tests the system hardware prior to booting the operating system and is often stored in ROM.  (BIOS on IBM-compatible PC systems and CP/M is an example.)\n*Some compilers translate high-level languages into assembly first before fully compiling, allowing the assembly code to be viewed for debugging and optimization purposes.\n*Some compilers for relatively low-level languages, such as Pascal or C, allow the programmer to embed assembly language directly in the source code. Programs using such facilities can then construct abstractions using different assembly language on each hardware platform. The system's portable code can then use these processor-specific components through a uniform interface.\n*Assembly language is useful in reverse engineering. Many programs are distributed only in machine code form which is straightforward to translate into assembly language, but more difficult to translate into a higher-level language. Tools such as the Interactive Disassembler make extensive use of disassembly for such a purpose. This technique is used by hackers to crack commercial software, and competitors to produce software with similar results from competing companies.\n*Assembly language is used to enhance speed of execution, especially in early Personal Computers with limited processing power and RAM.\n*Assemblers can be used to generate blocks of data, with no high-level language overhead, from formatted and commented source code, to be used by other code.",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Assembly language" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=1368" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "An assembly (or assembler) language,[http://www-01.ibm.com/support/knowledgecenter/SSLTBW_2.1.0/com.ibm.zos.v2r1.asma400/asmr102112.htm Assembler language], IBM Knowledge center often abbreviated asm, is a low-level programming language for a computer, or other programmable device, in which there is a very strong (but often not one-to-one) correspondence between the language and the architecture's machine code instructions.  Each assembly language is specific to a particular computer architecture. In contrast, most high-level programming languages are generally portable across multiple architectures but require interpreting or compiling. Assembly language may also be called symbolic machine code.\n\nAssembly language is converted into executable machine code by a utility program referred to as an assembler. The conversion process is referred to as assembly, or assembling the source code. Assembly time is the computational step where an assembler is run.\n\nAssembly language uses a mnemonic to represent each low-level machine instruction or opcode, typically also each architectural register, flag, etc. Many operations require one or more operands in order to form a complete instruction and most assemblers can take expressions of numbers and named constants as well as registers and labels as operands, freeing the programmer from tedious repetitive calculations. Depending on the architecture, these elements may also be combined for specific instructions or addressing modes using offsets or other data as well as fixed addresses. Many assemblers offer additional mechanisms to facilitate program development, to control the assembly process, and to aid debugging.\n\nTerminology\n\n* A macro assembler includes a macroinstruction facility so that (parameterized) assembly language text can be represented by a name, and that name can be used to insert the expanded text into other code.\n* A cross assembler (see also cross compiler) is an assembler that is run on a computer or operating system (the host system) of a different type from the system on which the resulting code is to run (the target system). Cross-assembling facilitates the development of programs for systems that do not have the resources to support software development, such as an embedded system. In such a case, the resulting object code must be transferred to the target system, either via read-only memory (ROM, EPROM, etc.) or a data link using an exact bit-by-bit copy of the object code or a text-based representation of that code, such as Motorola S-record or Intel HEX.\n* A high-level assembler is a program that provides language abstractions more often associated with high-level languages, such as advanced control structures (IF/THEN/ELSE, DO CASE, etc.) and high-level abstract data types, including structures/records, unions, classes, and sets.\n* A microassembler is a program that helps prepare a microprogram, called firmware, to control the low level operation of a computer.\n* A meta-assembler is a term used in some circles for \"a program that accepts the syntactic and semantic description of an assembly language, and generates an assembler for that language.\"[http://www.encyclopedia.com/doc/1O11-metaassembler.html (John Daintith, ed.) A Dictionary of Computing: \"meta-assembler\"]\n\nKey concepts\n\nAssembler\n\nAn assembler program creates object code by translating combinations of mnemonics and syntax for operations and addressing modes into their numerical equivalents. This representation typically includes an operation code (\"opcode\") as well as other control bits and data. The assembler also calculates constant expressions and resolves symbolic names for memory locations and other entities.David Salomon (1993). [http://www.davidsalomon.name/assem.advertis/asl.pdf Assemblers and Loaders] The use of symbolic references is a key feature of assemblers, saving tedious calculations and manual address updates after program modifications. Most assemblers also include macro facilities for performing textual substitution – e.g., to generate common short sequences of instructions as inline, instead of called subroutines.\n\nSome assemblers may also be able to perform some simple types of instruction set-specific optimizations. One concrete example of this may be the ubiquitous x86 assemblers from various vendors. Most of them are able to perform jump-instruction replacements (long jumps replaced by short or relative jumps) in any number of passes, on request. Others may even do simple rearrangement or insertion of instructions, such as some assemblers for RISC architectures that can help optimize a sensible instruction scheduling to exploit the CPU pipeline as efficiently as possible.\n\nLike early programming languages such as Fortran, Algol, Cobol and Lisp, assemblers have been available since the 1950s and the first generations of text based computer interfaces. However, assemblers came first as they are far simpler to write than compilers for high-level languages. This is because each mnemonic along with the addressing modes and operands of an instruction translates rather directly into the numeric representations of that particular instruction, without much context or analysis. There have also been several classes of translators and semi automatic code generators with properties similar to both assembly and high level languages, with speedcode as perhaps one of the better known examples.\n\nThere may be several assemblers with different syntax for a particular CPU or instruction set architecture. For instance, an instruction to add memory data to a register in a x86-family processor might be add eax,[ebx], in original Intel syntax, whereas this would be written addl (%ebx),%eax in the AT&T syntax used by the GNU Assembler. Despite different appearances, different syntactic forms generally generate the same numeric machine code, see further below. A single assembler may also have different modes in order to support variations in syntactic forms as well as their exact semantic interpretations (such as FASM-syntax, TASM-syntax, ideal mode etc., in the special case of x86 assembly programming).\n\nNumber of passes\n\nThere are two types of assemblers based on how many passes through the source are needed  (how many times the assembler reads the source) to produce the object file.\n* One-pass assemblers go through the source code once. Any symbol used before it is defined will require \"errata\" at the end of the object code (or, at least, no earlier than the point where the symbol is defined) telling the linker or the loader to \"go back\" and overwrite a placeholder which had been left where the as yet undefined symbol was used.\n* Multi-pass assemblers create a table with all symbols and their values in the first passes, then use the table in later passes to generate code.\nIn both cases, the assembler must be able to determine the size of each instruction on the initial passes in order to calculate the addresses of subsequent symbols. This means that if the size of an operation referring to an operand defined later depends on the type or distance of the operand, the assembler will make a pessimistic estimate when first encountering the operation, and if necessary pad it with one or more \"no-operation\" instructions in a later pass or the errata. In an assembler with peephole optimization, addresses may be recalculated between passes to allow replacing pessimistic code with code tailored to the exact distance from the target.\n\nThe original reason for the use of one-pass assemblers was speed of assembly – often a second pass would require rewinding and rereading the program source on tape or rereading a deck of cards or punched paper tape. Later computers with much larger memories (especially disc storage), had the space to perform all necessary processing without such re-reading. The advantage of the multi-pass assembler is that the absence of errata makes the linking process (or the program load if the assembler directly produces executable code) faster.\n\nExample: in the following code snippet a one-pass assembler would be able to determine the address of the backward reference BKWD when assembling statement S2, but would not be able to determine the address of the forward reference FWD when assembling the branch statement S1; indeed FWD may be undefined. A two-pass assembler would determine both addresses in pass 1, so they would be known when generating code in pass 2,\n    B    \n   ...\n    EQU *\n   ...\n   EQU *\n   ...\n     B   \n\nHigh-level assemblers\n\nMore sophisticated high-level assemblers provide language abstractions such as:\n* High-level procedure/function declarations and invocations\n* Advanced control structures\n* High-level abstract data types, including structures/records, unions, classes, and sets\n* Sophisticated macro processing (although available on ordinary assemblers since the late 1950s for IBM 700 series and since the 1960s for IBM/360, amongst other machines)\n* Object-oriented programming features such as classes, objects, abstraction, polymorphism, and inheritanceHyde, Randall. \"Chapter 12 – Classes and Objects\". The Art of Assembly Language, 2nd Edition. No Starch Press. © 2010.\nSee Language design below for more details.\n\nAssembly language\n\nA program written in assembly language consists of a series of mnemonic processor instructions and meta-statements (known variously as directives, pseudo-instructions and pseudo-ops), comments and data. Assembly language instructions usually consist of an opcode mnemonic followed by a list of data, arguments or parameters. These are translated by an assembler into machine language instructions that can be loaded into memory and executed.\n\nFor example, the instruction below tells an x86/IA-32 processor to move an immediate 8-bit value into a register. The binary code for this instruction is 10110 followed by a 3-bit identifier for which register to use. The identifier for the AL register is 000, so the following machine code loads the AL register with the data 01100001.\n 10110000 01100001\nThis binary computer code can be made more human-readable by expressing it in hexadecimal as follows.\n B0 61\nHere, B0 means 'Move a copy of the following value into AL, and 61 is a hexadecimal representation of the value 01100001, which is 97 in decimal. Assembly language for the 8086 family provides the mnemonic MOV (an abbreviation of move) for instructions such as this, so the machine code above can be written as follows in assembly language, complete with an explanatory comment if required, after the semicolon. This is much easier to read and to remember.\nMOV AL, 61h       ; Load AL with 97 decimal (61 hex)\n\nIn some assembly languages the same mnemonic such as MOV may be used for a family of related instructions for loading, copying and moving data, whether these are immediate values, values in registers, or memory locations pointed to by values in registers.  Other assemblers may use separate opcode mnemonics such as L for \"move memory to register\", ST for \"move register to memory\", LR for \"move register to register\", MVI for \"move immediate operand to memory\", etc.\n\nThe x86 opcode 10110000 (B0) copies an 8-bit value into the AL register, while 10110001 (B1) moves it into CL and 10110010 (B2) does so into DL. Assembly language examples for these follow.\n\nMOV AL, 1h        ; Load AL with immediate value 1\nMOV CL, 2h        ; Load CL with immediate value 2\nMOV DL, 3h        ; Load DL with immediate value 3\n\nThe syntax of MOV can also be more complex as the following examples show.\n\nMOV EAX, [EBX]\t  ; Move the 4 bytes in memory at the address contained in EBX into EAX\nMOV [ESI+EAX], CL ; Move the contents of CL into the byte at address ESI+EAX\n\nIn each case, the MOV mnemonic is translated directly into an opcode in the ranges 88-8E, A0-A3, B0-B8, C6 or C7 by an assembler, and the programmer does not have to know or remember which.\n\nTransforming assembly language into machine code is the job of an assembler, and the reverse can at least partially be achieved by a disassembler. Unlike high-level languages, there is a one-to-one correspondence between many simple assembly statements and machine language instructions. However, in some cases, an assembler may provide pseudoinstructions (essentially macros) which expand into several machine language instructions to provide commonly needed functionality. For example, for a machine that lacks a \"branch if greater or equal\" instruction, an assembler may provide a pseudoinstruction that expands to the machine's \"set if less than\" and \"branch if zero (on the result of the set instruction)\". Most full-featured assemblers also provide a rich macro language (discussed below) which is used by vendors and programmers to generate more complex code and data sequences.\n\nEach computer architecture has its own machine language.  Computers differ in the number and type of operations they support, in the different sizes and numbers of registers, and in the representations of data in storage. While most general-purpose computers are able to carry out essentially the same functionality, the ways they do so differ; the corresponding assembly languages reflect these differences.\n\nMultiple sets of mnemonics or assembly-language syntax may exist for a single instruction set, typically instantiated in different assembler programs. In these cases, the most popular one is usually that supplied by the manufacturer and used in its documentation.\n\nLanguage design\n\nBasic elements\n\nThere is a large degree of diversity in the way the authors of assemblers categorize statements and in the nomenclature that they use. In particular, some describe anything other than a machine mnemonic or extended mnemonic as a pseudo-operation (pseudo-op). A typical assembly language consists of 3 types of instruction statements that are used to define program operations:\n*Opcode mnemonics\n*Data definitions\n*Assembly directives\n\nOpcode mnemonics and extended mnemonics\n\nInstructions (statements) in assembly language are generally very simple, unlike those in high-level languages. Generally, a mnemonic is a symbolic name for a single executable machine language instruction (an opcode), and there is at least one opcode mnemonic defined for each machine language instruction. Each instruction typically consists of an operation or opcode plus zero or more operands. Most instructions refer to a single value, or a pair of values.  Operands can be immediate (value coded in the instruction itself), registers specified in the instruction or implied, or the addresses of data located elsewhere in storage. This is determined by the underlying processor architecture: the assembler merely reflects how this architecture works. Extended mnemonics are often used to specify a combination of an opcode with a specific operand, e.g., the System/360 assemblers use  as an extended mnemonic for  with a mask of 15 and  (\"NO OPeration\" – do nothing for one step) for  with a mask of 0.\n\nExtended mnemonics are often used to support specialized uses of instructions, often for purposes not obvious from the instruction name. For example, many CPU's do not have an explicit NOP instruction, but do have instructions that can be used for the purpose. In 8086 CPUs the instruction  is used for , with  being a pseudo-opcode to encode the instruction . Some disassemblers recognize this and will decode the  instruction as . Similarly, IBM assemblers for System/360 and System/370 use the extended mnemonics  and  for  and  with zero masks.  For the SPARC architecture, these are known as synthetic instructions.\n\nSome assemblers also support simple built-in macro-instructions that generate two or more machine instructions. For instance, with some Z80 assemblers the instruction  is recognized to generate  followed by .[http://www.z80.de/z80/z80code.htm Z80 Op Codes for ZINT]. Z80.de. Retrieved on 2013-07-21. These are sometimes known as pseudo-opcodes.\n\nMnemonics are arbitrary symbols; in 1985 the IEEE published Standard 694 for a uniform set of mnemonics to be used by all assemblers. The standard has since been withdrawn.\n\nData directives\n\nThere are instructions used to define data elements to hold data and variables.  They define the type of data, the length and the alignment of data. These instructions can also define whether the data is available to outside programs (programs assembled separately) or only to the program in which the data section is defined. Some assemblers classify these as pseudo-ops.\n\nAssembly directives\n\nAssembly directives, also called pseudo-opcodes, pseudo-operations or pseudo-ops, are commands given to an assembler \"directing it to perform operations other than assembling instructions.\". Directives affect how the assembler operates and \"may affect the object code, the symbol table, the listing file, and the values of internal assembler parameters.\"  Sometimes the term pseudo-opcode is reserved for directives that generate object code, such as those that generate data.\n\nThe names of pseudo-ops often start with a dot to distinguish them from machine instructions.  Pseudo-ops can make the assembly of the program dependent on parameters input by a programmer, so that one program can be assembled different ways, perhaps for different applications. Or, a pseudo-op can be used to manipulate presentation of a program to make it easier to read and maintain. Another common use of pseudo-ops is to reserve storage areas for run-time data and optionally initialize their contents to known values.\n\nSymbolic assemblers let programmers associate arbitrary names (labels or symbols) with memory locations and various constants. Usually, every constant and variable is given a name so instructions can reference those locations by name, thus promoting self-documenting code. In executable code, the name of each subroutine is associated with its entry point, so any calls to a subroutine can use its name. Inside subroutines, GOTO destinations are given labels. Some assemblers support local symbols which are lexically distinct from normal symbols (e.g., the use of \"10$\" as a GOTO destination).\n\nSome assemblers, such as NASM, provide flexible symbol management, letting programmers manage different namespaces, automatically calculate offsets within data structures, and assign labels that refer to literal values or the result of simple computations performed by the assembler. Labels can also be used to initialize constants and variables with relocatable addresses.\n\nAssembly languages, like most other computer languages, allow comments to be added to program source code that will be ignored during assembly. Judicious commenting is essential in assembly language programs, as the meaning and purpose of a sequence of binary machine instructions can be difficult to determine. The \"raw\" (uncommented) assembly language generated by compilers or disassemblers is quite difficult to read when changes must be made.\n\nMacros\n\nMany assemblers support predefined macros, and others support programmer-defined (and repeatedly re-definable) macros involving sequences of text lines in which variables and constants are embedded. This sequence of text lines may include opcodes or directives. Once a macro has been defined its name may be used in place of a mnemonic. When the assembler processes such a statement, it replaces the statement with the text lines associated with that macro, then processes them as if they existed in the source code file (including, in some assemblers, expansion of any macros existing in the replacement text). Macros in this sense date to IBM autocoders of the 1950s.\n\"The following minor restriction or limitation is in effect with regard to the use of 1401 Autocoder when coding macro nstructions ...\"\n\nIn assembly language, the term \"macro\" represents a more comprehensive concept than it does in some other contexts, such as in the C programming language, where its #define directive typically is used to create short single line macros. Assembler macro instructions, like macros in PL/I and some other languages, can be lengthy \"programs\" by themselves, executed by interpretation by the assembler during assembly.\n\nSince macros can have 'short' names but expand to several or indeed many lines of code, they can be used to make assembly language programs appear to be far shorter, requiring fewer lines of source code, as with higher level languages. They can also be used to add higher levels of structure to assembly programs, optionally introduce embedded debugging code via parameters and other similar features.\n\nMacro assemblers often allow macros to take parameters. Some assemblers include quite sophisticated macro languages, incorporating such high-level language elements as optional parameters, symbolic variables, conditionals, string manipulation, and arithmetic operations, all usable during the execution of a given macro, and allowing macros to save context or exchange information. Thus a macro might generate numerous assembly language instructions or data definitions, based on the macro arguments. This could be used to generate record-style data structures or \"unrolled\" loops, for example, or could generate entire algorithms based on complex parameters. For instance, a \"sort\" macro could accept the specification of a complex sort key and generate code crafted for that specific key, not needing the run-time tests that would be required  for a general procedure interpreting the specification. An organization using assembly language that has been heavily extended using such a macro suite can be considered to be working in a higher-level language, since such programmers are not working with a computer's lowest-level conceptual elements. Underlining this point, macros were used to implement an early virtual machine in SNOBOL4 (1967), which was written in the SNOBOL Implementation Language (SIL), an assembly language for a virtual machine, which was then targeted to physical machines by transpiled to a native assembler via a macro assembler.Griswold, Ralph E.  The Macro Implementation of SNOBOL4.  San Francisco, CA: W. H. Freeman and Company, 1972 (), Chapter 1. This allowed a high degree of portability for the time.\n\nMacros were used to customize large scale software systems for specific customers in the mainframe era and were also used by customer personnel to satisfy their employers' needs by making specific versions of manufacturer operating systems. This was done, for example, by systems programmers working with IBM's Conversational Monitor System / Virtual Machine (VM/CMS) and with IBM's \"real time transaction processing\" add-ons, Customer Information Control System CICS, and ACP/TPF, the airline/financial system that began in the 1970s and still runs many large computer reservation systems (CRS) and credit card systems today.\n\nIt is also possible to use solely the macro processing abilities of an assembler to generate code written in completely different languages, for example, to generate a version of a program in COBOL using a pure macro assembler program containing lines of COBOL code inside assembly time operators instructing the assembler to generate arbitrary code. IBM OS/360 uses macros to perform system generation. The user specifies options by coding a series of assembler macros.  Assembling these macros generates a job stream to build the system, including job control language and utility control statements.\n\nThis is because, as was realized in the 1960s, the concept of \"macro processing\" is independent of the concept of \"assembly\", the former being in modern terms more word processing, text processing, than generating object code. The concept of macro processing appeared, and appears, in the C programming language, which supports \"preprocessor instructions\" to set variables, and make conditional tests on their values. Note that unlike certain previous macro processors inside assemblers, the C preprocessor is not Turing-complete because it lacks the ability to either loop or \"go to\", the latter allowing programs to loop.\n\nDespite the power of macro processing, it fell into disuse in many high level languages (major exceptions being C, C++ and PL/I) while remaining a perennial for assemblers.\n\nMacro parameter substitution is strictly by name: at macro processing time, the value of a parameter is textually substituted for its name. The most famous class of bugs resulting was the use of a parameter that itself was an expression and not a simple name when the macro writer expected a name. In the macro:\n\n foo: macro a\n load a*b\n\nthe intention was that the caller would provide the name of a variable, and the \"global\" variable or constant b would be used to multiply \"a\". If foo is called with the parameter a-c, the macro expansion of load a-c*b occurs.  To avoid any possible ambiguity, users of macro processors can parenthesize formal parameters inside macro definitions, or callers can parenthesize the input parameters.\n\nSupport for structured programming\n\nSome assemblers have incorporated structured programming elements to encode execution flow. The earliest example of this approach was in the Concept-14 macro set, originally proposed by Dr. Harlan Mills (March 1970), and implemented by Marvin Kessler at IBM's Federal Systems Division, which extended the S/360 macro assembler with IF/ELSE/ENDIF and similar control flow blocks. This was a way to reduce or eliminate the use of GOTO operations in assembly code, one of the main factors causing spaghetti code in assembly language. This approach was widely accepted in the early '80s (the latter days of large-scale assembly language use).\n\nA curious design was A-natural, a \"stream-oriented\" assembler for 8080/Z80 processors from Whitesmiths Ltd. (developers of the Unix-like Idris operating system, and what was reported to be the first commercial C compiler). The language was classified as an assembler, because it worked with raw machine elements such as opcodes, registers, and memory references; but it incorporated an expression syntax to indicate execution order. Parentheses and other special symbols, along with block-oriented structured programming constructs, controlled the sequence of the generated instructions. A-natural was built as the object language of a C compiler, rather than for hand-coding, but its logical syntax won some fans.\n\nThere has been little apparent demand for more sophisticated assemblers since the decline of large-scale assembly language development. In spite of that, they are still being developed and applied in cases where resource constraints or peculiarities in the target system's architecture prevent the effective use of higher-level languages.\n\nAssemblers with a strong macro engine allow structured programming via macros, such as the switch macro provided with the Masm32 package (note this code is a complete program):\n\ninclude \\masm32\\include\\masm32rt.inc\t; use the Masm32 library\n\n.code\ndemomain:\n  REPEAT 20\n\tswitch rv(nrandom, 9)\t; generate a number between 0 and 8\n\tmov ecx, 7\n\tcase 0\n\t\tprint \"case 0\"\n\tcase ecx\t\t\t\t; in contrast to most other programming languages,\n\t\tprint \"case 7\"\t\t; the Masm32 switch allows \"variable cases\"\n\tcase 1 .. 3\n\t\t.if eax\n1\n\t\t\tprint \"case 1\"\n\t\t.elseif eax\n2\n\t\t\tprint \"case 2\"\n\t\t.else\n\t\t\tprint \"cases 1 to 3: other\"\n\t\t.endif\n\tcase 4, 6, 8\n\t\tprint \"cases 4, 6 or 8\"\n\tdefault\n\t\tmov ebx, 19\t\t     ; print 20 stars\n\t\t.Repeat\n\t\t\tprint \"*\"\n\t\t\tdec ebx\n\t\t.Until Sign?\t\t ; loop until the sign flag is set\n\tendsw\n\tprint chr$(13, 10)\n  ENDM\n  exit\nend demomain\n\nUse of assembly language\n\nHistorical perspective\n\nAssembly languages, and the use of the word assembly,  date to the introduction of the stored-program computer. The first assembly language was developed in 1947 by Kathleen Booth for the ARC2 at Birkbeck, University of London following work with John von Neumann and Herman Goldstine at the Institute for Advanced Study. The Electronic Delay Storage Automatic Calculator (EDSAC) had an assembler called initial orders featuring one-letter mnemonics in 1949. SOAP (Symbolic Optimal Assembly Program) was an assembly language for the IBM 650 computer written by Stan Poley in 1955.\n\nAssembly languages eliminate much of the error-prone, tedious, and time-consuming first-generation programming needed with the earliest computers, freeing programmers from tedium such as remembering numeric codes and calculating addresses. They were once widely used for all sorts of programming. However, by the 1980s (1990s on microcomputers), their use had largely been supplanted by higher-level languages, in the search for improved programming productivity. Today assembly language is still used for direct hardware manipulation, access to specialized processor instructions, or to address critical performance issues. Typical uses are device drivers, low-level embedded systems, and real-time systems.\n\nHistorically, numerous programs have been written entirely in assembly language. The Burroughs MCP (1961) was the first computer for which an operating system was not developed entirely in assembly language; it was written in Executive Systems Problem Oriented Language (ESPOL), an Algol dialect. Many commercial applications were written in assembly language as well, including a large amount of the IBM mainframe software written by large corporations. COBOL, FORTRAN and some PL/I eventually displaced much of this work, although a number of large organizations retained assembly-language application infrastructures well into the 1990s.\n\nMost early microcomputers relied on hand-coded assembly language, including most operating systems and large applications. This was because these systems had severe resource constraints, imposed idiosyncratic memory and display architectures, and provided limited, buggy system services. Perhaps more important was the lack of first-class high-level language compilers suitable for microcomputer use. A psychological factor may have also played a role: the first generation of microcomputer programmers retained a hobbyist, \"wires and pliers\" attitude.\n\nIn a more commercial context, the biggest reasons for using assembly language were minimal bloat (size), minimal overhead, greater speed, and reliability.\n\nTypical examples of large assembly language programs from this time are IBM PC DOS operating systems, the Turbo Pascal compiler and early applications such as the spreadsheet program Lotus 1-2-3. According to some industry insiders, the assembly language was the best computer language to use to get the best performance out of the Sega Saturn, a console that was notoriously challenging to develop and program games for.[http://www.eidolons-inn.net/tiki-index.php?page=SegaBase+Saturn Eidolon's Inn: SegaBase Saturn] The 1993 arcade game NBA Jam is another example.\n\nAssembly language has long been the primary development language for many popular home computers of the 1980s and 1990s (such as the MSX,  Sinclair ZX Spectrum, Commodore 64, Commodore Amiga, and Atari ST). This was in large part because interpreted BASIC dialects on these systems offered insufficient execution speed, as well as insufficient facilities to take full advantage of the available hardware on these systems. Some systems even have an integrated development environment (IDE) with highly advanced debugging and macro facilities. Some compilers available for the Radio Shack TRS-80 and its successors had the capability to combine inline assembly source with high-level program statements. Upon compilation a built-in assembler produced inline machine code.\n\nCurrent usage\n\nThere have always been debates over the usefulness and performance of assembly language relative to high-level languages. Assembly language has specific niche uses where it is important; see below. , the TIOBE index of programming language popularity ranks assembly language at 11, ahead of Visual Basic, for example. Assembler can be used to optimize for speed or optimize for size. In the case of speed optimization, modern optimizing compilers are claimed  to render high-level languages into code that can run as fast as hand-written assembly, despite the counter-examples that can be found. The complexity of modern processors and memory sub-systems makes effective optimization increasingly difficult for compilers, as well as assembly programmers. Moreover, increasing processor performance has meant that most CPUs sit idle most of the time, with delays caused by predictable bottlenecks such as cache misses, I/O operations and paging. This has made raw code execution speed a non-issue for many programmers.\n\nThere are some situations in which developers might choose to use assembly language:\n* A stand-alone executable of compact size is required that must execute without recourse to the run-time components or libraries associated with a high-level language; this is perhaps the most common situation. For example, firmware for telephones, automobile fuel and ignition systems, air-conditioning control systems, security systems, and sensors.\n* Code that must interact directly with the hardware, for example in device drivers and interrupt handlers.\n* In an embedded processor or DSP, high-repetition interrupts require the shortest number of cycles per interrupt, such as an interrupt that occurs 1000 or 10000 times a second.\n* Programs that need to use processor-specific instructions not implemented in a compiler. A common example is the bitwise rotation instruction at the core of many encryption algorithms, as well as querying the parity of a byte or the 4-bit carry of an addition.\n* Programs that create vectorized functions for programs in higher-level languages such as C.  In the higher-level language this is sometimes aided by compiler intrinsic functions which map directly to SIMD mnemonics, but nevertheless result in a one-to-one assembly conversion specific for the given vector processor.\n* Programs requiring extreme optimization, for example an inner loop in a processor-intensive algorithm. Game programmers take advantage of the abilities of hardware features in systems, enabling games to run faster. Also large scientific simulations require highly optimized algorithms, e.g. linear algebra with BLAS or discrete cosine transformation (e.g. SIMD assembly version from x264)\n* Situations where no high-level language exists, on a new or specialized processor, for example.\n* Programs that need precise timing such as\n** real-time programs such as simulations, flight navigation systems, and medical equipment. For example, in a fly-by-wire system, telemetry must be interpreted and acted upon within strict time constraints. Such systems must eliminate sources of unpredictable delays, which may be created by (some) interpreted languages, automatic garbage collection, paging operations, or preemptive multitasking. However, some higher-level languages incorporate run-time components and operating system interfaces that can introduce such delays. Choosing assembly or lower-level languages for such systems gives programmers greater visibility and control over processing details.\n** cryptographic algorithms that must always take strictly the same time to execute, preventing timing attacks.\n* Modify and extend legacy code written for IBM mainframe computers.\n* Situations where complete control over the environment is required, in extremely high security situations where nothing can be taken for granted.\n* Computer viruses, bootloaders, certain device drivers, or other items very close to the hardware or low-level operating system.\n*  Instruction set simulators for monitoring, tracing and debugging where additional overhead is kept to a minimum\n* Reverse-engineering and modifying program files such as\n**existing binaries that may or may not have originally been written in a high-level language, for example when trying to recreate programs for which source code is not available or has been lost, or cracking copy protection of proprietary software.\n** Video games (also termed ROM hacking), which is possible via several methods. The most widely employed method is altering program code at the assembly language level.\n* Self-modifying code, to which assembly language lends itself well.\n* Games and other software for graphing calculators.\n\nAssembly language is still taught in most computer science and electronic engineering programs. Although few programmers today regularly work with assembly language as a tool, the underlying concepts remain very important. Such fundamental topics as binary arithmetic, memory allocation, stack processing, character set encoding, interrupt processing, and compiler design would be hard to study in detail without a grasp of how a computer operates at the hardware level. Since a computer's behavior is fundamentally defined by its instruction set, the logical way to learn such concepts is to study an assembly language. Most modern computers have similar instruction sets. Therefore, studying a single assembly language is sufficient to learn: I) the basic concepts; II) to recognize situations where the use of assembly language might be appropriate; and III) to see how efficient executable code can be created from high-level languages. This is analogous to children needing to learn the basic arithmetic operations (e.g., long division), although calculators are widely used for all except the most trivial calculations.\n\nTypical applications\n\n*Assembly language is typically used in a system's boot code, the low-level code that initializes and tests the system hardware prior to booting the operating system and is often stored in ROM.  (BIOS on IBM-compatible PC systems and CP/M is an example.)\n*Some compilers translate high-level languages into assembly first before fully compiling, allowing the assembly code to be viewed for debugging and optimization purposes.\n*Some compilers for relatively low-level languages, such as Pascal or C, allow the programmer to embed assembly language directly in the source code. Programs using such facilities can then construct abstractions using different assembly language on each hardware platform. The system's portable code can then use these processor-specific components through a uniform interface.\n*Assembly language is useful in reverse engineering. Many programs are distributed only in machine code form which is straightforward to translate into assembly language, but more difficult to translate into a higher-level language. Tools such as the Interactive Disassembler make extensive use of disassembly for such a purpose. This technique is used by hackers to crack commercial software, and competitors to produce software with similar results from competing companies.\n*Assembly language is used to enhance speed of execution, especially in early Personal Computers with limited processing power and RAM.\n*Assemblers can be used to generate blocks of data, with no high-level language overhead, from formatted and commented source code, to be used by other code. Assembly language. http://en.wikipedia.org/?curid=1368."
  }
}
