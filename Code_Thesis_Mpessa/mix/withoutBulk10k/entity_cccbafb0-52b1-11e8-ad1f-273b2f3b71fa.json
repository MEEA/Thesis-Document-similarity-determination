{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=4320",
  "eid" : "cccbafb0-52b1-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778423339,
  "textBody" : "In computer science, binary search trees (BST), sometimes called ordered or sorted binary trees, are a particular type of container: data structures that store \"items\" (such as numbers, names etc.) in memory. They allow fast lookup, addition and removal of items, and can be used to implement either dynamic sets of items, or lookup tables that allow finding an item by its key (e.g., finding the phone number of a person by name).\n\nBinary search trees keep their keys in sorted order, so that lookup and other operations can use the principle of binary search: when looking for a key in a tree (or a place to insert a new key), they traverse the tree from root to leaf, making comparisons to keys stored in the nodes of the tree and deciding, on the basis of the comparison, to continue searching in the left or right subtrees. On average, this means that each comparison allows the operations to skip about half of the tree, so that each lookup, insertion or deletion takes time proportional to the logarithm of the number of items stored in the tree. This is much better than the linear time required to find items by key in an (unsorted) array, but slower than the corresponding operations on hash tables.\n\nSeveral variants of the binary search tree have been studied in computer science; this article deals primarily with the basic type, making references to more advanced types when appropriate.\n\nDefinition\n\nA binary search tree is a rooted binary tree, whose internal nodes each store a key (and optionally, an associated value) and each have two distinguished sub-trees, commonly denoted left and right. The tree additionally satisfies the binary search property, which states that the key in each node must be greater than or equal to any key stored in the left sub-tree, and less than or equal to any key stored in the right sub-tree. (The leaves (final nodes) of the tree contain no key and have no structure to distinguish them from one another. Leaves are commonly represented by a special  or  symbol, a  pointer, etc.)\n\nFrequently, the information represented by each node is a record rather than a single data element.  However, for sequencing purposes, nodes are compared according to their keys rather than any part of their associated records.\n\nThe major advantage of binary search trees over other data structures is that the related sorting algorithms and search algorithms such as in-order traversal can be very efficient; they are also easy to code.\n\nBinary search trees are a fundamental data structure used to construct more abstract data structures such as sets, multisets, and associative arrays.\n* When inserting or searching for an element in a binary search tree, the key of each visited node has to be compared with the key of the element to be inserted or found.\n* The shape of the binary search tree depends entirely on the order of insertions and deletions, and can become degenerate.\n* After a long intermixed sequence of random insertion and deletion, the expected height of the tree approaches square root of the number of keys, , which grows much faster than .\n* There has been a lot of research to prevent degeneration of the tree resulting in worst case time complexity of  (for details see section #Types).\n\nOrder relation \n\nBinary search requires an order relation by which every element (item) can be compared with every other element in the sense of a total preorder. The part of the element which effectively takes place in the comparison is called its key. Whether duplicates, i.e. different elements with same key, shall be allowed in the tree or not, does not depend on the order relation, but on the application only.\n\nIn the context of binary search trees a total preorder is realized most flexibly by means of a three-way comparison subroutine.\n\nOperations\n\nBinary search trees support three main operations: insertion of elements, deletion of elements, and lookup (checking whether a key is present).\n\nSearching\n\nSearching a binary search tree for a specific key can be programmed recursively or iteratively.\n\nWe begin by examining the root node. If the tree is null, the key we are searching for does not exist in the tree. Otherwise, if the key equals that of the root, the search is successful and we return the node. If the key is less than that of the root, we search the left subtree. Similarly, if the key is greater than that of the root, we search the right subtree. This process is repeated until the key is found or the remaining subtree is null. If the searched key is not found after a null subtree is reached, then the key is not present in the tree. This is easily expressed as a recursive algorithm (implemented in Python):\n\ndef search_recursively(key, node):\n    if node is None or node.key \n key:\n        return node\n    if key  node.key\n    return search_recursively(key, node.right)\n\nThe same algorithm can be implemented iteratively:\n\ndef search_iteratively(key, node): \n    current_node = node\n    while current_node is not None:\n        if key \n current_node.key:\n            return current_node\n        if key  current_node.key:\n            current_node = current_node.right\n    return current_node\n\nThese two examples rely on the order relation being a total order.\n\nIf the order relation is only a total preorder a reasonable extension of the functionality is the following: also in case of equality search down to the leaves in a direction specified by the user. A binary tree sort equipped with such a comparison function becomes stable.\n\nBecause in the worst case this algorithm must search from the root of the tree to the leaf farthest from the root, the search operation takes time proportional to the tree's height (see tree terminology). On average, binary search trees with  nodes have  height. However, in the worst case, binary search trees can have  height, when the unbalanced tree resembles a linked list (degenerate tree).\n\nInsertion\n\nInsertion begins as a search would begin; if the key is not equal to that of the root, we search the left or right subtrees as before. Eventually, we will reach an external node and add the new key-value pair (here encoded as a record 'newNode') as its right or left child, depending on the node's key. In other words, we examine the root and recursively insert the new node to the left subtree if its key is less than that of the root, or the right subtree if its key is greater than or equal to the root.\n\nHere's how a typical binary search tree insertion might be performed in a binary tree in C++:\n\nNode* insert(Node* root, int key, int value) {\n  if (!root) \n    root = new Node(key, value);\n  else if (key key)\n    root->left = insert(root->left, key, value);\n  else  // key >= root->key\n    root->right = insert(root->right, key, value);\n  return root;\n}\n\nThe above destructive procedural variant modifies the tree in place. It uses only constant heap space (and the iterative version uses constant stack space as well), but the prior version of the tree is lost. Alternatively, as in the following Python example, we can reconstruct all ancestors of the inserted node; any reference to the original tree root remains valid, making the tree a persistent data structure:\n\ndef binary_tree_insert(node, key, value):\n   if node is None:\n       return NodeTree(None, key, value, None)\n   if key \n node.key:\n       return NodeTree(node.left, key, value, node.right)\n   if key \n\nThe part that is rebuilt uses  space in the average case and  in the worst case.\n\nIn either version, this operation requires time proportional to the height of the tree in the worst case, which is  time in the average case over all trees, but  time in the worst case.\n\nAnother way to explain insertion is that in order to insert a new node in the tree, its key is first compared with that of the root. If its key is less than the root's, it is then compared with the key of the root's left child. If its key is greater, it is compared with the root's right child. This process continues, until the new node is compared with a leaf node, and then it is added as this node's right or left child, depending on its key: if the key is less than the leaf's key, then it is inserted as the leaf's left child, otherwise as the leaf's right child.\n\nThere are other ways of inserting nodes into a binary tree, but this is the only way of inserting nodes at the leaves and at the same time preserving the BST structure.\n\nDeletion\n\nWhen removing a node from a binary search tree it is mandatory to maintain the in-order sequence of the nodes.\nThere are many possibilities to do this. However, the following method which has been proposed by T. Hibbard in 1962s. Robert Sedgewick, Kevin Wayne: [http://bookshelf.theopensourcelibrary.org/AlgorithmsFourthEdition.pdf Algorithms Fourth Edition.] Pearson Education, 2011, , p. 410. guarantees that the heights of the subject subtrees are changed by at most one.\nThere are three possible cases to consider:\n* Deleting a node with no children: simply remove the node from the tree.\n* Deleting a node with one child: remove the node and replace it with its child.\n* Deleting a node with two children: call the node to be deleted D.  Do not delete D.  Instead, choose either its in-order predecessor node or its in-order successor node as replacement node E (s. figure). Copy the user values of E to D.Of course, a generic software package has to work the other way around: It has to leave the user data untouched and to furnish E with all the BST links to and from D. If E does not have a child simply remove E from its previous parent G. If E has a child, say F, it is a right child. Replace E with F at E's parent.\n\nIn all cases, when D happens to be the root, make the replacement node root again.\n\nBroadly speaking, nodes with children are harder to delete. As with all binary trees, a node's in-order successor is its right subtree's left-most child, and a node's in-order predecessor is the left subtree's right-most child. In either case, this node will have only one or no child at all. Delete it according to one of the two simpler cases above.\n\nConsistently using the in-order successor or the in-order predecessor for every instance of the two-child case can lead to an unbalanced tree, so some implementations select one or the other at different times.\n\nRuntime analysis: Although this operation does not always traverse the tree down to a leaf, this is always a possibility; thus in the worst case it requires time proportional to the height of the tree. It does not require more even when the node has two children, since it still follows a single path and does not visit any node twice.\n\ndef find_min(self):   # Gets minimum node in a subtree\n    current_node = self\n    while current_node.left_child:\n        current_node = current_node.left_child\n    return current_node\n\ndef replace_node_in_parent(self, new_value=None):\n    if self.parent:\n        if self \n self.parent.left_child:\n            self.parent.left_child = new_value\n        else:\n            self.parent.right_child = new_value\n    if new_value:\n        new_value.parent = self.parent\n\ndef binary_tree_delete(self, key):\n    if key  self.key:\n        self.right_child.binary_tree_delete(key)\n        return\n    # delete the key here\n    if self.left_child and self.right_child: # if both children are present\n        successor = self.right_child.find_min()\n        self.key = successor.key\n        successor.binary_tree_delete(successor.key)\n    elif self.left_child:   # if the node has only a *left* child\n        self.replace_node_in_parent(self.left_child)\n    elif self.right_child:  # if the node has only a *right* child\n        self.replace_node_in_parent(self.right_child)\n    else:\n        self.replace_node_in_parent(None) # this node has no children\n\nTraversal\n\nOnce the binary search tree has been created, its elements can be retrieved in-order by recursively traversing the left subtree of the root node, accessing the node itself, then recursively traversing the right subtree of the node, continuing this pattern with each node in the tree as it's recursively accessed. As with all binary trees, one may conduct a pre-order traversal or a post-order traversal, but neither are likely to be useful for binary search trees. An in-order traversal of a binary search tree will always result in a sorted list of node items (numbers, strings or other comparable items).\n\nThe code for in-order traversal in Python is given below. It will call callback (some function the programmer wishes to call on the node's value, such as printing to the screen) for every node in the tree.\n\ndef traverse_binary_tree(node, callback):\n    if node is None:\n        return\n    traverse_binary_tree(node.leftChild, callback)\n    callback(node.value)\n    traverse_binary_tree(node.rightChild, callback)\n\nTraversal requires  time, since it must visit every node. This algorithm is also , so it is asymptotically optimal.\n\nTraversal can also be implemented iteratively. For certain applications, e.g. greater equal search, approximative search, an operation for single step (iterative) traversal can be very useful. This is, of course, implemented without the callback construct and takes  on average and  in the worst case.\n\nVerification\n\nSometimes we already have a binary tree, and we need to determine whether it is a BST. This problem has a simple recursive solution.\n\nThe BST property—every node on the right subtree has to be larger than the current node and every node on the left subtree has to be smaller than the current node—is the key to figuring out whether a tree is a BST or not. The greedy algorithm—simply traverse the tree, at every node check whether the node contains a value larger than the value at the left child and smaller than the value on the right child—does not work for all cases. Consider the following tree:\n\n      20\n     /  \\\n   10    30\n        /  \\\n       5    40\n\nIn the tree above, each node meets the condition that the node contains a value larger than its left child and smaller than its right child hold, and yet it is not a BST: the value 5 is on the right subtree of the node containing 20, a violation of the BST property.\n\nInstead of making a decision based solely on the values of a node and its children, we also need information flowing down from the parent as well. In the case of the tree above, if we could remember about the node containing the value 20, we would see that the node with value 5 is violating the BST property contract.\n\nSo the condition we need to check at each node is: \n* if the node is the left child of its parent, then it must be smaller than (or equal to) the parent and it must pass down the value from its parent to its right subtree to make sure none of the nodes in that subtree is greater than the parent\n* if the node is the right child of its parent, then it must be larger than the parent and it must pass down the value from its parent to its left subtree to make sure none of the nodes in that subtree is lesser than the parent.\n\nA recursive solution in C can explain this further:\n\nstruct TreeNode {\n    int key;\n    int value;\n    struct TreeNode *left;\n    struct TreeNode *right;\n};\n\nbool isBST(struct TreeNode *node, int minKey, int maxKey) {\n    if (node \n NULL) return true;\n    if (node->key key > maxKey) return false;\n    \n    return isBST(node->left, minKey, node->key-1) && isBST(node->right, node->key+1, maxKey);\n}\n\nnode->key+1 and node->key-1 are done to allow only distinct elements in BST.\n\nIf we want same elements to also be present, then we can use only node->key in both places.\n\nThe initial call to this function can be something like this:\n\nif (isBST(root, INT_MIN, INT_MAX)) {\n    puts(\"This is a BST.\");\n} else {\n    puts(\"This is NOT a BST!\");\n}\n\nEssentially we keep creating a valid range (starting from [MIN_VALUE, MAX_VALUE]) and keep shrinking it down for each node as we go down recursively.\n\nAs pointed out in section #Traversal, an in-order traversal of a binary search tree returns the nodes sorted. Thus we only need to keep the last visited node while traversing the tree and check whether its key is smaller (or smaller/equal, if duplicates are to be allowed in the tree) compared to the current key.\n\nExamples of applications\n\nSome examples shall illustrate the use of above basic building blocks.\n\nSort\n\nA binary search tree can be used to implement a simple sorting algorithm. Similar to heapsort, we insert all the values we wish to sort into a new ordered data structure—in this case a binary search tree—and then traverse it in order.\n\nThe worst-case time of build_binary_tree is —if you feed it a sorted list of values, it chains them into a linked list with no left subtrees. For example, build_binary_tree([1, 2, 3, 4, 5]) yields the tree (1 (2 (3 (4 (5))))).\n\nThere are several schemes for overcoming this flaw with simple binary trees; the most common is the self-balancing binary search tree. If this same procedure is done using such a tree, the overall worst-case time is , which is asymptotically optimal for a comparison sort. In practice, the added overhead in time and space for a tree-based sort (particularly for node allocation) make it inferior to other asymptotically optimal sorts such as  heapsort for static list sorting. On the other hand, it is one of the most efficient methods of incremental sorting, adding items to a list over time while keeping the list sorted at all times.\n\nPriority queue operations\n\nBinary search trees can serve as priority queues: structures that allow insertion of arbitrary key as well as lookup and deletion of the minimum (or maximum) key. Insertion works as previously explained. Find-min walks the tree, following left pointers as far as it can without hitting a leaf:\n\n // Precondition: T is not a leaf\n function find-min(T):\n     while hasLeft(T):\n         T ? left(T)\n     return key(T)\n\nFind-max is analogous: follow right pointers as far as possible. Delete-min (max) can simply look up the minimum (maximum), then delete it. This way, insertion and deletion both take logarithmic time, just as they do in a binary heap, but unlike a binary heap and most other priority queue implementations, a single tree can support all of find-min, find-max, delete-min and delete-max at the same time, making binary search trees suitable as double-ended priority queues.\n\nTypes\n\nThere are many types of binary search trees. AVL trees and red-black trees are both forms of self-balancing binary search trees. A splay tree is a binary search tree that automatically moves frequently accessed elements nearer to the root. In a treap (tree heap), each node also holds a (randomly chosen) priority and the parent node has higher priority than its children. Tango trees are trees optimized for fast searches.\nT-trees are binary search trees optimized to reduce storage space overhead, widely used for in-memory databases\n\nA degenerate tree is a tree where for each parent node, there is only one associated child node. It is unbalanced and, in the worst case, performance degrades to that of a linked list. If your add node function does not handle re-balancing, then you can easily construct a degenerate tree by feeding it with data that is already sorted. What this means is that in a performance measurement, the tree will  essentially behave like a linked list data structure.\n\nPerformance comparisons\n\nD. A. Heger (2004) presented a performance comparison of binary search trees. Treap was found to have the best average performance, while red-black tree was found to have the smallest amount of performance variations.\n\nOptimal binary search trees\n\nIf we do not plan on modifying a search tree, and we know exactly how often each item will be accessed, we can construct an optimal binary search tree, which is a search tree where the average cost of looking up an item (the expected search cost) is minimized.\n\nEven if we only have estimates of the search costs, such a system can considerably speed up lookups on average. For example, if you have a BST of English words used in a spell checker, you might balance the tree based on word frequency in text corpora, placing words like the near the root and words like agerasia near the leaves. Such a tree might be compared with Huffman trees, which similarly seek to place frequently used items near the root in order to produce a dense information encoding; however, Huffman trees store data elements only in leaves, and these elements need not be ordered.\n\nIf we do not know the sequence in which the elements in the tree will be accessed in advance, we can use splay trees which are asymptotically as good as any static search tree we can construct for any particular sequence of lookup operations.\n\nAlphabetic trees are Huffman trees with the additional constraint on order, or, equivalently, search trees with the modification that all elements are stored in the leaves. Faster algorithms exist for optimal alphabetic binary trees (OABTs).",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Binary search tree" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=4320" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "In computer science, binary search trees (BST), sometimes called ordered or sorted binary trees, are a particular type of container: data structures that store \"items\" (such as numbers, names etc.) in memory. They allow fast lookup, addition and removal of items, and can be used to implement either dynamic sets of items, or lookup tables that allow finding an item by its key (e.g., finding the phone number of a person by name).\n\nBinary search trees keep their keys in sorted order, so that lookup and other operations can use the principle of binary search: when looking for a key in a tree (or a place to insert a new key), they traverse the tree from root to leaf, making comparisons to keys stored in the nodes of the tree and deciding, on the basis of the comparison, to continue searching in the left or right subtrees. On average, this means that each comparison allows the operations to skip about half of the tree, so that each lookup, insertion or deletion takes time proportional to the logarithm of the number of items stored in the tree. This is much better than the linear time required to find items by key in an (unsorted) array, but slower than the corresponding operations on hash tables.\n\nSeveral variants of the binary search tree have been studied in computer science; this article deals primarily with the basic type, making references to more advanced types when appropriate.\n\nDefinition\n\nA binary search tree is a rooted binary tree, whose internal nodes each store a key (and optionally, an associated value) and each have two distinguished sub-trees, commonly denoted left and right. The tree additionally satisfies the binary search property, which states that the key in each node must be greater than or equal to any key stored in the left sub-tree, and less than or equal to any key stored in the right sub-tree. (The leaves (final nodes) of the tree contain no key and have no structure to distinguish them from one another. Leaves are commonly represented by a special  or  symbol, a  pointer, etc.)\n\nFrequently, the information represented by each node is a record rather than a single data element.  However, for sequencing purposes, nodes are compared according to their keys rather than any part of their associated records.\n\nThe major advantage of binary search trees over other data structures is that the related sorting algorithms and search algorithms such as in-order traversal can be very efficient; they are also easy to code.\n\nBinary search trees are a fundamental data structure used to construct more abstract data structures such as sets, multisets, and associative arrays.\n* When inserting or searching for an element in a binary search tree, the key of each visited node has to be compared with the key of the element to be inserted or found.\n* The shape of the binary search tree depends entirely on the order of insertions and deletions, and can become degenerate.\n* After a long intermixed sequence of random insertion and deletion, the expected height of the tree approaches square root of the number of keys, , which grows much faster than .\n* There has been a lot of research to prevent degeneration of the tree resulting in worst case time complexity of  (for details see section #Types).\n\nOrder relation \n\nBinary search requires an order relation by which every element (item) can be compared with every other element in the sense of a total preorder. The part of the element which effectively takes place in the comparison is called its key. Whether duplicates, i.e. different elements with same key, shall be allowed in the tree or not, does not depend on the order relation, but on the application only.\n\nIn the context of binary search trees a total preorder is realized most flexibly by means of a three-way comparison subroutine.\n\nOperations\n\nBinary search trees support three main operations: insertion of elements, deletion of elements, and lookup (checking whether a key is present).\n\nSearching\n\nSearching a binary search tree for a specific key can be programmed recursively or iteratively.\n\nWe begin by examining the root node. If the tree is null, the key we are searching for does not exist in the tree. Otherwise, if the key equals that of the root, the search is successful and we return the node. If the key is less than that of the root, we search the left subtree. Similarly, if the key is greater than that of the root, we search the right subtree. This process is repeated until the key is found or the remaining subtree is null. If the searched key is not found after a null subtree is reached, then the key is not present in the tree. This is easily expressed as a recursive algorithm (implemented in Python):\n\ndef search_recursively(key, node):\n    if node is None or node.key \n key:\n        return node\n    if key  node.key\n    return search_recursively(key, node.right)\n\nThe same algorithm can be implemented iteratively:\n\ndef search_iteratively(key, node): \n    current_node = node\n    while current_node is not None:\n        if key \n current_node.key:\n            return current_node\n        if key  current_node.key:\n            current_node = current_node.right\n    return current_node\n\nThese two examples rely on the order relation being a total order.\n\nIf the order relation is only a total preorder a reasonable extension of the functionality is the following: also in case of equality search down to the leaves in a direction specified by the user. A binary tree sort equipped with such a comparison function becomes stable.\n\nBecause in the worst case this algorithm must search from the root of the tree to the leaf farthest from the root, the search operation takes time proportional to the tree's height (see tree terminology). On average, binary search trees with  nodes have  height. However, in the worst case, binary search trees can have  height, when the unbalanced tree resembles a linked list (degenerate tree).\n\nInsertion\n\nInsertion begins as a search would begin; if the key is not equal to that of the root, we search the left or right subtrees as before. Eventually, we will reach an external node and add the new key-value pair (here encoded as a record 'newNode') as its right or left child, depending on the node's key. In other words, we examine the root and recursively insert the new node to the left subtree if its key is less than that of the root, or the right subtree if its key is greater than or equal to the root.\n\nHere's how a typical binary search tree insertion might be performed in a binary tree in C++:\n\nNode* insert(Node* root, int key, int value) {\n  if (!root) \n    root = new Node(key, value);\n  else if (key key)\n    root->left = insert(root->left, key, value);\n  else  // key >= root->key\n    root->right = insert(root->right, key, value);\n  return root;\n}\n\nThe above destructive procedural variant modifies the tree in place. It uses only constant heap space (and the iterative version uses constant stack space as well), but the prior version of the tree is lost. Alternatively, as in the following Python example, we can reconstruct all ancestors of the inserted node; any reference to the original tree root remains valid, making the tree a persistent data structure:\n\ndef binary_tree_insert(node, key, value):\n   if node is None:\n       return NodeTree(None, key, value, None)\n   if key \n node.key:\n       return NodeTree(node.left, key, value, node.right)\n   if key \n\nThe part that is rebuilt uses  space in the average case and  in the worst case.\n\nIn either version, this operation requires time proportional to the height of the tree in the worst case, which is  time in the average case over all trees, but  time in the worst case.\n\nAnother way to explain insertion is that in order to insert a new node in the tree, its key is first compared with that of the root. If its key is less than the root's, it is then compared with the key of the root's left child. If its key is greater, it is compared with the root's right child. This process continues, until the new node is compared with a leaf node, and then it is added as this node's right or left child, depending on its key: if the key is less than the leaf's key, then it is inserted as the leaf's left child, otherwise as the leaf's right child.\n\nThere are other ways of inserting nodes into a binary tree, but this is the only way of inserting nodes at the leaves and at the same time preserving the BST structure.\n\nDeletion\n\nWhen removing a node from a binary search tree it is mandatory to maintain the in-order sequence of the nodes.\nThere are many possibilities to do this. However, the following method which has been proposed by T. Hibbard in 1962s. Robert Sedgewick, Kevin Wayne: [http://bookshelf.theopensourcelibrary.org/AlgorithmsFourthEdition.pdf Algorithms Fourth Edition.] Pearson Education, 2011, , p. 410. guarantees that the heights of the subject subtrees are changed by at most one.\nThere are three possible cases to consider:\n* Deleting a node with no children: simply remove the node from the tree.\n* Deleting a node with one child: remove the node and replace it with its child.\n* Deleting a node with two children: call the node to be deleted D.  Do not delete D.  Instead, choose either its in-order predecessor node or its in-order successor node as replacement node E (s. figure). Copy the user values of E to D.Of course, a generic software package has to work the other way around: It has to leave the user data untouched and to furnish E with all the BST links to and from D. If E does not have a child simply remove E from its previous parent G. If E has a child, say F, it is a right child. Replace E with F at E's parent.\n\nIn all cases, when D happens to be the root, make the replacement node root again.\n\nBroadly speaking, nodes with children are harder to delete. As with all binary trees, a node's in-order successor is its right subtree's left-most child, and a node's in-order predecessor is the left subtree's right-most child. In either case, this node will have only one or no child at all. Delete it according to one of the two simpler cases above.\n\nConsistently using the in-order successor or the in-order predecessor for every instance of the two-child case can lead to an unbalanced tree, so some implementations select one or the other at different times.\n\nRuntime analysis: Although this operation does not always traverse the tree down to a leaf, this is always a possibility; thus in the worst case it requires time proportional to the height of the tree. It does not require more even when the node has two children, since it still follows a single path and does not visit any node twice.\n\ndef find_min(self):   # Gets minimum node in a subtree\n    current_node = self\n    while current_node.left_child:\n        current_node = current_node.left_child\n    return current_node\n\ndef replace_node_in_parent(self, new_value=None):\n    if self.parent:\n        if self \n self.parent.left_child:\n            self.parent.left_child = new_value\n        else:\n            self.parent.right_child = new_value\n    if new_value:\n        new_value.parent = self.parent\n\ndef binary_tree_delete(self, key):\n    if key  self.key:\n        self.right_child.binary_tree_delete(key)\n        return\n    # delete the key here\n    if self.left_child and self.right_child: # if both children are present\n        successor = self.right_child.find_min()\n        self.key = successor.key\n        successor.binary_tree_delete(successor.key)\n    elif self.left_child:   # if the node has only a *left* child\n        self.replace_node_in_parent(self.left_child)\n    elif self.right_child:  # if the node has only a *right* child\n        self.replace_node_in_parent(self.right_child)\n    else:\n        self.replace_node_in_parent(None) # this node has no children\n\nTraversal\n\nOnce the binary search tree has been created, its elements can be retrieved in-order by recursively traversing the left subtree of the root node, accessing the node itself, then recursively traversing the right subtree of the node, continuing this pattern with each node in the tree as it's recursively accessed. As with all binary trees, one may conduct a pre-order traversal or a post-order traversal, but neither are likely to be useful for binary search trees. An in-order traversal of a binary search tree will always result in a sorted list of node items (numbers, strings or other comparable items).\n\nThe code for in-order traversal in Python is given below. It will call callback (some function the programmer wishes to call on the node's value, such as printing to the screen) for every node in the tree.\n\ndef traverse_binary_tree(node, callback):\n    if node is None:\n        return\n    traverse_binary_tree(node.leftChild, callback)\n    callback(node.value)\n    traverse_binary_tree(node.rightChild, callback)\n\nTraversal requires  time, since it must visit every node. This algorithm is also , so it is asymptotically optimal.\n\nTraversal can also be implemented iteratively. For certain applications, e.g. greater equal search, approximative search, an operation for single step (iterative) traversal can be very useful. This is, of course, implemented without the callback construct and takes  on average and  in the worst case.\n\nVerification\n\nSometimes we already have a binary tree, and we need to determine whether it is a BST. This problem has a simple recursive solution.\n\nThe BST property—every node on the right subtree has to be larger than the current node and every node on the left subtree has to be smaller than the current node—is the key to figuring out whether a tree is a BST or not. The greedy algorithm—simply traverse the tree, at every node check whether the node contains a value larger than the value at the left child and smaller than the value on the right child—does not work for all cases. Consider the following tree:\n\n      20\n     /  \\\n   10    30\n        /  \\\n       5    40\n\nIn the tree above, each node meets the condition that the node contains a value larger than its left child and smaller than its right child hold, and yet it is not a BST: the value 5 is on the right subtree of the node containing 20, a violation of the BST property.\n\nInstead of making a decision based solely on the values of a node and its children, we also need information flowing down from the parent as well. In the case of the tree above, if we could remember about the node containing the value 20, we would see that the node with value 5 is violating the BST property contract.\n\nSo the condition we need to check at each node is: \n* if the node is the left child of its parent, then it must be smaller than (or equal to) the parent and it must pass down the value from its parent to its right subtree to make sure none of the nodes in that subtree is greater than the parent\n* if the node is the right child of its parent, then it must be larger than the parent and it must pass down the value from its parent to its left subtree to make sure none of the nodes in that subtree is lesser than the parent.\n\nA recursive solution in C can explain this further:\n\nstruct TreeNode {\n    int key;\n    int value;\n    struct TreeNode *left;\n    struct TreeNode *right;\n};\n\nbool isBST(struct TreeNode *node, int minKey, int maxKey) {\n    if (node \n NULL) return true;\n    if (node->key key > maxKey) return false;\n    \n    return isBST(node->left, minKey, node->key-1) && isBST(node->right, node->key+1, maxKey);\n}\n\nnode->key+1 and node->key-1 are done to allow only distinct elements in BST.\n\nIf we want same elements to also be present, then we can use only node->key in both places.\n\nThe initial call to this function can be something like this:\n\nif (isBST(root, INT_MIN, INT_MAX)) {\n    puts(\"This is a BST.\");\n} else {\n    puts(\"This is NOT a BST!\");\n}\n\nEssentially we keep creating a valid range (starting from [MIN_VALUE, MAX_VALUE]) and keep shrinking it down for each node as we go down recursively.\n\nAs pointed out in section #Traversal, an in-order traversal of a binary search tree returns the nodes sorted. Thus we only need to keep the last visited node while traversing the tree and check whether its key is smaller (or smaller/equal, if duplicates are to be allowed in the tree) compared to the current key.\n\nExamples of applications\n\nSome examples shall illustrate the use of above basic building blocks.\n\nSort\n\nA binary search tree can be used to implement a simple sorting algorithm. Similar to heapsort, we insert all the values we wish to sort into a new ordered data structure—in this case a binary search tree—and then traverse it in order.\n\nThe worst-case time of build_binary_tree is —if you feed it a sorted list of values, it chains them into a linked list with no left subtrees. For example, build_binary_tree([1, 2, 3, 4, 5]) yields the tree (1 (2 (3 (4 (5))))).\n\nThere are several schemes for overcoming this flaw with simple binary trees; the most common is the self-balancing binary search tree. If this same procedure is done using such a tree, the overall worst-case time is , which is asymptotically optimal for a comparison sort. In practice, the added overhead in time and space for a tree-based sort (particularly for node allocation) make it inferior to other asymptotically optimal sorts such as  heapsort for static list sorting. On the other hand, it is one of the most efficient methods of incremental sorting, adding items to a list over time while keeping the list sorted at all times.\n\nPriority queue operations\n\nBinary search trees can serve as priority queues: structures that allow insertion of arbitrary key as well as lookup and deletion of the minimum (or maximum) key. Insertion works as previously explained. Find-min walks the tree, following left pointers as far as it can without hitting a leaf:\n\n // Precondition: T is not a leaf\n function find-min(T):\n     while hasLeft(T):\n         T ? left(T)\n     return key(T)\n\nFind-max is analogous: follow right pointers as far as possible. Delete-min (max) can simply look up the minimum (maximum), then delete it. This way, insertion and deletion both take logarithmic time, just as they do in a binary heap, but unlike a binary heap and most other priority queue implementations, a single tree can support all of find-min, find-max, delete-min and delete-max at the same time, making binary search trees suitable as double-ended priority queues.\n\nTypes\n\nThere are many types of binary search trees. AVL trees and red-black trees are both forms of self-balancing binary search trees. A splay tree is a binary search tree that automatically moves frequently accessed elements nearer to the root. In a treap (tree heap), each node also holds a (randomly chosen) priority and the parent node has higher priority than its children. Tango trees are trees optimized for fast searches.\nT-trees are binary search trees optimized to reduce storage space overhead, widely used for in-memory databases\n\nA degenerate tree is a tree where for each parent node, there is only one associated child node. It is unbalanced and, in the worst case, performance degrades to that of a linked list. If your add node function does not handle re-balancing, then you can easily construct a degenerate tree by feeding it with data that is already sorted. What this means is that in a performance measurement, the tree will  essentially behave like a linked list data structure.\n\nPerformance comparisons\n\nD. A. Heger (2004) presented a performance comparison of binary search trees. Treap was found to have the best average performance, while red-black tree was found to have the smallest amount of performance variations.\n\nOptimal binary search trees\n\nIf we do not plan on modifying a search tree, and we know exactly how often each item will be accessed, we can construct an optimal binary search tree, which is a search tree where the average cost of looking up an item (the expected search cost) is minimized.\n\nEven if we only have estimates of the search costs, such a system can considerably speed up lookups on average. For example, if you have a BST of English words used in a spell checker, you might balance the tree based on word frequency in text corpora, placing words like the near the root and words like agerasia near the leaves. Such a tree might be compared with Huffman trees, which similarly seek to place frequently used items near the root in order to produce a dense information encoding; however, Huffman trees store data elements only in leaves, and these elements need not be ordered.\n\nIf we do not know the sequence in which the elements in the tree will be accessed in advance, we can use splay trees which are asymptotically as good as any static search tree we can construct for any particular sequence of lookup operations.\n\nAlphabetic trees are Huffman trees with the additional constraint on order, or, equivalently, search trees with the modification that all elements are stored in the leaves. Faster algorithms exist for optimal alphabetic binary trees (OABTs). Binary search tree. http://en.wikipedia.org/?curid=4320."
  }
}
