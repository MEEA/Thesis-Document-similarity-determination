{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=14775",
  "eid" : "17bdef60-52b2-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778549078,
  "textBody" : "The inch (abbreviation: in or ″) is a unit of length in the (British) imperial and United States customary systems of measurement now formally equal to  yard but usually understood as  of a foot. Derived from the Roman uncia (\"twelfth\"), inch is also sometimes used to translate related units in other measurement systems, usually understood as deriving from the width of the human thumb. Traditional standards for the exact length of an inch have varied in the past, but since the adoption of the international yard during the 1950s and 1960s it has been based on the metric system and defined as exactly 2.54cm.\n\nName\n\nThe English word \"inch\" () was an early borrowing from Latin ' (\"one-twelfth; Roman inch; Roman ounce\") not present in other Germanic languages.. The vowel change from Latin /u/ to English /ɪ/ is known as umlaut. The consonant change from the Latin /k/ to English /tʃ/ or /ʃ/ is palatalisation. Both were features of Old English phonology. \"Inch\" is cognate with \"ounce\" (), whose separate pronunciation and spelling reflect its reborrowing in Middle English from Anglo-Norman unce and ounce..\n\nIn many other European languages, the word for \"inch\" is the same as or derived from the word for \"thumb\", as a man's thumb is about an inch wide (and this was even sometimes used to define the inch). Examples include ;  (\"inch\") and ' (\"thumb\"); ; Danish and  (\"inch\") ' (\"thumb\"); ;  ; ; ;  (\"inch\") and ' (\"thumb\"); ;  (\"inch\") and ' (\"thumb\"); and  (\"inch\") and tumme (\"thumb\").\n\nUsage \n\nThe inch is a commonly used customary unit of length in the United States, lists 24,302 instances of inch(es) compared to 1548 instances of centimeter(s) and 1343 instances of millimeter(s). Canada, Canadian units (5) The Canadian units of measurement are as set out and defined in Schedule II, and the symbols and abbreviations therefore are as added pursuant to subparagraph 6(1)(b)(ii). and the United Kingdom. It is also used in Japan for electronic parts, especially display screens. In most of continental Europe the inch is used informally as a measure for display screens too. For the United Kingdom, guidance on public sector use states that, since 1 October 1995, without time limit, the inch (along with the foot) is to be used as a primary unit for road signs and related measurements of distance (with the possible exception of clearance heights and widths) and may continue to be used as a secondary or supplementary indication following a metric measurement for other purposes.\n\nThe international standard symbol for inch is in (see ISO 31-1, Annex A) but traditionally the inch is denoted by a double prime, which is often approximated by double quotes, and the foot by a prime, which is often approximated by an apostrophe. For example,  can be written as 3′ 2″. (This is akin to how the first and second \"cuts\" of the hour are likewise indicated by prime and double prime symbols.) Subdivisions of an inch are typically written using dyadic fractions with odd number numerators; for example,  would be written as ″ and not as 2.375″ nor as ″.\n\nEquivalences\n\n1 international inch is equal to:\n* 10,000 tenths\n* 1,000 thou or mil\n* 100 points or gries\n* 72 PostScript points\n* 10, 12, 16, or 40 lines\n* 6 computer picas\n* 3 barleycorns\n* 2.54 centimetres exactly (1 centimetre ≈ 0.3937008 inches.)\n* 0.999998 US Survey inches\n*  or 0.33 palms\n*  or 0.25 hands\n*  or 0.0833 feet\n*  or 0.0277 yards\n\nHistory \n\nThe earliest known reference to the inch in England is from the Laws of Æthelberht dating to the early 7th century, surviving in a single manuscript from 1120. Paragraph LXVII sets out the fine for wounds of various depths: one inch, one shilling, two inches, two shillings, etc.\n\nAn Anglo-Saxon unit of length was the barleycorn. After 1066, 1 inch was equal to 3 barleycorns, which continued to be its legal definition for several centuries, with the barleycorn being the base unit. One of the earliest such definitions is that of 1324, where the legal definition of the inch was set out in a statute of Edward II of England, defining it as \"three grains of barley, dry and round, placed end to end, lengthwise\".\n\nSimilar definitions are recorded in both English and Welsh medieval law tracts. One, dating from the first half of the 10th century, is contained in the Laws of Hywel Dda which superseded those of Dyfnwal, an even earlier definition of the inch in Wales. Both definitions, as recorded in Ancient Laws and Institutes of Wales (vol i., pp. 184, 187, 189), are that \"three lengths of a barleycorn is the inch\".\n\nKing David I of Scotland in his Assize of Weights and Measures (c. 1150) is said to have defined the Scottish inch as the width of an average man's thumb at the base of the nail, even including the requirement to calculate the average of a small, a medium, and a large man's measures. However, the oldest surviving manuscripts date from the early 14th century and appear to have been altered with the inclusion of newer material.\n\nIn 1814, Charles Butler, a mathematics teacher at Cheam School, recorded the old legal definition of the inch to be \"three grains of sound ripe barley being taken out the middle of the ear, well dried, and laid end to end in a row\", and placed the barleycorn, not the inch, as the base unit of the English Long Measure system, from which all other units were derived. John Bouvier similarly recorded in his 1843 law dictionary that the barleycorn was the fundamental measure. Butler observed, however, that \"[a]s the length of the barley-corn cannot be fixed, so the inch according to this method will be uncertain\", noting that a standard inch measure was now (by his time) kept in the Exchequer chamber, Guildhall, and that was the legal definition of the inch. This was a point also made by George Long in his 1842 Penny Cyclopædia, observing that standard measures had since surpassed the barleycorn definition of the inch, and that to recover the inch measure from its original definition, in the event that the standard measure were destroyed, would involve the measurement of large numbers of barleycorns and taking their average lengths. He noted that this process would not perfectly recover the standard, since it might introduce errors of anywhere between one hundredth and one tenth of an inch in the definition of a yard.\n\nBefore the adoption of the international yard and pound, various definitions were in use. In the United Kingdom and most countries of the British Commonwealth, the inch was defined in terms of the Imperial Standard Yard. The United States adopted the conversion factor 1 metre 39.37 inches by an act in 1866. In 1893, Mendenhall ordered the physical realization of the inch to be based on the international prototype metres numbers 21 and 27, which had been received from the CGPM, together with the previously adopted conversion factor.\n\nIn 1930, the British Standards Institution adopted an inch of exactly 25.4 mm. The American Standards Association followed suit in 1933. By 1935, industry in 16 countries had adopted the \"industrial inch\" as it came to be known.\n\nIn 1946, the Commonwealth Science Congress recommended a yard of exactly 0.9144 metres for adoption throughout the British Commonwealth. This was adopted by Canada in 1951, the United States on 1 July 1959, Australia in 1961,Statutory Rule No. 142. effective 1 January 1964,[http://www.comlaw.gov.au/Details/C2004L00578 Australian Government ComLaw Weights and Measures (National Standards) Regulations - C2004L00578] and the United Kingdom in 1963,Weights and Measures Act of 1963. effective on 1 January 1964. The new standards gave an inch of exactly 25.4 mm, 1.7 millionths of an inch longer than the old imperial inch and 2 millionths of an inch shorter than the old US inch.\n\nRelated units\n\nUS Survey inches\n\nThe United States retains the -metre definition for survey purposes, producing a 2 millionth part difference in between standard and US survey inches.A. V. Astin & H. Arnold Karo, (1959), [http://www.ngs.noaa.gov/PUBS_LIB/FedRegister/FRdoc59-5442.pdf Refinement of values for the yard and the pound], Washington DC: National Bureau of Standards, republished on  National Geodetic Survey web site and the Federal Register (Doc. 59-5442, Filed, 30 June 1959, 8:45 am) This is approximately -inch in a mile. This difference is very significant when doing calculations in State Plane Coordinate Systems with coordinate values in the hundreds of thousands or millions of feet.\n\nContinental inches\n\nBefore the adoption of the metric system, several European countries had customary units whose name translates into \"inch\". The French pouce measured 2.70 cm, at least when applied to describe the calibre of artillery pieces. The Amsterdam foot (voet) consisted of 11 Amsterdam inches (duim). The Amsterdam foot is about 8% shorter than an English foot.\n\nScottish inch \n\nThe now obsolete Scottish inch (),  of a Scottish foot, was about 1.0016 imperial inches (about ). It was used in the popular expression ', in English \"Give him an inch and he'll take an ell\", first published as \"For when I gave you an inch, you tooke an ell\" by John Heywood in 1546. [https://archive.org/stream/proverbsofjohnhe00heywrich/proverbsofjohnhe00heywrich_djvu.txt Full text of 1874 reprint] (The ell, equal to 37 inches (about 94 cm), was in use in England until 1685.) Modern versions of the saying include \"Give him an inch and he'll take a mile\" and \"Give him and inch and he'll take a yard\".",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Inch" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=14775" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "The inch (abbreviation: in or ″) is a unit of length in the (British) imperial and United States customary systems of measurement now formally equal to  yard but usually understood as  of a foot. Derived from the Roman uncia (\"twelfth\"), inch is also sometimes used to translate related units in other measurement systems, usually understood as deriving from the width of the human thumb. Traditional standards for the exact length of an inch have varied in the past, but since the adoption of the international yard during the 1950s and 1960s it has been based on the metric system and defined as exactly 2.54cm.\n\nName\n\nThe English word \"inch\" () was an early borrowing from Latin ' (\"one-twelfth; Roman inch; Roman ounce\") not present in other Germanic languages.. The vowel change from Latin /u/ to English /ɪ/ is known as umlaut. The consonant change from the Latin /k/ to English /tʃ/ or /ʃ/ is palatalisation. Both were features of Old English phonology. \"Inch\" is cognate with \"ounce\" (), whose separate pronunciation and spelling reflect its reborrowing in Middle English from Anglo-Norman unce and ounce..\n\nIn many other European languages, the word for \"inch\" is the same as or derived from the word for \"thumb\", as a man's thumb is about an inch wide (and this was even sometimes used to define the inch). Examples include ;  (\"inch\") and ' (\"thumb\"); ; Danish and  (\"inch\") ' (\"thumb\"); ;  ; ; ;  (\"inch\") and ' (\"thumb\"); ;  (\"inch\") and ' (\"thumb\"); and  (\"inch\") and tumme (\"thumb\").\n\nUsage \n\nThe inch is a commonly used customary unit of length in the United States, lists 24,302 instances of inch(es) compared to 1548 instances of centimeter(s) and 1343 instances of millimeter(s). Canada, Canadian units (5) The Canadian units of measurement are as set out and defined in Schedule II, and the symbols and abbreviations therefore are as added pursuant to subparagraph 6(1)(b)(ii). and the United Kingdom. It is also used in Japan for electronic parts, especially display screens. In most of continental Europe the inch is used informally as a measure for display screens too. For the United Kingdom, guidance on public sector use states that, since 1 October 1995, without time limit, the inch (along with the foot) is to be used as a primary unit for road signs and related measurements of distance (with the possible exception of clearance heights and widths) and may continue to be used as a secondary or supplementary indication following a metric measurement for other purposes.\n\nThe international standard symbol for inch is in (see ISO 31-1, Annex A) but traditionally the inch is denoted by a double prime, which is often approximated by double quotes, and the foot by a prime, which is often approximated by an apostrophe. For example,  can be written as 3′ 2″. (This is akin to how the first and second \"cuts\" of the hour are likewise indicated by prime and double prime symbols.) Subdivisions of an inch are typically written using dyadic fractions with odd number numerators; for example,  would be written as ″ and not as 2.375″ nor as ″.\n\nEquivalences\n\n1 international inch is equal to:\n* 10,000 tenths\n* 1,000 thou or mil\n* 100 points or gries\n* 72 PostScript points\n* 10, 12, 16, or 40 lines\n* 6 computer picas\n* 3 barleycorns\n* 2.54 centimetres exactly (1 centimetre ≈ 0.3937008 inches.)\n* 0.999998 US Survey inches\n*  or 0.33 palms\n*  or 0.25 hands\n*  or 0.0833 feet\n*  or 0.0277 yards\n\nHistory \n\nThe earliest known reference to the inch in England is from the Laws of Æthelberht dating to the early 7th century, surviving in a single manuscript from 1120. Paragraph LXVII sets out the fine for wounds of various depths: one inch, one shilling, two inches, two shillings, etc.\n\nAn Anglo-Saxon unit of length was the barleycorn. After 1066, 1 inch was equal to 3 barleycorns, which continued to be its legal definition for several centuries, with the barleycorn being the base unit. One of the earliest such definitions is that of 1324, where the legal definition of the inch was set out in a statute of Edward II of England, defining it as \"three grains of barley, dry and round, placed end to end, lengthwise\".\n\nSimilar definitions are recorded in both English and Welsh medieval law tracts. One, dating from the first half of the 10th century, is contained in the Laws of Hywel Dda which superseded those of Dyfnwal, an even earlier definition of the inch in Wales. Both definitions, as recorded in Ancient Laws and Institutes of Wales (vol i., pp. 184, 187, 189), are that \"three lengths of a barleycorn is the inch\".\n\nKing David I of Scotland in his Assize of Weights and Measures (c. 1150) is said to have defined the Scottish inch as the width of an average man's thumb at the base of the nail, even including the requirement to calculate the average of a small, a medium, and a large man's measures. However, the oldest surviving manuscripts date from the early 14th century and appear to have been altered with the inclusion of newer material.\n\nIn 1814, Charles Butler, a mathematics teacher at Cheam School, recorded the old legal definition of the inch to be \"three grains of sound ripe barley being taken out the middle of the ear, well dried, and laid end to end in a row\", and placed the barleycorn, not the inch, as the base unit of the English Long Measure system, from which all other units were derived. John Bouvier similarly recorded in his 1843 law dictionary that the barleycorn was the fundamental measure. Butler observed, however, that \"[a]s the length of the barley-corn cannot be fixed, so the inch according to this method will be uncertain\", noting that a standard inch measure was now (by his time) kept in the Exchequer chamber, Guildhall, and that was the legal definition of the inch. This was a point also made by George Long in his 1842 Penny Cyclopædia, observing that standard measures had since surpassed the barleycorn definition of the inch, and that to recover the inch measure from its original definition, in the event that the standard measure were destroyed, would involve the measurement of large numbers of barleycorns and taking their average lengths. He noted that this process would not perfectly recover the standard, since it might introduce errors of anywhere between one hundredth and one tenth of an inch in the definition of a yard.\n\nBefore the adoption of the international yard and pound, various definitions were in use. In the United Kingdom and most countries of the British Commonwealth, the inch was defined in terms of the Imperial Standard Yard. The United States adopted the conversion factor 1 metre 39.37 inches by an act in 1866. In 1893, Mendenhall ordered the physical realization of the inch to be based on the international prototype metres numbers 21 and 27, which had been received from the CGPM, together with the previously adopted conversion factor.\n\nIn 1930, the British Standards Institution adopted an inch of exactly 25.4 mm. The American Standards Association followed suit in 1933. By 1935, industry in 16 countries had adopted the \"industrial inch\" as it came to be known.\n\nIn 1946, the Commonwealth Science Congress recommended a yard of exactly 0.9144 metres for adoption throughout the British Commonwealth. This was adopted by Canada in 1951, the United States on 1 July 1959, Australia in 1961,Statutory Rule No. 142. effective 1 January 1964,[http://www.comlaw.gov.au/Details/C2004L00578 Australian Government ComLaw Weights and Measures (National Standards) Regulations - C2004L00578] and the United Kingdom in 1963,Weights and Measures Act of 1963. effective on 1 January 1964. The new standards gave an inch of exactly 25.4 mm, 1.7 millionths of an inch longer than the old imperial inch and 2 millionths of an inch shorter than the old US inch.\n\nRelated units\n\nUS Survey inches\n\nThe United States retains the -metre definition for survey purposes, producing a 2 millionth part difference in between standard and US survey inches.A. V. Astin & H. Arnold Karo, (1959), [http://www.ngs.noaa.gov/PUBS_LIB/FedRegister/FRdoc59-5442.pdf Refinement of values for the yard and the pound], Washington DC: National Bureau of Standards, republished on  National Geodetic Survey web site and the Federal Register (Doc. 59-5442, Filed, 30 June 1959, 8:45 am) This is approximately -inch in a mile. This difference is very significant when doing calculations in State Plane Coordinate Systems with coordinate values in the hundreds of thousands or millions of feet.\n\nContinental inches\n\nBefore the adoption of the metric system, several European countries had customary units whose name translates into \"inch\". The French pouce measured 2.70 cm, at least when applied to describe the calibre of artillery pieces. The Amsterdam foot (voet) consisted of 11 Amsterdam inches (duim). The Amsterdam foot is about 8% shorter than an English foot.\n\nScottish inch \n\nThe now obsolete Scottish inch (),  of a Scottish foot, was about 1.0016 imperial inches (about ). It was used in the popular expression ', in English \"Give him an inch and he'll take an ell\", first published as \"For when I gave you an inch, you tooke an ell\" by John Heywood in 1546. [https://archive.org/stream/proverbsofjohnhe00heywrich/proverbsofjohnhe00heywrich_djvu.txt Full text of 1874 reprint] (The ell, equal to 37 inches (about 94 cm), was in use in England until 1685.) Modern versions of the saying include \"Give him an inch and he'll take a mile\" and \"Give him and inch and he'll take a yard\". Inch. http://en.wikipedia.org/?curid=14775."
  }
}
