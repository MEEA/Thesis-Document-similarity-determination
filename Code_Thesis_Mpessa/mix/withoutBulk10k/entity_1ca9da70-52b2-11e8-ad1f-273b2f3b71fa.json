{
  "datasourceIdentifier" : "awesome wiki export",
  "backlink" : "http://en.wikipedia.org/?curid=15491",
  "eid" : "1ca9da70-52b2-11e8-ad1f-273b2f3b71fa",
  "loadTime" : 1525778557335,
  "textBody" : "In number theory, integer factorization is the decomposition of a composite number into a product of smaller integers. If these integers are further restricted to prime numbers, the process is called prime factorization.\n\nWhen the numbers are sufficiently large, no efficient, non-quantum integer factorization algorithm is known. An effort by several researchers, concluded in 2009, to factor a 232-digit number (RSA-768) utilizing hundreds of machines took two years and the researchers estimated that a 1024-bit RSA modulus would take about a thousand times as long. However, it has not been proven that no efficient algorithm exists. The presumed difficulty of this problem is at the heart of widely used algorithms in cryptography such as RSA. Many areas of mathematics and computer science have been brought to bear on the problem, including elliptic curves, algebraic number theory, and quantum computing.\n\nNot all numbers of a given length are equally hard to factor. The hardest instances of these problems (for currently known techniques) are semiprimes, the product of two prime numbers. When they are both large, for instance more than two thousand bits long, randomly chosen, and about the same size (but not too close, e.g., to avoid efficient factorization by Fermat's factorization method), even the fastest prime factorization algorithms on the fastest computers can take enough time to make the search impractical; that is, as the number of digits of the primes being factored increases, the number of operations required to perform the factorization on any computer increases drastically.\n\nMany cryptographic protocols are based on the difficulty of factoring large composite integers or a related problem—for example, the RSA problem. An algorithm that efficiently factors an arbitrary integer would render RSA-based public-key cryptography insecure.\n\nPrime decomposition\n\nBy the fundamental theorem of arithmetic, every positive integer has a unique prime factorization. (By convention 1 is the empty product.) If the integer is prime then it can be recognized as such in polynomial time. If composite however, the theorem gives no insight into how to obtain the factors.\n\nGiven a general algorithm for integer factorization, any integer can be factored down to its constituent prime factors simply by repeated application of this algorithm. The situation is more complicated with special-purpose factorization algorithms, whose benefits may not be realized as well or even at all with the factors produced during decomposition. For example, if  where  are very large primes, trial division will quickly produce the factors 2 and 5 but will take p divisions to find the next factor. As a contrasting example, if N is the product of the primes 13729, 1372933, and 18848997161, where , Fermat's factorization method will start out with  which immediately yields  and hence the factors  and . While these are easily recognized as respectively composite and prime, Fermat's method will take much longer to factorize the composite one because the starting value of  for a is nowhere near 1372933.\n\nCurrent state of the art\n\nAmong the b-bit numbers, the most difficult to factor in practice using existing algorithms are those that are products of two primes of similar size. For this reason, these are the integers used in cryptographic applications. The largest such semiprime yet factored was RSA-768, a 768-bit number with 232 decimal digits, on December 12, 2009. This factorization was a collaboration of several research institutions, spanning two years and taking the equivalent of almost 2000 years of computing on a single-core 2.2 GHz AMD Opteron. Like all recent factorization records, this factorization was completed with a highly optimized implementation of the general number field sieve run on hundreds of machines.\n\nDifficulty and complexity\n\nNo algorithm has been published that can factor all integers in polynomial time, i.e., that can factor b-bit numbers in time O(bk) for some constant k.     The problem is clearly in class NP but has not been proved to be or not be NP-complete.  It is generally suspected not to be NP-complete.\n\nThere are published algorithms that are faster than O((1+ε)b) for all positive ε, i.e., sub-exponential.  The best published asymptotic running time is for the general number field sieve (GNFS) algorithm, which, for a b-bit number n, is:\n\nO\\left(\\exp\\sqrt[3]{\\frac{64}{9} b (\\log b)^2}\\right).\n\nFor current computers, GNFS is the best published algorithm for large n (more than about 100 digits). For a quantum computer, however, Peter Shor discovered an algorithm in 1994 that solves it in polynomial time. This will have significant implications for cryptography if quantum computation becomes scalable. Shor's algorithm takes only  time and O(b) space on b-bit number inputs. In 2001, the first seven-qubit quantum computer became the first to run Shor's algorithm. It factored the number 15.\n\nWhen discussing what complexity classes the integer factorization problem falls into, it is necessary to distinguish two slightly different versions of the problem:\n\n* The function problem version: given an integer N, find an integer d with  that divides N (or conclude that N is prime). This problem is trivially in FNP and it's not known whether it lies in FP or not. This is the version solved by practical implementations.\n* The decision problem version: given an integer N and an integer M with , does N have a factor d with ? This version is useful because most well studied complexity classes are defined as classes of decision problems, not function problems. \n\nFor , the decision problem is equivalent to asking if N is not prime. \n\nAn algorithm for either version provides one for the other. Repeated application of the function problem (applied to d and N/d, and their factors, if needed) will eventually provide either a factor of N no larger than M or a factorization into primes all greater than M. All known algorithms for the decision problem work in this way. Hence it is only of theoretical interest that, with at most log N queries using an algorithm for the decision problem, one would isolate a factor of N (or prove it prime) by binary search. \n\nIt is not known exactly which complexity classes contain the decision version of the integer factorization problem. It is known to be in both NP and co-NP. This is because both YES and NO answers can be verified in polynomial time. An answer of YES can be certified by exhibiting a factorization  with . An answer of NO can be certified by exhibiting the factorization of N into distinct primes, all larger than M. We can verify their primality using the AKS primality test and that their product is N by multiplication. The fundamental theorem of arithmetic guarantees that there is only one possible string that will be accepted (providing the factors are required to be listed in order), which shows that the problem is in both UP and co-UP. It is known to be in BQP because of Shor's algorithm. It is suspected to be outside of all three of the complexity classes P, NP-complete, and co-NP-complete. It is therefore a candidate for the NP-intermediate complexity class. If it could be proved that it is in either NP-Complete or co-NP-Complete, that would imply NP = co-NP. That would be a very surprising result, and therefore integer factorization is widely suspected to be outside both of those classes. Many people have tried to find classical polynomial-time algorithms for it and failed, and therefore it is widely suspected to be outside P.\n\nIn contrast, the decision problem \"is N a composite number?\" (or equivalently: \"is N a prime number?\") appears to be much easier than the problem of actually finding the factors of N. Specifically, the former can be solved in polynomial time (in the number n of digits of N) with the AKS primality test. In addition, there are a number of probabilistic algorithms that can test primality very quickly in practice if one is willing to accept the vanishingly small possibility of error. The ease of primality testing is a crucial part of the RSA algorithm, as it is necessary to find large prime numbers to start with.\n\nFactoring algorithms\n\nSpecial-purpose\n\nA special-purpose factoring algorithm's running time depends on the properties of the number to be factored or on one of its unknown factors: size, special form, etc. Exactly what the running time depends on varies between algorithms.\n\nAn important subclass of special-purpose factoring algorithms is the Category 1 or First Category algorithms, whose running time depends on the size of smallest prime factor. Given an integer of unknown form, these methods are usually applied before general-purpose methods to remove small factors. For example, trial division is a Category 1 algorithm.\n\n* Trial division\n* Wheel factorization\n* Pollard's rho algorithm\n* Algebraic-group factorisation algorithms, among which are Pollard's p − 1 algorithm, Williams' p + 1 algorithm, and Lenstra elliptic curve factorization\n* Fermat's factorization method\n* Euler's factorization method\n* Special number field sieve\n\nGeneral-purpose\n\nA general-purpose factoring algorithm, also known as a Category 2, Second Category, or Kraitchik family algorithm (after Maurice Kraitchik), has a running time which depends solely on the size of the integer to be factored. This is the type of algorithm used to factor RSA numbers. Most general-purpose factoring algorithms are based on the congruence of squares method.\n\n* Dixon's algorithm\n* Continued fraction factorization (CFRAC)\n* Quadratic sieve\n* Rational sieve\n* General number field sieve\n* Shanks' square forms factorization (SQUFOF)\n\nOther notable algorithms\n\n* Shor's algorithm, for quantum computers\n\nHeuristic running time\n\nIn number theory, there are many integer factoring algorithms that heuristically have expected running time\n\nL_n\\left[\\tfrac12,1+o(1)\\right]=e^{(1+o(1))\\sqrt{(\\log n)(\\log \\log n)}}\n\nin big O and L-notation.\nSome examples of those algorithms are the elliptic curve method and the quadratic sieve.\nAnother such algorithm is the class group relations method proposed by Schnorr, Seysen, and Lenstra, that is proved under the assumption of the Generalized Riemann Hypothesis (GRH).\n\nRigorous running time\n\nThe Schnorr-Seysen-Lenstra probabilistic algorithm has been rigorously proven by Lenstra and Pomerance to have expected running time L_n\\left[\\tfrac12,1+o(1)\\right] by replacing the GRH assumption with the use of multipliers.\nThe algorithm uses the class group of positive binary quadratic forms of discriminant Δ denoted by GΔ.\nGΔ is the set of triples of integers (a, b, c) in which those integers are relative prime.\n\nSchnorr-Seysen-Lenstra Algorithm\n\nGiven an integer n that will be factored, where n is an odd positive integer greater than a certain constant. In this factoring algorithm the discriminant Δ is chosen as a multiple of n, , where d is some positive multiplier. The algorithm expects that for one d there exist enough smooth forms in GΔ. Lenstra and Pomerance show that the choice of d can be restricted to a small set to guarantee the smoothness result.\n\nDenote by PΔ the set of all primes q with Kronecker symbol \\left(\\tfrac{\\Delta}{q}\\right)=1. By constructing a set of generators of GΔ and prime forms fq of GΔ with q in PΔ a sequence of relations between the set of generators and fq are produced.\nThe size of q can be bounded by c_0(\\log|\\Delta|)^2 for some constant c_0.\n\nThe relation that will be used is a relation between the product of powers that is equal to the neutral element of GΔ. These relations will be used to construct a so-called ambiguous form of GΔ, which is an element of GΔ of order dividing 2. By calculating the corresponding factorization of Δ and by taking a gcd, this ambiguous form provides the complete prime factorization of n. This algorithm has these main steps:\n\nLet n be the number to be factored.\n# Let Δ be a negative integer with , where d is a multiplier and Δ is the negative discriminant of some quadratic form.\n# Take the t first primes p_12,p_2\n3,p_3=5, \\dots ,p_t, for some t\\in{\\mathbb N}.\n# Let f_q be a random prime form of GΔ with \\left(\\tfrac{\\Delta}{q}\\right)=1.\n# Find a generating set X of GΔ\n# Collect a sequence of relations between set X and } satisfying: \\left(\\prod_{x \\in X_{}} x^{r(x)}\\right).\\left(\\prod_{q \\in P_\\Delta} f^{t(q)}_{q}\\right) = 1\n# Construct an ambiguous form  that is an element f ∈ GΔ of order dividing 2 to obtain a coprime factorization of the largest odd divisor of Δ in which \\Delta = -4ac \\text{ or } a(a - 4c) \\text{ or } (b - 2a)(b + 2a)\n# If the ambiguous form provides a factorization of n then stop, otherwise find another ambiguous form until the factorization of n is found. In order to prevent useless ambiguous forms from generating, build up the 2-Sylow group Sll2(Δ) of G(Δ).\n\nTo obtain an algorithm for factoring any positive integer, it is necessary to add a few steps to this algorithm such as trial division, and the Jacobi sum test.\n\nExpected running time\n\nThe algorithm as stated is a probabilistic algorithm as it makes random choices. Its expected running time is at most L_n\\left[\\tfrac12,1+o(1)\\right].",
  "entityProperties" : [ {
    "name" : "title",
    "type" : "String",
    "values" : [ "Integer factorization" ],
    "synthetic" : false
  }, {
    "name" : "url",
    "type" : "String",
    "values" : [ "http://en.wikipedia.org/?curid=15491" ],
    "synthetic" : false
  } ],
  "classifications" : [ "xml-export" ],
  "technicalAttributes" : {
    "technicalAttributes" : null,
    "aggregatedText" : "In number theory, integer factorization is the decomposition of a composite number into a product of smaller integers. If these integers are further restricted to prime numbers, the process is called prime factorization.\n\nWhen the numbers are sufficiently large, no efficient, non-quantum integer factorization algorithm is known. An effort by several researchers, concluded in 2009, to factor a 232-digit number (RSA-768) utilizing hundreds of machines took two years and the researchers estimated that a 1024-bit RSA modulus would take about a thousand times as long. However, it has not been proven that no efficient algorithm exists. The presumed difficulty of this problem is at the heart of widely used algorithms in cryptography such as RSA. Many areas of mathematics and computer science have been brought to bear on the problem, including elliptic curves, algebraic number theory, and quantum computing.\n\nNot all numbers of a given length are equally hard to factor. The hardest instances of these problems (for currently known techniques) are semiprimes, the product of two prime numbers. When they are both large, for instance more than two thousand bits long, randomly chosen, and about the same size (but not too close, e.g., to avoid efficient factorization by Fermat's factorization method), even the fastest prime factorization algorithms on the fastest computers can take enough time to make the search impractical; that is, as the number of digits of the primes being factored increases, the number of operations required to perform the factorization on any computer increases drastically.\n\nMany cryptographic protocols are based on the difficulty of factoring large composite integers or a related problem—for example, the RSA problem. An algorithm that efficiently factors an arbitrary integer would render RSA-based public-key cryptography insecure.\n\nPrime decomposition\n\nBy the fundamental theorem of arithmetic, every positive integer has a unique prime factorization. (By convention 1 is the empty product.) If the integer is prime then it can be recognized as such in polynomial time. If composite however, the theorem gives no insight into how to obtain the factors.\n\nGiven a general algorithm for integer factorization, any integer can be factored down to its constituent prime factors simply by repeated application of this algorithm. The situation is more complicated with special-purpose factorization algorithms, whose benefits may not be realized as well or even at all with the factors produced during decomposition. For example, if  where  are very large primes, trial division will quickly produce the factors 2 and 5 but will take p divisions to find the next factor. As a contrasting example, if N is the product of the primes 13729, 1372933, and 18848997161, where , Fermat's factorization method will start out with  which immediately yields  and hence the factors  and . While these are easily recognized as respectively composite and prime, Fermat's method will take much longer to factorize the composite one because the starting value of  for a is nowhere near 1372933.\n\nCurrent state of the art\n\nAmong the b-bit numbers, the most difficult to factor in practice using existing algorithms are those that are products of two primes of similar size. For this reason, these are the integers used in cryptographic applications. The largest such semiprime yet factored was RSA-768, a 768-bit number with 232 decimal digits, on December 12, 2009. This factorization was a collaboration of several research institutions, spanning two years and taking the equivalent of almost 2000 years of computing on a single-core 2.2 GHz AMD Opteron. Like all recent factorization records, this factorization was completed with a highly optimized implementation of the general number field sieve run on hundreds of machines.\n\nDifficulty and complexity\n\nNo algorithm has been published that can factor all integers in polynomial time, i.e., that can factor b-bit numbers in time O(bk) for some constant k.     The problem is clearly in class NP but has not been proved to be or not be NP-complete.  It is generally suspected not to be NP-complete.\n\nThere are published algorithms that are faster than O((1+ε)b) for all positive ε, i.e., sub-exponential.  The best published asymptotic running time is for the general number field sieve (GNFS) algorithm, which, for a b-bit number n, is:\n\nO\\left(\\exp\\sqrt[3]{\\frac{64}{9} b (\\log b)^2}\\right).\n\nFor current computers, GNFS is the best published algorithm for large n (more than about 100 digits). For a quantum computer, however, Peter Shor discovered an algorithm in 1994 that solves it in polynomial time. This will have significant implications for cryptography if quantum computation becomes scalable. Shor's algorithm takes only  time and O(b) space on b-bit number inputs. In 2001, the first seven-qubit quantum computer became the first to run Shor's algorithm. It factored the number 15.\n\nWhen discussing what complexity classes the integer factorization problem falls into, it is necessary to distinguish two slightly different versions of the problem:\n\n* The function problem version: given an integer N, find an integer d with  that divides N (or conclude that N is prime). This problem is trivially in FNP and it's not known whether it lies in FP or not. This is the version solved by practical implementations.\n* The decision problem version: given an integer N and an integer M with , does N have a factor d with ? This version is useful because most well studied complexity classes are defined as classes of decision problems, not function problems. \n\nFor , the decision problem is equivalent to asking if N is not prime. \n\nAn algorithm for either version provides one for the other. Repeated application of the function problem (applied to d and N/d, and their factors, if needed) will eventually provide either a factor of N no larger than M or a factorization into primes all greater than M. All known algorithms for the decision problem work in this way. Hence it is only of theoretical interest that, with at most log N queries using an algorithm for the decision problem, one would isolate a factor of N (or prove it prime) by binary search. \n\nIt is not known exactly which complexity classes contain the decision version of the integer factorization problem. It is known to be in both NP and co-NP. This is because both YES and NO answers can be verified in polynomial time. An answer of YES can be certified by exhibiting a factorization  with . An answer of NO can be certified by exhibiting the factorization of N into distinct primes, all larger than M. We can verify their primality using the AKS primality test and that their product is N by multiplication. The fundamental theorem of arithmetic guarantees that there is only one possible string that will be accepted (providing the factors are required to be listed in order), which shows that the problem is in both UP and co-UP. It is known to be in BQP because of Shor's algorithm. It is suspected to be outside of all three of the complexity classes P, NP-complete, and co-NP-complete. It is therefore a candidate for the NP-intermediate complexity class. If it could be proved that it is in either NP-Complete or co-NP-Complete, that would imply NP = co-NP. That would be a very surprising result, and therefore integer factorization is widely suspected to be outside both of those classes. Many people have tried to find classical polynomial-time algorithms for it and failed, and therefore it is widely suspected to be outside P.\n\nIn contrast, the decision problem \"is N a composite number?\" (or equivalently: \"is N a prime number?\") appears to be much easier than the problem of actually finding the factors of N. Specifically, the former can be solved in polynomial time (in the number n of digits of N) with the AKS primality test. In addition, there are a number of probabilistic algorithms that can test primality very quickly in practice if one is willing to accept the vanishingly small possibility of error. The ease of primality testing is a crucial part of the RSA algorithm, as it is necessary to find large prime numbers to start with.\n\nFactoring algorithms\n\nSpecial-purpose\n\nA special-purpose factoring algorithm's running time depends on the properties of the number to be factored or on one of its unknown factors: size, special form, etc. Exactly what the running time depends on varies between algorithms.\n\nAn important subclass of special-purpose factoring algorithms is the Category 1 or First Category algorithms, whose running time depends on the size of smallest prime factor. Given an integer of unknown form, these methods are usually applied before general-purpose methods to remove small factors. For example, trial division is a Category 1 algorithm.\n\n* Trial division\n* Wheel factorization\n* Pollard's rho algorithm\n* Algebraic-group factorisation algorithms, among which are Pollard's p − 1 algorithm, Williams' p + 1 algorithm, and Lenstra elliptic curve factorization\n* Fermat's factorization method\n* Euler's factorization method\n* Special number field sieve\n\nGeneral-purpose\n\nA general-purpose factoring algorithm, also known as a Category 2, Second Category, or Kraitchik family algorithm (after Maurice Kraitchik), has a running time which depends solely on the size of the integer to be factored. This is the type of algorithm used to factor RSA numbers. Most general-purpose factoring algorithms are based on the congruence of squares method.\n\n* Dixon's algorithm\n* Continued fraction factorization (CFRAC)\n* Quadratic sieve\n* Rational sieve\n* General number field sieve\n* Shanks' square forms factorization (SQUFOF)\n\nOther notable algorithms\n\n* Shor's algorithm, for quantum computers\n\nHeuristic running time\n\nIn number theory, there are many integer factoring algorithms that heuristically have expected running time\n\nL_n\\left[\\tfrac12,1+o(1)\\right]=e^{(1+o(1))\\sqrt{(\\log n)(\\log \\log n)}}\n\nin big O and L-notation.\nSome examples of those algorithms are the elliptic curve method and the quadratic sieve.\nAnother such algorithm is the class group relations method proposed by Schnorr, Seysen, and Lenstra, that is proved under the assumption of the Generalized Riemann Hypothesis (GRH).\n\nRigorous running time\n\nThe Schnorr-Seysen-Lenstra probabilistic algorithm has been rigorously proven by Lenstra and Pomerance to have expected running time L_n\\left[\\tfrac12,1+o(1)\\right] by replacing the GRH assumption with the use of multipliers.\nThe algorithm uses the class group of positive binary quadratic forms of discriminant Δ denoted by GΔ.\nGΔ is the set of triples of integers (a, b, c) in which those integers are relative prime.\n\nSchnorr-Seysen-Lenstra Algorithm\n\nGiven an integer n that will be factored, where n is an odd positive integer greater than a certain constant. In this factoring algorithm the discriminant Δ is chosen as a multiple of n, , where d is some positive multiplier. The algorithm expects that for one d there exist enough smooth forms in GΔ. Lenstra and Pomerance show that the choice of d can be restricted to a small set to guarantee the smoothness result.\n\nDenote by PΔ the set of all primes q with Kronecker symbol \\left(\\tfrac{\\Delta}{q}\\right)=1. By constructing a set of generators of GΔ and prime forms fq of GΔ with q in PΔ a sequence of relations between the set of generators and fq are produced.\nThe size of q can be bounded by c_0(\\log|\\Delta|)^2 for some constant c_0.\n\nThe relation that will be used is a relation between the product of powers that is equal to the neutral element of GΔ. These relations will be used to construct a so-called ambiguous form of GΔ, which is an element of GΔ of order dividing 2. By calculating the corresponding factorization of Δ and by taking a gcd, this ambiguous form provides the complete prime factorization of n. This algorithm has these main steps:\n\nLet n be the number to be factored.\n# Let Δ be a negative integer with , where d is a multiplier and Δ is the negative discriminant of some quadratic form.\n# Take the t first primes p_12,p_2\n3,p_3=5, \\dots ,p_t, for some t\\in{\\mathbb N}.\n# Let f_q be a random prime form of GΔ with \\left(\\tfrac{\\Delta}{q}\\right)=1.\n# Find a generating set X of GΔ\n# Collect a sequence of relations between set X and } satisfying: \\left(\\prod_{x \\in X_{}} x^{r(x)}\\right).\\left(\\prod_{q \\in P_\\Delta} f^{t(q)}_{q}\\right) = 1\n# Construct an ambiguous form  that is an element f ∈ GΔ of order dividing 2 to obtain a coprime factorization of the largest odd divisor of Δ in which \\Delta = -4ac \\text{ or } a(a - 4c) \\text{ or } (b - 2a)(b + 2a)\n# If the ambiguous form provides a factorization of n then stop, otherwise find another ambiguous form until the factorization of n is found. In order to prevent useless ambiguous forms from generating, build up the 2-Sylow group Sll2(Δ) of G(Δ).\n\nTo obtain an algorithm for factoring any positive integer, it is necessary to add a few steps to this algorithm such as trial division, and the Jacobi sum test.\n\nExpected running time\n\nThe algorithm as stated is a probabilistic algorithm as it makes random choices. Its expected running time is at most L_n\\left[\\tfrac12,1+o(1)\\right]. Integer factorization. http://en.wikipedia.org/?curid=15491."
  }
}
